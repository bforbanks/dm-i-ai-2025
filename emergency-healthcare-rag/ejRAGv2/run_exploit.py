#!/usr/bin/env python3
"""
Exploitative refinement run using prior results.

- Loads prior runs from CSV or JSON
- Picks best discrete settings (model, chunk sizes, overlaps)
- Samples locally around k1, b, alpha, beta
- Evaluates and saves to .cache/bo_exploit_results.{csv,json}
"""

import argparse
import json
import csv
from pathlib import Path
from typing import Dict, List, Tuple
import random

import pandas as pd
from tqdm import tqdm

# Import evaluation from the main module
from hybrid_retrieval_bo import (
    evaluate_config,
)

CACHE_DIR = Path('.cache')
CACHE_DIR.mkdir(exist_ok=True)

DEFAULT_CSV = CACHE_DIR / 'bo_results.csv'
DEFAULT_JSON = CACHE_DIR / 'bo_results_incremental.json'
OUT_CSV = CACHE_DIR / 'bo_exploit_results.csv'
OUT_JSON = CACHE_DIR / 'bo_exploit_results.json'

COLUMNS = [
    'target',
    'chunk_size_bm25','overlap_bm25','k1','b',
    'chunk_size_embed','overlap_embed','alpha','beta','model_selector'
]


def _cast_discrete(row: Dict[str, float]) -> Dict[str, float]:
    out = dict(row)
    # Discrete cast
    out['chunk_size_bm25'] = int(round(float(out['chunk_size_bm25'])))
    out['overlap_bm25'] = int(round(float(out['overlap_bm25'])))
    out['chunk_size_embed'] = int(round(float(out['chunk_size_embed'])))
    out['overlap_embed'] = int(round(float(out['overlap_embed'])))
    # clamp overlaps < chunk size
    out['chunk_size_bm25'] = max(2, out['chunk_size_bm25'])
    out['chunk_size_embed'] = max(2, out['chunk_size_embed'])
    out['overlap_bm25'] = max(0, min(out['overlap_bm25'], out['chunk_size_bm25'] - 1))
    out['overlap_embed'] = max(0, min(out['overlap_embed'], out['chunk_size_embed'] - 1))
    # model selector to 0/1
    ms = float(out['model_selector'])
    out['model_selector'] = 0.0 if ms < 0.5 else 1.0
    return out


def load_prior(seed_csv: Path, seed_json: Path) -> pd.DataFrame:
    # Try CSV first; be robust to malformed lines
    if seed_csv.exists():
        try:
            df = pd.read_csv(seed_csv, engine='python', on_bad_lines='skip')
            if 'target' in df.columns:
                return df
        except Exception:
            pass
    # Fallback to JSON
    if seed_json.exists():
        data = json.loads(seed_json.read_text())
        results = data.get('all_results', [])
        rows = []
        for r in results:
            t = r.get('target')
            p = r.get('params', {})
            if t is None:
                continue
            row = {k: p.get(k) for k in COLUMNS[1:]}
            row['target'] = t
            rows.append(row)
        if rows:
            return pd.DataFrame(rows, columns=COLUMNS)
    raise FileNotFoundError('No usable prior file found')


def bounded(val: float, lo: float, hi: float) -> float:
    return max(lo, min(hi, val))


def local_bounds(best: Dict[str, float], pct: float = 0.2) -> Dict[str, Tuple[float, float]]:
    # Bounds for continuous params around best (±pct), clipped to global sensible ranges
    k1 = float(best['k1']); b = float(best['b'])
    a = float(best['alpha']); bb = float(best['beta'])
    return {
        'k1': (bounded(k1 * (1 - pct), 0.0, 3.0), bounded(k1 * (1 + pct), 0.0, 3.0)),
        'b': (bounded(b * (1 - pct), 0.1, 1.5), bounded(b * (1 + pct), 0.1, 1.5)),
        'alpha': (bounded(a - pct, 0.0, 1.0), bounded(a + pct, 0.0, 1.0)),
        'beta': (bounded(bb - pct, 0.0, 1.0), bounded(bb + pct, 0.0, 1.0)),
    }


def sample_cont(bounds: Dict[str, Tuple[float, float]]) -> Dict[str, float]:
    return {k: random.uniform(lo, hi) for k, (lo, hi) in bounds.items()}


def append_row(csv_path: Path, row: Dict[str, float]) -> None:
    header_needed = not csv_path.exists()
    with csv_path.open('a', newline='', encoding='utf-8') as f:
        w = csv.DictWriter(f, fieldnames=COLUMNS)
        if header_needed:
            w.writeheader()
        w.writerow(row)


def save_json(json_path: Path, rows: List[Dict[str, float]]) -> None:
    json_path.write_text(json.dumps({'results': rows}, indent=2))


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument('--seed_csv', type=Path, default=DEFAULT_CSV)
    ap.add_argument('--seed_json', type=Path, default=DEFAULT_JSON)
    ap.add_argument('--trials', type=int, default=200)
    ap.add_argument('--pct', type=float, default=0.2, help='±percent window for k1,b,alpha,beta (when alpha_beta_mode=local)')
    ap.add_argument('--alpha_beta_mode', choices=['local','global','simplex'], default='local',
                    help='How to sample alpha/beta: local=within ±pct of best; global=uniform in [0,1]^2; simplex=alpha+beta=1 (Beta mix)')
    # BM25 fixing options
    ap.add_argument('--fix_bm25', action='store_true', help='Fix BM25 to provided values (or best prior if not provided) and do not sample k1/b')
    ap.add_argument('--bm25_chunk_size', type=int, default=None, help='Fixed BM25 chunk size if --fix_bm25')
    ap.add_argument('--bm25_overlap', type=int, default=None, help='Fixed BM25 overlap if --fix_bm25')
    ap.add_argument('--bm25_k1', type=float, default=None, help='Fixed BM25 k1 if --fix_bm25')
    ap.add_argument('--bm25_b', type=float, default=None, help='Fixed BM25 b if --fix_bm25')
    args = ap.parse_args()

    df = load_prior(args.seed_csv, args.seed_json)
    df = df.dropna(subset=['target'])
    # Cast discrete columns
    for col in ['chunk_size_bm25','overlap_bm25','chunk_size_embed','overlap_embed','model_selector']:
        if col in df.columns:
            df[col] = df[col].astype(float)
    best_row = df.sort_values('target', ascending=False).iloc[0].to_dict()
    best = _cast_discrete(best_row)

    # Optionally override BM25 with user-provided fixed values
    if args.fix_bm25:
        if args.bm25_chunk_size is not None:
            best['chunk_size_bm25'] = int(args.bm25_chunk_size)
        if args.bm25_overlap is not None:
            best['overlap_bm25'] = int(args.bm25_overlap)
        if args.bm25_k1 is not None:
            best['k1'] = float(args.bm25_k1)
        if args.bm25_b is not None:
            best['b'] = float(args.bm25_b)

    print('Using best prior:')
    print({k: best[k] for k in ['target','chunk_size_bm25','overlap_bm25','chunk_size_embed','overlap_embed','model_selector','k1','b','alpha','beta']})

    # Fix discrete params; locally sample continuous ones
    lb = local_bounds(best, pct=args.pct)

    results_json: List[Dict[str, float]] = []

    for i in tqdm(range(args.trials), desc='Exploit trials', unit='trial'):
        picked = sample_cont(lb)
        # If BM25 is fixed, do not sample k1/b; use fixed values
        if args.fix_bm25:
            picked['k1'] = float(best['k1'])
            picked['b'] = float(best['b'])
        # Override alpha/beta sampling per mode
        if args.alpha_beta_mode == 'global':
            picked['alpha'] = random.random()
            picked['beta'] = random.random()
        elif args.alpha_beta_mode == 'simplex':
            # Sample on the line alpha+beta=1 with Beta(0.8,0.8) to allow extremes
            p = random.betavariate(0.8, 0.8)
            picked['beta'] = p
            picked['alpha'] = 1.0 - p
        acc = evaluate_config(
            chunk_size_bm25=best['chunk_size_bm25'],
            overlap_bm25=best['overlap_bm25'],
            k1=picked['k1'],
            b=picked['b'],
            chunk_size_embed=best['chunk_size_embed'],
            overlap_embed=best['overlap_embed'],
            model_type=('MiniLM' if best['model_selector'] < 0.5 else 'ColBERT'),
            alpha=picked['alpha'],
            beta=picked['beta']
        )
        row = {
            'target': acc,
            'chunk_size_bm25': best['chunk_size_bm25'],
            'overlap_bm25': best['overlap_bm25'],
            'k1': picked['k1'],
            'b': picked['b'],
            'chunk_size_embed': best['chunk_size_embed'],
            'overlap_embed': best['overlap_embed'],
            'alpha': picked['alpha'],
            'beta': picked['beta'],
            'model_selector': best['model_selector'],
        }
        append_row(OUT_CSV, row)
        results_json.append(row)
        # Keep a rolling JSON snapshot
        save_json(OUT_JSON, results_json)

    print('\nExploit run complete.')
    print(f'CSV: {OUT_CSV}')
    print(f'JSON: {OUT_JSON}')


if __name__ == '__main__':
    main()
