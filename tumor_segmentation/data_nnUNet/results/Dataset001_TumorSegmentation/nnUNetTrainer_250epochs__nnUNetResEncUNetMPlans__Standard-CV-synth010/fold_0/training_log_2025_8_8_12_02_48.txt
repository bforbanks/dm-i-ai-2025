
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-08-08 12:02:52.010543: Using torch.compile... 
2025-08-08 12:02:54.185247: do_dummy_2d_data_aug: False 
2025-08-08 12:02:54.189679: Using splits from existing split file: /zhome/4b/5/187216/dm-i-ai-2025/tumor_segmentation/data_nnUNet/preprocessed/Dataset001_TumorSegmentation/splits_final.json 
2025-08-08 12:02:54.190785: The split file contains 1 splits. 
2025-08-08 12:02:54.191535: Desired fold for training: 0 
2025-08-08 12:02:54.192220: This split has 516 training and 27 validation cases. 

This is the configuration used by this training:
Configuration name: Standard-CV-synth010
 {'data_identifier': 'nnUNetPlans_Standard-CV-synth010', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 8, 'patch_size': [256, 256], 'median_image_size_in_voxels': [489.0, 400.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_blocks_per_stage': [1, 3, 4, 6, 6, 6, 6], 'n_conv_per_stage_decoder': [1, 1, 1, 1, 1, 1], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '2d'} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_TumorSegmentation', 'plans_name': 'nnUNetResEncUNetMPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 489, 400], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'nnUNetPlannerResEncM', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 239.0, 'mean': 58.64480943229735, 'median': 30.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 200.0, 'std': 65.01235322952341}}} 
 
2025-08-08 12:02:55.281432: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-08-08 12:02:55.335604:  
2025-08-08 12:02:55.336593: Epoch 0 
2025-08-08 12:02:55.339513: Current learning rate: 0.01 
2025-08-08 12:03:30.776440: train_loss -0.0353 
2025-08-08 12:03:30.778869: val_loss -0.2456 
2025-08-08 12:03:30.779853: Pseudo dice [np.float32(0.2166)] 
2025-08-08 12:03:30.780771: Epoch time: 35.45 s 
2025-08-08 12:03:30.781621: Yayy! New best EMA pseudo Dice: 0.21660000085830688 
2025-08-08 12:03:40.100241:  
2025-08-08 12:03:40.101336: Epoch 1 
2025-08-08 12:03:40.102145: Current learning rate: 0.00996 
2025-08-08 12:03:58.283890: train_loss -0.1624 
2025-08-08 12:03:58.285902: val_loss -0.2288 
2025-08-08 12:03:58.286693: Pseudo dice [np.float32(0.4486)] 
2025-08-08 12:03:58.287518: Epoch time: 18.19 s 
2025-08-08 12:03:58.288280: Yayy! New best EMA pseudo Dice: 0.23980000615119934 
2025-08-08 12:04:07.960928:  
2025-08-08 12:04:07.961705: Epoch 2 
2025-08-08 12:04:07.962442: Current learning rate: 0.00993 
2025-08-08 12:04:26.037216: train_loss -0.2487 
2025-08-08 12:04:26.039337: val_loss -0.3971 
2025-08-08 12:04:26.040225: Pseudo dice [np.float32(0.5578)] 
2025-08-08 12:04:26.041516: Epoch time: 18.08 s 
2025-08-08 12:04:26.042423: Yayy! New best EMA pseudo Dice: 0.27160000801086426 
2025-08-08 12:04:36.022058:  
2025-08-08 12:04:36.023014: Epoch 3 
2025-08-08 12:04:36.023922: Current learning rate: 0.00989 
2025-08-08 12:04:54.166923: train_loss -0.2342 
2025-08-08 12:04:54.168734: val_loss -0.3701 
2025-08-08 12:04:54.169475: Pseudo dice [np.float32(0.5459)] 
2025-08-08 12:04:54.170291: Epoch time: 18.15 s 
2025-08-08 12:04:54.171051: Yayy! New best EMA pseudo Dice: 0.29899999499320984 
2025-08-08 12:05:03.857183:  
2025-08-08 12:05:03.858036: Epoch 4 
2025-08-08 12:05:03.858824: Current learning rate: 0.00986 
2025-08-08 12:05:22.042430: train_loss -0.2929 
2025-08-08 12:05:22.044746: val_loss -0.4868 
2025-08-08 12:05:22.045640: Pseudo dice [np.float32(0.6248)] 
2025-08-08 12:05:22.046461: Epoch time: 18.19 s 
2025-08-08 12:05:22.047383: Yayy! New best EMA pseudo Dice: 0.33160001039505005 
2025-08-08 12:05:31.997200:  
2025-08-08 12:05:31.998170: Epoch 5 
2025-08-08 12:05:31.999066: Current learning rate: 0.00982 
2025-08-08 12:05:50.202715: train_loss -0.3462 
2025-08-08 12:05:50.204612: val_loss -0.4388 
2025-08-08 12:05:50.205392: Pseudo dice [np.float32(0.5983)] 
2025-08-08 12:05:50.206183: Epoch time: 18.21 s 
2025-08-08 12:05:50.206910: Yayy! New best EMA pseudo Dice: 0.35830000042915344 
2025-08-08 12:05:59.936895:  
2025-08-08 12:05:59.937726: Epoch 6 
2025-08-08 12:05:59.938474: Current learning rate: 0.00978 
2025-08-08 12:06:18.092180: train_loss -0.3605 
2025-08-08 12:06:18.094240: val_loss -0.4977 
2025-08-08 12:06:18.094999: Pseudo dice [np.float32(0.6377)] 
2025-08-08 12:06:18.095783: Epoch time: 18.16 s 
2025-08-08 12:06:18.096510: Yayy! New best EMA pseudo Dice: 0.3862000107765198 
2025-08-08 12:06:27.893762:  
2025-08-08 12:06:27.894629: Epoch 7 
2025-08-08 12:06:27.895420: Current learning rate: 0.00975 
2025-08-08 12:06:46.076602: train_loss -0.3775 
2025-08-08 12:06:46.078301: val_loss -0.3421 
2025-08-08 12:06:46.079345: Pseudo dice [np.float32(0.5129)] 
2025-08-08 12:06:46.080129: Epoch time: 18.19 s 
2025-08-08 12:06:46.080899: Yayy! New best EMA pseudo Dice: 0.39890000224113464 
2025-08-08 12:06:55.773597:  
2025-08-08 12:06:55.774530: Epoch 8 
2025-08-08 12:06:55.775251: Current learning rate: 0.00971 
2025-08-08 12:07:13.885885: train_loss -0.3515 
2025-08-08 12:07:13.887795: val_loss -0.4819 
2025-08-08 12:07:13.888643: Pseudo dice [np.float32(0.6278)] 
2025-08-08 12:07:13.889483: Epoch time: 18.12 s 
2025-08-08 12:07:13.890302: Yayy! New best EMA pseudo Dice: 0.42179998755455017 
2025-08-08 12:07:23.634798:  
2025-08-08 12:07:23.635897: Epoch 9 
2025-08-08 12:07:23.636795: Current learning rate: 0.00968 
2025-08-08 12:07:41.824650: train_loss -0.3823 
2025-08-08 12:07:41.826465: val_loss -0.4985 
2025-08-08 12:07:41.827216: Pseudo dice [np.float32(0.6539)] 
2025-08-08 12:07:41.827984: Epoch time: 18.19 s 
2025-08-08 12:07:41.828722: Yayy! New best EMA pseudo Dice: 0.4449999928474426 
2025-08-08 12:07:51.540915:  
2025-08-08 12:07:51.541785: Epoch 10 
2025-08-08 12:07:51.542582: Current learning rate: 0.00964 
2025-08-08 12:08:09.751095: train_loss -0.3783 
2025-08-08 12:08:09.752928: val_loss -0.4886 
2025-08-08 12:08:09.753811: Pseudo dice [np.float32(0.6287)] 
2025-08-08 12:08:09.754620: Epoch time: 18.21 s 
2025-08-08 12:08:09.755368: Yayy! New best EMA pseudo Dice: 0.4634000062942505 
2025-08-08 12:08:20.128875:  
2025-08-08 12:08:20.129734: Epoch 11 
2025-08-08 12:08:20.130537: Current learning rate: 0.0096 
2025-08-08 12:08:38.390562: train_loss -0.421 
2025-08-08 12:08:38.392489: val_loss -0.3644 
2025-08-08 12:08:38.393305: Pseudo dice [np.float32(0.5293)] 
2025-08-08 12:08:38.394068: Epoch time: 18.27 s 
2025-08-08 12:08:38.394854: Yayy! New best EMA pseudo Dice: 0.4699999988079071 
2025-08-08 12:08:48.267935:  
2025-08-08 12:08:48.268968: Epoch 12 
2025-08-08 12:08:48.269707: Current learning rate: 0.00957 
2025-08-08 12:09:06.486343: train_loss -0.4268 
2025-08-08 12:09:06.488335: val_loss -0.4502 
2025-08-08 12:09:06.489113: Pseudo dice [np.float32(0.6053)] 
2025-08-08 12:09:06.489884: Epoch time: 18.22 s 
2025-08-08 12:09:06.490598: Yayy! New best EMA pseudo Dice: 0.48350000381469727 
2025-08-08 12:09:16.434581:  
2025-08-08 12:09:16.435385: Epoch 13 
2025-08-08 12:09:16.436174: Current learning rate: 0.00953 
2025-08-08 12:09:34.660574: train_loss -0.4355 
2025-08-08 12:09:34.662618: val_loss -0.4214 
2025-08-08 12:09:34.663378: Pseudo dice [np.float32(0.5854)] 
2025-08-08 12:09:34.664100: Epoch time: 18.23 s 
2025-08-08 12:09:34.664804: Yayy! New best EMA pseudo Dice: 0.4936999976634979 
2025-08-08 12:09:44.575910:  
2025-08-08 12:09:44.577050: Epoch 14 
2025-08-08 12:09:44.578026: Current learning rate: 0.00949 
2025-08-08 12:10:02.640409: train_loss -0.4156 
2025-08-08 12:10:02.642399: val_loss -0.5734 
2025-08-08 12:10:02.643193: Pseudo dice [np.float32(0.6937)] 
2025-08-08 12:10:02.644022: Epoch time: 18.07 s 
2025-08-08 12:10:02.644848: Yayy! New best EMA pseudo Dice: 0.513700008392334 
2025-08-08 12:10:12.482791:  
2025-08-08 12:10:12.483781: Epoch 15 
2025-08-08 12:10:12.484702: Current learning rate: 0.00946 
2025-08-08 12:10:30.732647: train_loss -0.4261 
2025-08-08 12:10:30.734448: val_loss -0.4501 
2025-08-08 12:10:30.735317: Pseudo dice [np.float32(0.6053)] 
2025-08-08 12:10:30.736058: Epoch time: 18.25 s 
2025-08-08 12:10:30.736813: Yayy! New best EMA pseudo Dice: 0.5228000283241272 
2025-08-08 12:10:40.489671:  
2025-08-08 12:10:40.490422: Epoch 16 
2025-08-08 12:10:40.491147: Current learning rate: 0.00942 
2025-08-08 12:10:58.681854: train_loss -0.4435 
2025-08-08 12:10:58.683829: val_loss -0.2351 
2025-08-08 12:10:58.684767: Pseudo dice [np.float32(0.4401)] 
2025-08-08 12:10:58.685658: Epoch time: 18.2 s 
2025-08-08 12:10:59.942080:  
2025-08-08 12:10:59.943770: Epoch 17 
2025-08-08 12:10:59.944612: Current learning rate: 0.00939 
2025-08-08 12:11:17.853399: train_loss -0.4288 
2025-08-08 12:11:17.855632: val_loss -0.5514 
2025-08-08 12:11:17.856480: Pseudo dice [np.float32(0.677)] 
2025-08-08 12:11:17.857411: Epoch time: 17.92 s 
2025-08-08 12:11:17.858242: Yayy! New best EMA pseudo Dice: 0.5307999849319458 
2025-08-08 12:11:27.626364:  
2025-08-08 12:11:27.627304: Epoch 18 
2025-08-08 12:11:27.628130: Current learning rate: 0.00935 
2025-08-08 12:11:45.801980: train_loss -0.4465 
2025-08-08 12:11:45.803957: val_loss -0.543 
2025-08-08 12:11:45.804809: Pseudo dice [np.float32(0.6731)] 
2025-08-08 12:11:45.805634: Epoch time: 18.18 s 
2025-08-08 12:11:45.806445: Yayy! New best EMA pseudo Dice: 0.5450000166893005 
2025-08-08 12:11:55.580408:  
2025-08-08 12:11:55.581220: Epoch 19 
2025-08-08 12:11:55.582044: Current learning rate: 0.00931 
2025-08-08 12:12:13.809013: train_loss -0.4243 
2025-08-08 12:12:13.811058: val_loss -0.5037 
2025-08-08 12:12:13.811953: Pseudo dice [np.float32(0.6383)] 
2025-08-08 12:12:13.812869: Epoch time: 18.23 s 
2025-08-08 12:12:13.813669: Yayy! New best EMA pseudo Dice: 0.5544000267982483 
2025-08-08 12:12:23.633954:  
2025-08-08 12:12:23.634922: Epoch 20 
2025-08-08 12:12:23.635776: Current learning rate: 0.00928 
2025-08-08 12:12:41.745694: train_loss -0.4629 
2025-08-08 12:12:41.747790: val_loss -0.5382 
2025-08-08 12:12:41.748662: Pseudo dice [np.float32(0.6664)] 
2025-08-08 12:12:41.749560: Epoch time: 18.12 s 
2025-08-08 12:12:41.750398: Yayy! New best EMA pseudo Dice: 0.5655999779701233 
2025-08-08 12:12:51.514545:  
2025-08-08 12:12:51.515550: Epoch 21 
2025-08-08 12:12:51.516472: Current learning rate: 0.00924 
2025-08-08 12:13:09.724797: train_loss -0.4526 
2025-08-08 12:13:09.726921: val_loss -0.4583 
2025-08-08 12:13:09.727973: Pseudo dice [np.float32(0.6126)] 
2025-08-08 12:13:09.728871: Epoch time: 18.21 s 
2025-08-08 12:13:09.729677: Yayy! New best EMA pseudo Dice: 0.5702999830245972 
2025-08-08 12:13:19.753915:  
2025-08-08 12:13:19.754727: Epoch 22 
2025-08-08 12:13:19.755476: Current learning rate: 0.0092 
2025-08-08 12:13:37.912232: train_loss -0.4456 
2025-08-08 12:13:37.914289: val_loss -0.5646 
2025-08-08 12:13:37.915230: Pseudo dice [np.float32(0.6792)] 
2025-08-08 12:13:37.916173: Epoch time: 18.16 s 
2025-08-08 12:13:37.916977: Yayy! New best EMA pseudo Dice: 0.5812000036239624 
2025-08-08 12:13:47.823773:  
2025-08-08 12:13:47.824756: Epoch 23 
2025-08-08 12:13:47.825612: Current learning rate: 0.00917 
2025-08-08 12:14:05.988118: train_loss -0.543 
2025-08-08 12:14:05.990193: val_loss -0.4508 
2025-08-08 12:14:05.991066: Pseudo dice [np.float32(0.6109)] 
2025-08-08 12:14:05.991924: Epoch time: 18.17 s 
2025-08-08 12:14:05.992751: Yayy! New best EMA pseudo Dice: 0.5841000080108643 
2025-08-08 12:14:15.676647:  
2025-08-08 12:14:15.677670: Epoch 24 
2025-08-08 12:14:15.678715: Current learning rate: 0.00913 
2025-08-08 12:14:33.817697: train_loss -0.4876 
2025-08-08 12:14:33.819539: val_loss -0.4447 
2025-08-08 12:14:33.820805: Pseudo dice [np.float32(0.6076)] 
2025-08-08 12:14:33.821769: Epoch time: 18.14 s 
2025-08-08 12:14:33.822522: Yayy! New best EMA pseudo Dice: 0.5864999890327454 
2025-08-08 12:14:43.500427:  
2025-08-08 12:14:43.501555: Epoch 25 
2025-08-08 12:14:43.502361: Current learning rate: 0.0091 
2025-08-08 12:15:01.664434: train_loss -0.4921 
2025-08-08 12:15:01.666301: val_loss -0.5625 
2025-08-08 12:15:01.667078: Pseudo dice [np.float32(0.6767)] 
2025-08-08 12:15:01.667819: Epoch time: 18.17 s 
2025-08-08 12:15:01.668537: Yayy! New best EMA pseudo Dice: 0.5954999923706055 
2025-08-08 12:15:11.503000:  
2025-08-08 12:15:11.504271: Epoch 26 
2025-08-08 12:15:11.505105: Current learning rate: 0.00906 
2025-08-08 12:15:29.705768: train_loss -0.4372 
2025-08-08 12:15:29.708183: val_loss -0.2971 
2025-08-08 12:15:29.708993: Pseudo dice [np.float32(0.484)] 
2025-08-08 12:15:29.709710: Epoch time: 18.21 s 
2025-08-08 12:15:31.021995:  
2025-08-08 12:15:31.023516: Epoch 27 
2025-08-08 12:15:31.024365: Current learning rate: 0.00902 
2025-08-08 12:15:49.194243: train_loss -0.4724 
2025-08-08 12:15:49.196159: val_loss -0.5352 
2025-08-08 12:15:49.196998: Pseudo dice [np.float32(0.6663)] 
2025-08-08 12:15:49.197721: Epoch time: 18.18 s 
2025-08-08 12:15:50.436262:  
2025-08-08 12:15:50.437740: Epoch 28 
2025-08-08 12:15:50.438546: Current learning rate: 0.00899 
2025-08-08 12:16:10.290510: train_loss -0.5141 
2025-08-08 12:16:10.398283: val_loss -0.5882 
2025-08-08 12:16:10.433610: Pseudo dice [np.float32(0.7019)] 
2025-08-08 12:16:10.469449: Epoch time: 19.86 s 
2025-08-08 12:16:10.505050: Yayy! New best EMA pseudo Dice: 0.6035000085830688 
2025-08-08 12:16:23.445840:  
2025-08-08 12:16:23.446898: Epoch 29 
2025-08-08 12:16:23.447815: Current learning rate: 0.00895 
2025-08-08 12:16:44.382710: train_loss -0.4808 
2025-08-08 12:16:44.481903: val_loss -0.5719 
2025-08-08 12:16:44.521593: Pseudo dice [np.float32(0.6926)] 
2025-08-08 12:16:44.557636: Epoch time: 20.94 s 
2025-08-08 12:16:44.593016: Yayy! New best EMA pseudo Dice: 0.6123999953269958 
2025-08-08 12:16:54.897925:  
2025-08-08 12:16:54.898761: Epoch 30 
2025-08-08 12:16:54.899526: Current learning rate: 0.00891 
2025-08-08 12:17:14.903111: train_loss -0.4932 
2025-08-08 12:17:14.905061: val_loss -0.4516 
2025-08-08 12:17:14.905863: Pseudo dice [np.float32(0.5935)] 
2025-08-08 12:17:14.906673: Epoch time: 20.01 s 
2025-08-08 12:17:16.158734:  
2025-08-08 12:17:16.160288: Epoch 31 
2025-08-08 12:17:16.161070: Current learning rate: 0.00888 
2025-08-08 12:17:34.136568: train_loss -0.4715 
2025-08-08 12:17:34.138269: val_loss -0.3039 
2025-08-08 12:17:34.139129: Pseudo dice [np.float32(0.4829)] 
2025-08-08 12:17:34.139915: Epoch time: 17.98 s 
2025-08-08 12:17:35.531375:  
2025-08-08 12:17:35.765887: Epoch 32 
2025-08-08 12:17:35.801912: Current learning rate: 0.00884 
2025-08-08 12:17:53.972154: train_loss -0.4548 
2025-08-08 12:17:53.974217: val_loss -0.5427 
2025-08-08 12:17:53.975021: Pseudo dice [np.float32(0.6585)] 
2025-08-08 12:17:53.975874: Epoch time: 18.45 s 
2025-08-08 12:17:55.326014:  
2025-08-08 12:17:55.327466: Epoch 33 
2025-08-08 12:17:55.328188: Current learning rate: 0.0088 
2025-08-08 12:18:13.565840: train_loss -0.546 
2025-08-08 12:18:13.567989: val_loss -0.5114 
2025-08-08 12:18:13.568821: Pseudo dice [np.float32(0.6516)] 
2025-08-08 12:18:13.569569: Epoch time: 18.24 s 
2025-08-08 12:18:15.490215:  
2025-08-08 12:18:15.491675: Epoch 34 
2025-08-08 12:18:15.492381: Current learning rate: 0.00877 
2025-08-08 12:18:36.350350: train_loss -0.4781 
2025-08-08 12:18:36.459726: val_loss -0.562 
2025-08-08 12:18:36.495155: Pseudo dice [np.float32(0.6807)] 
2025-08-08 12:18:36.535312: Epoch time: 20.86 s 
2025-08-08 12:18:36.570963: Yayy! New best EMA pseudo Dice: 0.6158000230789185 
2025-08-08 12:18:46.404699:  
2025-08-08 12:18:46.405516: Epoch 35 
2025-08-08 12:18:46.406247: Current learning rate: 0.00873 
2025-08-08 12:19:06.469461: train_loss -0.5232 
2025-08-08 12:19:06.471422: val_loss -0.6205 
2025-08-08 12:19:06.472222: Pseudo dice [np.float32(0.7235)] 
2025-08-08 12:19:06.472998: Epoch time: 20.07 s 
2025-08-08 12:19:06.474105: Yayy! New best EMA pseudo Dice: 0.6266000270843506 
2025-08-08 12:19:16.113309:  
2025-08-08 12:19:16.114139: Epoch 36 
2025-08-08 12:19:16.114887: Current learning rate: 0.00869 
2025-08-08 12:19:34.052527: train_loss -0.5268 
2025-08-08 12:19:34.054610: val_loss -0.5527 
2025-08-08 12:19:34.055441: Pseudo dice [np.float32(0.6733)] 
2025-08-08 12:19:34.056240: Epoch time: 17.94 s 
2025-08-08 12:19:34.057052: Yayy! New best EMA pseudo Dice: 0.6312999725341797 
2025-08-08 12:19:43.850341:  
2025-08-08 12:19:43.851335: Epoch 37 
2025-08-08 12:19:43.852145: Current learning rate: 0.00866 
2025-08-08 12:20:01.812969: train_loss -0.514 
2025-08-08 12:20:01.814750: val_loss -0.534 
2025-08-08 12:20:01.815480: Pseudo dice [np.float32(0.6636)] 
2025-08-08 12:20:01.816246: Epoch time: 17.97 s 
2025-08-08 12:20:01.817075: Yayy! New best EMA pseudo Dice: 0.6345000267028809 
2025-08-08 12:20:11.610944:  
2025-08-08 12:20:11.611848: Epoch 38 
2025-08-08 12:20:11.612593: Current learning rate: 0.00862 
2025-08-08 12:20:29.575396: train_loss -0.5698 
2025-08-08 12:20:29.577236: val_loss -0.6167 
2025-08-08 12:20:29.577979: Pseudo dice [np.float32(0.7246)] 
2025-08-08 12:20:29.578687: Epoch time: 17.97 s 
2025-08-08 12:20:29.579394: Yayy! New best EMA pseudo Dice: 0.6434999704360962 
2025-08-08 12:20:39.291263:  
2025-08-08 12:20:39.292179: Epoch 39 
2025-08-08 12:20:39.292940: Current learning rate: 0.00858 
2025-08-08 12:20:57.385041: train_loss -0.5453 
2025-08-08 12:20:57.387039: val_loss -0.6291 
2025-08-08 12:20:57.388346: Pseudo dice [np.float32(0.7315)] 
2025-08-08 12:20:57.389138: Epoch time: 18.1 s 
2025-08-08 12:20:57.389983: Yayy! New best EMA pseudo Dice: 0.6523000001907349 
2025-08-08 12:21:07.167889:  
2025-08-08 12:21:07.168826: Epoch 40 
2025-08-08 12:21:07.169909: Current learning rate: 0.00855 
2025-08-08 12:21:25.323363: train_loss -0.5678 
2025-08-08 12:21:25.325457: val_loss -0.6285 
2025-08-08 12:21:25.326351: Pseudo dice [np.float32(0.7291)] 
2025-08-08 12:21:25.327295: Epoch time: 18.16 s 
2025-08-08 12:21:25.328166: Yayy! New best EMA pseudo Dice: 0.6600000262260437 
2025-08-08 12:21:35.125229:  
2025-08-08 12:21:35.126210: Epoch 41 
2025-08-08 12:21:35.127129: Current learning rate: 0.00851 
2025-08-08 12:21:53.416377: train_loss -0.5155 
2025-08-08 12:21:53.418341: val_loss -0.5572 
2025-08-08 12:21:53.419134: Pseudo dice [np.float32(0.6801)] 
2025-08-08 12:21:53.419952: Epoch time: 18.3 s 
2025-08-08 12:21:53.420695: Yayy! New best EMA pseudo Dice: 0.6620000004768372 
2025-08-08 12:22:03.126112:  
2025-08-08 12:22:03.126989: Epoch 42 
2025-08-08 12:22:03.127865: Current learning rate: 0.00847 
2025-08-08 12:22:21.351260: train_loss -0.5389 
2025-08-08 12:22:21.353029: val_loss -0.5998 
2025-08-08 12:22:21.353872: Pseudo dice [np.float32(0.7289)] 
2025-08-08 12:22:21.354714: Epoch time: 18.23 s 
2025-08-08 12:22:21.355465: Yayy! New best EMA pseudo Dice: 0.6686999797821045 
2025-08-08 12:22:31.084761:  
2025-08-08 12:22:31.085561: Epoch 43 
2025-08-08 12:22:31.086250: Current learning rate: 0.00844 
2025-08-08 12:22:49.272927: train_loss -0.5517 
2025-08-08 12:22:49.275328: val_loss -0.4333 
2025-08-08 12:22:49.276055: Pseudo dice [np.float32(0.5955)] 
2025-08-08 12:22:49.276839: Epoch time: 18.19 s 
2025-08-08 12:22:50.537322:  
2025-08-08 12:22:50.538800: Epoch 44 
2025-08-08 12:22:50.539575: Current learning rate: 0.0084 
2025-08-08 12:23:11.461396: train_loss -0.5513 
2025-08-08 12:23:11.560059: val_loss -0.5625 
2025-08-08 12:23:11.590930: Pseudo dice [np.float32(0.6883)] 
2025-08-08 12:23:11.622118: Epoch time: 20.93 s 
2025-08-08 12:23:13.022819:  
2025-08-08 12:23:13.193793: Epoch 45 
2025-08-08 12:23:13.278444: Current learning rate: 0.00836 
2025-08-08 12:23:31.288653: train_loss -0.5039 
2025-08-08 12:23:31.290568: val_loss -0.547 
2025-08-08 12:23:31.291467: Pseudo dice [np.float32(0.6916)] 
2025-08-08 12:23:31.292300: Epoch time: 18.27 s 
2025-08-08 12:23:32.644465:  
2025-08-08 12:23:32.646124: Epoch 46 
2025-08-08 12:23:32.647048: Current learning rate: 0.00833 
2025-08-08 12:23:50.847761: train_loss -0.5501 
2025-08-08 12:23:50.849889: val_loss -0.6537 
2025-08-08 12:23:50.850739: Pseudo dice [np.float32(0.7487)] 
2025-08-08 12:23:50.851494: Epoch time: 18.21 s 
2025-08-08 12:23:50.852284: Yayy! New best EMA pseudo Dice: 0.675000011920929 
2025-08-08 12:24:00.690971:  
2025-08-08 12:24:00.692640: Epoch 47 
2025-08-08 12:24:00.693544: Current learning rate: 0.00829 
2025-08-08 12:24:18.981594: train_loss -0.5601 
2025-08-08 12:24:18.983615: val_loss -0.5236 
2025-08-08 12:24:18.984401: Pseudo dice [np.float32(0.6704)] 
2025-08-08 12:24:18.985194: Epoch time: 18.29 s 
2025-08-08 12:24:20.306225:  
2025-08-08 12:24:20.307893: Epoch 48 
2025-08-08 12:24:20.308613: Current learning rate: 0.00825 
2025-08-08 12:24:38.463905: train_loss -0.5038 
2025-08-08 12:24:38.465602: val_loss -0.6156 
2025-08-08 12:24:38.466549: Pseudo dice [np.float32(0.7252)] 
2025-08-08 12:24:38.467366: Epoch time: 18.16 s 
2025-08-08 12:24:38.468197: Yayy! New best EMA pseudo Dice: 0.6796000003814697 
2025-08-08 12:24:48.175783:  
2025-08-08 12:24:48.176814: Epoch 49 
2025-08-08 12:24:48.177715: Current learning rate: 0.00822 
2025-08-08 12:25:06.383445: train_loss -0.5576 
2025-08-08 12:25:06.385215: val_loss -0.6202 
2025-08-08 12:25:06.385951: Pseudo dice [np.float32(0.7293)] 
2025-08-08 12:25:06.386720: Epoch time: 18.21 s 
2025-08-08 12:25:14.883597: Yayy! New best EMA pseudo Dice: 0.6845999956130981 
2025-08-08 12:25:24.964399:  
2025-08-08 12:25:24.966242: Epoch 50 
2025-08-08 12:25:24.968051: Current learning rate: 0.00818 
2025-08-08 12:25:43.475447: train_loss -0.5194 
2025-08-08 12:25:43.477196: val_loss -0.597 
2025-08-08 12:25:43.478097: Pseudo dice [np.float32(0.7151)] 
2025-08-08 12:25:43.478963: Epoch time: 18.51 s 
2025-08-08 12:25:43.479823: Yayy! New best EMA pseudo Dice: 0.6876000165939331 
2025-08-08 12:25:53.207191:  
2025-08-08 12:25:53.208237: Epoch 51 
2025-08-08 12:25:53.209179: Current learning rate: 0.00814 
2025-08-08 12:26:11.363432: train_loss -0.5363 
2025-08-08 12:26:11.365508: val_loss -0.5716 
2025-08-08 12:26:11.366318: Pseudo dice [np.float32(0.6881)] 
2025-08-08 12:26:11.367118: Epoch time: 18.16 s 
2025-08-08 12:26:11.367862: Yayy! New best EMA pseudo Dice: 0.6876999735832214 
2025-08-08 12:26:21.196613:  
2025-08-08 12:26:21.197473: Epoch 52 
2025-08-08 12:26:21.198260: Current learning rate: 0.00811 
2025-08-08 12:26:39.157594: train_loss -0.5548 
2025-08-08 12:26:39.159644: val_loss -0.4629 
2025-08-08 12:26:39.160573: Pseudo dice [np.float32(0.6035)] 
2025-08-08 12:26:39.161412: Epoch time: 17.96 s 
2025-08-08 12:26:40.474891:  
2025-08-08 12:26:40.476493: Epoch 53 
2025-08-08 12:26:40.477429: Current learning rate: 0.00807 
2025-08-08 12:26:58.432300: train_loss -0.5625 
2025-08-08 12:26:58.434226: val_loss -0.6219 
2025-08-08 12:26:58.435031: Pseudo dice [np.float32(0.7284)] 
2025-08-08 12:26:58.435907: Epoch time: 17.96 s 
2025-08-08 12:26:59.699761:  
2025-08-08 12:26:59.701251: Epoch 54 
2025-08-08 12:26:59.702024: Current learning rate: 0.00803 
2025-08-08 12:27:17.641759: train_loss -0.5419 
2025-08-08 12:27:17.643715: val_loss -0.6414 
2025-08-08 12:27:17.644460: Pseudo dice [np.float32(0.7396)] 
2025-08-08 12:27:17.645181: Epoch time: 17.95 s 
2025-08-08 12:27:17.645880: Yayy! New best EMA pseudo Dice: 0.6897000074386597 
2025-08-08 12:27:28.007473:  
2025-08-08 12:27:28.009348: Epoch 55 
2025-08-08 12:27:28.010172: Current learning rate: 0.008 
2025-08-08 12:27:45.965267: train_loss -0.5746 
2025-08-08 12:27:45.967237: val_loss -0.545 
2025-08-08 12:27:45.968043: Pseudo dice [np.float32(0.6717)] 
2025-08-08 12:27:45.968738: Epoch time: 17.96 s 
2025-08-08 12:27:47.265842:  
2025-08-08 12:27:47.268249: Epoch 56 
2025-08-08 12:27:47.269005: Current learning rate: 0.00796 
2025-08-08 12:28:05.244704: train_loss -0.5755 
2025-08-08 12:28:05.246668: val_loss -0.5951 
2025-08-08 12:28:05.247591: Pseudo dice [np.float32(0.7125)] 
2025-08-08 12:28:05.248439: Epoch time: 17.98 s 
2025-08-08 12:28:05.249335: Yayy! New best EMA pseudo Dice: 0.6904000043869019 
2025-08-08 12:28:14.950006:  
2025-08-08 12:28:14.951029: Epoch 57 
2025-08-08 12:28:14.951995: Current learning rate: 0.00792 
2025-08-08 12:28:32.962351: train_loss -0.6008 
2025-08-08 12:28:32.964930: val_loss -0.641 
2025-08-08 12:28:32.965822: Pseudo dice [np.float32(0.7478)] 
2025-08-08 12:28:32.966769: Epoch time: 18.02 s 
2025-08-08 12:28:32.967587: Yayy! New best EMA pseudo Dice: 0.6960999965667725 
2025-08-08 12:28:42.660804:  
2025-08-08 12:28:42.661798: Epoch 58 
2025-08-08 12:28:42.662643: Current learning rate: 0.00789 
2025-08-08 12:29:00.936389: train_loss -0.5699 
2025-08-08 12:29:00.938483: val_loss -0.5802 
2025-08-08 12:29:00.939228: Pseudo dice [np.float32(0.7043)] 
2025-08-08 12:29:00.939955: Epoch time: 18.28 s 
2025-08-08 12:29:00.940681: Yayy! New best EMA pseudo Dice: 0.6969000101089478 
2025-08-08 12:29:10.647124:  
2025-08-08 12:29:10.647981: Epoch 59 
2025-08-08 12:29:10.648697: Current learning rate: 0.00785 
2025-08-08 12:29:28.800480: train_loss -0.5774 
2025-08-08 12:29:28.802394: val_loss -0.591 
2025-08-08 12:29:28.803176: Pseudo dice [np.float32(0.7021)] 
2025-08-08 12:29:28.803961: Epoch time: 18.16 s 
2025-08-08 12:29:28.804696: Yayy! New best EMA pseudo Dice: 0.6974999904632568 
2025-08-08 12:29:38.610748:  
2025-08-08 12:29:38.611701: Epoch 60 
2025-08-08 12:29:38.612444: Current learning rate: 0.00781 
2025-08-08 12:29:56.844281: train_loss -0.5109 
2025-08-08 12:29:56.846303: val_loss -0.6202 
2025-08-08 12:29:56.847221: Pseudo dice [np.float32(0.7305)] 
2025-08-08 12:29:56.848116: Epoch time: 18.24 s 
2025-08-08 12:29:56.849111: Yayy! New best EMA pseudo Dice: 0.7008000016212463 
2025-08-08 12:30:06.492342:  
2025-08-08 12:30:06.493309: Epoch 61 
2025-08-08 12:30:06.494219: Current learning rate: 0.00777 
2025-08-08 12:30:24.751716: train_loss -0.5408 
2025-08-08 12:30:24.753633: val_loss -0.618 
2025-08-08 12:30:24.754410: Pseudo dice [np.float32(0.7186)] 
2025-08-08 12:30:24.755240: Epoch time: 18.26 s 
2025-08-08 12:30:24.755994: Yayy! New best EMA pseudo Dice: 0.7024999856948853 
2025-08-08 12:30:34.540328:  
2025-08-08 12:30:34.541177: Epoch 62 
2025-08-08 12:30:34.541956: Current learning rate: 0.00774 
2025-08-08 12:30:52.487515: train_loss -0.5911 
2025-08-08 12:30:52.489530: val_loss -0.6185 
2025-08-08 12:30:52.490355: Pseudo dice [np.float32(0.7276)] 
2025-08-08 12:30:52.491160: Epoch time: 17.95 s 
2025-08-08 12:30:52.491902: Yayy! New best EMA pseudo Dice: 0.7049999833106995 
2025-08-08 12:31:02.310886:  
2025-08-08 12:31:02.314169: Epoch 63 
2025-08-08 12:31:02.315577: Current learning rate: 0.0077 
2025-08-08 12:31:20.310552: train_loss -0.6086 
2025-08-08 12:31:20.312197: val_loss -0.5835 
2025-08-08 12:31:20.312982: Pseudo dice [np.float32(0.7144)] 
2025-08-08 12:31:20.313800: Epoch time: 18.0 s 
2025-08-08 12:31:20.314751: Yayy! New best EMA pseudo Dice: 0.7059999704360962 
2025-08-08 12:31:30.106604:  
2025-08-08 12:31:30.107494: Epoch 64 
2025-08-08 12:31:30.108319: Current learning rate: 0.00766 
2025-08-08 12:31:48.055962: train_loss -0.5768 
2025-08-08 12:31:48.057871: val_loss -0.5463 
2025-08-08 12:31:48.058863: Pseudo dice [np.float32(0.6628)] 
2025-08-08 12:31:48.059659: Epoch time: 17.95 s 
2025-08-08 12:31:49.394221:  
2025-08-08 12:31:49.395799: Epoch 65 
2025-08-08 12:31:49.396557: Current learning rate: 0.00763 
2025-08-08 12:32:07.359522: train_loss -0.5622 
2025-08-08 12:32:07.361425: val_loss -0.6087 
2025-08-08 12:32:07.362207: Pseudo dice [np.float32(0.7237)] 
2025-08-08 12:32:07.363003: Epoch time: 17.97 s 
2025-08-08 12:32:08.678993:  
2025-08-08 12:32:08.680443: Epoch 66 
2025-08-08 12:32:08.681330: Current learning rate: 0.00759 
2025-08-08 12:32:26.600245: train_loss -0.6064 
2025-08-08 12:32:26.602148: val_loss -0.4906 
2025-08-08 12:32:26.602906: Pseudo dice [np.float32(0.632)] 
2025-08-08 12:32:26.603651: Epoch time: 17.93 s 
2025-08-08 12:32:27.955906:  
2025-08-08 12:32:27.957335: Epoch 67 
2025-08-08 12:32:27.958088: Current learning rate: 0.00755 
2025-08-08 12:32:45.898611: train_loss -0.5519 
2025-08-08 12:32:45.900746: val_loss -0.5237 
2025-08-08 12:32:45.901713: Pseudo dice [np.float32(0.6621)] 
2025-08-08 12:32:45.902591: Epoch time: 17.95 s 
2025-08-08 12:32:47.218355:  
2025-08-08 12:32:47.220024: Epoch 68 
2025-08-08 12:32:47.220963: Current learning rate: 0.00751 
2025-08-08 12:33:05.175258: train_loss -0.5513 
2025-08-08 12:33:05.177378: val_loss -0.6068 
2025-08-08 12:33:05.178194: Pseudo dice [np.float32(0.7141)] 
2025-08-08 12:33:05.178913: Epoch time: 17.96 s 
2025-08-08 12:33:06.441594:  
2025-08-08 12:33:06.443068: Epoch 69 
2025-08-08 12:33:06.443843: Current learning rate: 0.00748 
2025-08-08 12:33:24.428893: train_loss -0.5491 
2025-08-08 12:33:24.430632: val_loss -0.6131 
2025-08-08 12:33:24.431347: Pseudo dice [np.float32(0.7253)] 
2025-08-08 12:33:24.432090: Epoch time: 17.99 s 
2025-08-08 12:33:25.709618:  
2025-08-08 12:33:25.711153: Epoch 70 
2025-08-08 12:33:25.711931: Current learning rate: 0.00744 
2025-08-08 12:33:43.663863: train_loss -0.5728 
2025-08-08 12:33:43.665775: val_loss -0.5143 
2025-08-08 12:33:43.666553: Pseudo dice [np.float32(0.645)] 
2025-08-08 12:33:43.667437: Epoch time: 17.96 s 
2025-08-08 12:33:45.009846:  
2025-08-08 12:33:45.011333: Epoch 71 
2025-08-08 12:33:45.012146: Current learning rate: 0.0074 
2025-08-08 12:34:02.944378: train_loss -0.5836 
2025-08-08 12:34:02.946186: val_loss -0.5688 
2025-08-08 12:34:02.946981: Pseudo dice [np.float32(0.6931)] 
2025-08-08 12:34:02.947713: Epoch time: 17.94 s 
2025-08-08 12:34:04.218830:  
2025-08-08 12:34:04.220280: Epoch 72 
2025-08-08 12:34:04.221058: Current learning rate: 0.00737 
2025-08-08 12:34:22.503582: train_loss -0.576 
2025-08-08 12:34:22.505618: val_loss -0.6266 
2025-08-08 12:34:22.506810: Pseudo dice [np.float32(0.7252)] 
2025-08-08 12:34:22.508056: Epoch time: 18.29 s 
2025-08-08 12:34:23.770693:  
2025-08-08 12:34:23.772246: Epoch 73 
2025-08-08 12:34:23.773038: Current learning rate: 0.00733 
2025-08-08 12:34:41.711817: train_loss -0.5774 
2025-08-08 12:34:41.713594: val_loss -0.546 
2025-08-08 12:34:41.714386: Pseudo dice [np.float32(0.6778)] 
2025-08-08 12:34:41.715206: Epoch time: 17.94 s 
2025-08-08 12:34:42.971511:  
2025-08-08 12:34:42.973083: Epoch 74 
2025-08-08 12:34:42.973859: Current learning rate: 0.00729 
2025-08-08 12:35:00.910385: train_loss -0.5852 
2025-08-08 12:35:00.912291: val_loss -0.6263 
2025-08-08 12:35:00.913100: Pseudo dice [np.float32(0.7219)] 
2025-08-08 12:35:00.913846: Epoch time: 17.94 s 
2025-08-08 12:35:02.832316:  
2025-08-08 12:35:02.833898: Epoch 75 
2025-08-08 12:35:02.834732: Current learning rate: 0.00725 
2025-08-08 12:35:22.579637: train_loss -0.5556 
2025-08-08 12:35:22.685144: val_loss -0.3604 
2025-08-08 12:35:22.724996: Pseudo dice [np.float32(0.5264)] 
2025-08-08 12:35:22.760743: Epoch time: 19.75 s 
2025-08-08 12:35:24.212688:  
2025-08-08 12:35:24.340084: Epoch 76 
2025-08-08 12:35:24.469702: Current learning rate: 0.00722 
2025-08-08 12:35:42.614407: train_loss -0.5763 
2025-08-08 12:35:42.616360: val_loss -0.6409 
2025-08-08 12:35:42.617112: Pseudo dice [np.float32(0.7389)] 
2025-08-08 12:35:42.617826: Epoch time: 18.41 s 
2025-08-08 12:35:43.970582:  
2025-08-08 12:35:43.972135: Epoch 77 
2025-08-08 12:35:43.972920: Current learning rate: 0.00718 
2025-08-08 12:36:01.918417: train_loss -0.6484 
2025-08-08 12:36:01.920348: val_loss -0.6241 
2025-08-08 12:36:01.921150: Pseudo dice [np.float32(0.7232)] 
2025-08-08 12:36:01.921946: Epoch time: 17.95 s 
2025-08-08 12:36:03.285955:  
2025-08-08 12:36:03.287503: Epoch 78 
2025-08-08 12:36:03.288354: Current learning rate: 0.00714 
2025-08-08 12:36:21.537144: train_loss -0.6387 
2025-08-08 12:36:21.538892: val_loss -0.6398 
2025-08-08 12:36:21.539651: Pseudo dice [np.float32(0.7317)] 
2025-08-08 12:36:21.540398: Epoch time: 18.26 s 
2025-08-08 12:36:22.825720:  
2025-08-08 12:36:22.827388: Epoch 79 
2025-08-08 12:36:22.828336: Current learning rate: 0.0071 
2025-08-08 12:36:40.776213: train_loss -0.6111 
2025-08-08 12:36:40.778230: val_loss -0.1431 
2025-08-08 12:36:40.779014: Pseudo dice [np.float32(0.3525)] 
2025-08-08 12:36:40.779784: Epoch time: 17.95 s 
2025-08-08 12:36:42.162270:  
2025-08-08 12:36:42.163793: Epoch 80 
2025-08-08 12:36:42.164557: Current learning rate: 0.00707 
2025-08-08 12:37:01.101575: train_loss -0.5275 
2025-08-08 12:37:01.103127: val_loss -0.5954 
2025-08-08 12:37:01.103868: Pseudo dice [np.float32(0.7142)] 
2025-08-08 12:37:01.104631: Epoch time: 18.94 s 
2025-08-08 12:37:02.431458:  
2025-08-08 12:37:02.433148: Epoch 81 
2025-08-08 12:37:02.433915: Current learning rate: 0.00703 
2025-08-08 12:37:20.408512: train_loss -0.6303 
2025-08-08 12:37:20.410019: val_loss -0.6383 
2025-08-08 12:37:20.410787: Pseudo dice [np.float32(0.7397)] 
2025-08-08 12:37:20.411557: Epoch time: 17.98 s 
2025-08-08 12:37:21.714979:  
2025-08-08 12:37:21.716143: Epoch 82 
2025-08-08 12:37:21.716888: Current learning rate: 0.00699 
2025-08-08 12:37:39.684051: train_loss -0.6045 
2025-08-08 12:37:39.685743: val_loss -0.6759 
2025-08-08 12:37:39.686667: Pseudo dice [np.float32(0.7668)] 
2025-08-08 12:37:39.687501: Epoch time: 17.97 s 
2025-08-08 12:37:40.905515:  
2025-08-08 12:37:40.906813: Epoch 83 
2025-08-08 12:37:40.907679: Current learning rate: 0.00696 
2025-08-08 12:37:58.887621: train_loss -0.5979 
2025-08-08 12:37:58.889349: val_loss -0.6507 
2025-08-08 12:37:58.890208: Pseudo dice [np.float32(0.7452)] 
2025-08-08 12:37:58.891024: Epoch time: 17.99 s 
2025-08-08 12:38:00.387334:  
2025-08-08 12:38:00.625708: Epoch 84 
2025-08-08 12:38:00.661501: Current learning rate: 0.00692 
2025-08-08 12:38:18.855016: train_loss -0.5831 
2025-08-08 12:38:18.856971: val_loss -0.5688 
2025-08-08 12:38:18.857836: Pseudo dice [np.float32(0.6792)] 
2025-08-08 12:38:18.858637: Epoch time: 18.47 s 
2025-08-08 12:38:20.167559:  
2025-08-08 12:38:20.169077: Epoch 85 
2025-08-08 12:38:20.169866: Current learning rate: 0.00688 
2025-08-08 12:38:38.502781: train_loss -0.5638 
2025-08-08 12:38:38.504726: val_loss -0.6067 
2025-08-08 12:38:38.505546: Pseudo dice [np.float32(0.7215)] 
2025-08-08 12:38:38.506335: Epoch time: 18.34 s 
2025-08-08 12:38:39.826714:  
2025-08-08 12:38:39.828472: Epoch 86 
2025-08-08 12:38:39.829255: Current learning rate: 0.00684 
2025-08-08 12:38:57.787356: train_loss -0.6264 
2025-08-08 12:38:57.789215: val_loss -0.5916 
2025-08-08 12:38:57.790018: Pseudo dice [np.float32(0.7067)] 
2025-08-08 12:38:57.790748: Epoch time: 17.96 s 
2025-08-08 12:38:59.092188:  
2025-08-08 12:38:59.093648: Epoch 87 
2025-08-08 12:38:59.094488: Current learning rate: 0.0068 
2025-08-08 12:39:20.076926: train_loss -0.5949 
2025-08-08 12:39:20.185256: val_loss -0.6606 
2025-08-08 12:39:20.220720: Pseudo dice [np.float32(0.7536)] 
2025-08-08 12:39:20.251976: Epoch time: 20.99 s 
2025-08-08 12:39:21.624594:  
2025-08-08 12:39:21.627163: Epoch 88 
2025-08-08 12:39:21.627923: Current learning rate: 0.00677 
2025-08-08 12:39:39.568270: train_loss -0.6433 
2025-08-08 12:39:39.570178: val_loss -0.6464 
2025-08-08 12:39:39.571001: Pseudo dice [np.float32(0.7459)] 
2025-08-08 12:39:39.571811: Epoch time: 17.95 s 
2025-08-08 12:39:40.946483:  
2025-08-08 12:39:40.947945: Epoch 89 
2025-08-08 12:39:40.948694: Current learning rate: 0.00673 
2025-08-08 12:39:59.223811: train_loss -0.6278 
2025-08-08 12:39:59.225891: val_loss -0.6041 
2025-08-08 12:39:59.226698: Pseudo dice [np.float32(0.7143)] 
2025-08-08 12:39:59.227499: Epoch time: 18.28 s 
2025-08-08 12:40:00.512508:  
2025-08-08 12:40:00.514013: Epoch 90 
2025-08-08 12:40:00.514777: Current learning rate: 0.00669 
2025-08-08 12:40:18.472197: train_loss -0.5991 
2025-08-08 12:40:18.474056: val_loss -0.4958 
2025-08-08 12:40:18.474848: Pseudo dice [np.float32(0.6198)] 
2025-08-08 12:40:18.475569: Epoch time: 17.96 s 
2025-08-08 12:40:19.817447:  
2025-08-08 12:40:19.818911: Epoch 91 
2025-08-08 12:40:19.819703: Current learning rate: 0.00665 
2025-08-08 12:40:38.130649: train_loss -0.5494 
2025-08-08 12:40:38.132173: val_loss -0.6284 
2025-08-08 12:40:38.132966: Pseudo dice [np.float32(0.7395)] 
2025-08-08 12:40:38.133690: Epoch time: 18.32 s 
2025-08-08 12:40:39.380969:  
2025-08-08 12:40:39.382635: Epoch 92 
2025-08-08 12:40:39.383622: Current learning rate: 0.00662 
2025-08-08 12:40:57.346397: train_loss -0.5961 
2025-08-08 12:40:57.348238: val_loss -0.6089 
2025-08-08 12:40:57.349179: Pseudo dice [np.float32(0.7126)] 
2025-08-08 12:40:57.349964: Epoch time: 17.97 s 
2025-08-08 12:40:58.736125:  
2025-08-08 12:40:58.979335: Epoch 93 
2025-08-08 12:40:59.010522: Current learning rate: 0.00658 
2025-08-08 12:41:17.170530: train_loss -0.6017 
2025-08-08 12:41:17.172499: val_loss -0.6001 
2025-08-08 12:41:17.173278: Pseudo dice [np.float32(0.7028)] 
2025-08-08 12:41:17.174091: Epoch time: 18.44 s 
2025-08-08 12:41:18.440912:  
2025-08-08 12:41:18.442339: Epoch 94 
2025-08-08 12:41:18.443123: Current learning rate: 0.00654 
2025-08-08 12:41:36.409104: train_loss -0.6396 
2025-08-08 12:41:36.410923: val_loss -0.6225 
2025-08-08 12:41:36.411684: Pseudo dice [np.float32(0.7325)] 
2025-08-08 12:41:36.412387: Epoch time: 17.97 s 
2025-08-08 12:41:38.370990:  
2025-08-08 12:41:38.372421: Epoch 95 
2025-08-08 12:41:38.373240: Current learning rate: 0.0065 
2025-08-08 12:41:56.674889: train_loss -0.6486 
2025-08-08 12:41:56.676876: val_loss -0.6355 
2025-08-08 12:41:56.677640: Pseudo dice [np.float32(0.7387)] 
2025-08-08 12:41:56.678518: Epoch time: 18.31 s 
2025-08-08 12:41:56.679307: Yayy! New best EMA pseudo Dice: 0.7081000208854675 
2025-08-08 12:42:06.490514:  
2025-08-08 12:42:06.491481: Epoch 96 
2025-08-08 12:42:06.492372: Current learning rate: 0.00647 
2025-08-08 12:42:24.821123: train_loss -0.636 
2025-08-08 12:42:24.823242: val_loss -0.5663 
2025-08-08 12:42:24.824029: Pseudo dice [np.float32(0.6709)] 
2025-08-08 12:42:24.824818: Epoch time: 18.33 s 
2025-08-08 12:42:26.160276:  
2025-08-08 12:42:26.161746: Epoch 97 
2025-08-08 12:42:26.162549: Current learning rate: 0.00643 
2025-08-08 12:42:47.020292: train_loss -0.63 
2025-08-08 12:42:47.117477: val_loss -0.5638 
2025-08-08 12:42:47.192870: Pseudo dice [np.float32(0.6724)] 
2025-08-08 12:42:47.228557: Epoch time: 20.86 s 
2025-08-08 12:42:48.604786:  
2025-08-08 12:42:48.607366: Epoch 98 
2025-08-08 12:42:48.608146: Current learning rate: 0.00639 
2025-08-08 12:43:06.640229: train_loss -0.6058 
2025-08-08 12:43:06.641990: val_loss -0.6774 
2025-08-08 12:43:06.642757: Pseudo dice [np.float32(0.7686)] 
2025-08-08 12:43:06.643567: Epoch time: 18.04 s 
2025-08-08 12:43:07.892655:  
2025-08-08 12:43:07.894140: Epoch 99 
2025-08-08 12:43:07.894925: Current learning rate: 0.00635 
2025-08-08 12:43:25.908344: train_loss -0.6125 
2025-08-08 12:43:25.909984: val_loss -0.6291 
2025-08-08 12:43:25.910803: Pseudo dice [np.float32(0.7379)] 
2025-08-08 12:43:25.911645: Epoch time: 18.02 s 
2025-08-08 12:43:41.523540: Yayy! New best EMA pseudo Dice: 0.7109000086784363 
2025-08-08 12:43:51.177497:  
2025-08-08 12:43:51.178505: Epoch 100 
2025-08-08 12:43:51.179348: Current learning rate: 0.00631 
2025-08-08 12:44:09.140568: train_loss -0.5754 
2025-08-08 12:44:09.142688: val_loss -0.5619 
2025-08-08 12:44:09.143669: Pseudo dice [np.float32(0.6892)] 
2025-08-08 12:44:09.144575: Epoch time: 17.97 s 
2025-08-08 12:44:10.484073:  
2025-08-08 12:44:10.485683: Epoch 101 
2025-08-08 12:44:10.486545: Current learning rate: 0.00628 
2025-08-08 12:44:28.452396: train_loss -0.6385 
2025-08-08 12:44:28.454493: val_loss -0.618 
2025-08-08 12:44:28.455354: Pseudo dice [np.float32(0.7224)] 
2025-08-08 12:44:28.456147: Epoch time: 17.97 s 
2025-08-08 12:44:29.779979:  
2025-08-08 12:44:29.781660: Epoch 102 
2025-08-08 12:44:29.782521: Current learning rate: 0.00624 
2025-08-08 12:44:48.801589: train_loss -0.6424 
2025-08-08 12:44:48.803093: val_loss -0.6498 
2025-08-08 12:44:48.803866: Pseudo dice [np.float32(0.751)] 
2025-08-08 12:44:48.804607: Epoch time: 19.03 s 
2025-08-08 12:44:48.805343: Yayy! New best EMA pseudo Dice: 0.7142000198364258 
2025-08-08 12:44:58.562560:  
2025-08-08 12:44:58.563398: Epoch 103 
2025-08-08 12:44:58.564119: Current learning rate: 0.0062 
2025-08-08 12:45:16.516470: train_loss -0.6271 
2025-08-08 12:45:16.519112: val_loss -0.6802 
2025-08-08 12:45:16.520018: Pseudo dice [np.float32(0.7573)] 
2025-08-08 12:45:16.520892: Epoch time: 17.96 s 
2025-08-08 12:45:16.521759: Yayy! New best EMA pseudo Dice: 0.718500018119812 
2025-08-08 12:45:26.565353:  
2025-08-08 12:45:26.566297: Epoch 104 
2025-08-08 12:45:26.567191: Current learning rate: 0.00616 
2025-08-08 12:45:44.529792: train_loss -0.6103 
2025-08-08 12:45:44.531749: val_loss -0.6766 
2025-08-08 12:45:44.532554: Pseudo dice [np.float32(0.7655)] 
2025-08-08 12:45:44.533314: Epoch time: 17.97 s 
2025-08-08 12:45:44.534105: Yayy! New best EMA pseudo Dice: 0.7232000231742859 
2025-08-08 12:45:54.277691:  
2025-08-08 12:45:54.278525: Epoch 105 
2025-08-08 12:45:54.279270: Current learning rate: 0.00612 
2025-08-08 12:46:12.272047: train_loss -0.6437 
2025-08-08 12:46:12.274197: val_loss -0.659 
2025-08-08 12:46:12.274964: Pseudo dice [np.float32(0.7562)] 
2025-08-08 12:46:12.276057: Epoch time: 18.0 s 
2025-08-08 12:46:12.276973: Yayy! New best EMA pseudo Dice: 0.7264999747276306 
2025-08-08 12:46:22.013122:  
2025-08-08 12:46:22.014070: Epoch 106 
2025-08-08 12:46:22.014890: Current learning rate: 0.00609 
2025-08-08 12:46:39.960679: train_loss -0.6561 
2025-08-08 12:46:39.962586: val_loss -0.6315 
2025-08-08 12:46:39.963387: Pseudo dice [np.float32(0.74)] 
2025-08-08 12:46:39.964149: Epoch time: 17.95 s 
2025-08-08 12:46:39.965211: Yayy! New best EMA pseudo Dice: 0.7279000282287598 
2025-08-08 12:46:49.672510:  
2025-08-08 12:46:49.674139: Epoch 107 
2025-08-08 12:46:49.675032: Current learning rate: 0.00605 
2025-08-08 12:47:07.647052: train_loss -0.6755 
2025-08-08 12:47:07.648590: val_loss -0.6563 
2025-08-08 12:47:07.649506: Pseudo dice [np.float32(0.7558)] 
2025-08-08 12:47:07.650296: Epoch time: 17.98 s 
2025-08-08 12:47:07.651105: Yayy! New best EMA pseudo Dice: 0.7307000160217285 
2025-08-08 12:47:17.594522:  
2025-08-08 12:47:17.595420: Epoch 108 
2025-08-08 12:47:17.596226: Current learning rate: 0.00601 
2025-08-08 12:47:35.607961: train_loss -0.6397 
2025-08-08 12:47:35.609954: val_loss -0.5639 
2025-08-08 12:47:35.610752: Pseudo dice [np.float32(0.675)] 
2025-08-08 12:47:35.611676: Epoch time: 18.02 s 
2025-08-08 12:47:36.988758:  
2025-08-08 12:47:36.990249: Epoch 109 
2025-08-08 12:47:36.991051: Current learning rate: 0.00597 
2025-08-08 12:47:54.947295: train_loss -0.6365 
2025-08-08 12:47:54.949502: val_loss -0.617 
2025-08-08 12:47:54.950346: Pseudo dice [np.float32(0.7173)] 
2025-08-08 12:47:54.951199: Epoch time: 17.96 s 
2025-08-08 12:47:56.238367:  
2025-08-08 12:47:56.240045: Epoch 110 
2025-08-08 12:47:56.240895: Current learning rate: 0.00593 
2025-08-08 12:48:14.183985: train_loss -0.6537 
2025-08-08 12:48:14.185856: val_loss -0.6841 
2025-08-08 12:48:14.186678: Pseudo dice [np.float32(0.7692)] 
2025-08-08 12:48:14.187468: Epoch time: 17.95 s 
2025-08-08 12:48:15.559799:  
2025-08-08 12:48:15.561343: Epoch 111 
2025-08-08 12:48:15.562179: Current learning rate: 0.0059 
2025-08-08 12:48:33.535522: train_loss -0.6348 
2025-08-08 12:48:33.537407: val_loss -0.6635 
2025-08-08 12:48:33.538168: Pseudo dice [np.float32(0.7588)] 
2025-08-08 12:48:33.538883: Epoch time: 17.98 s 
2025-08-08 12:48:33.539611: Yayy! New best EMA pseudo Dice: 0.7318000197410583 
2025-08-08 12:48:43.212228:  
2025-08-08 12:48:43.213033: Epoch 112 
2025-08-08 12:48:43.213762: Current learning rate: 0.00586 
2025-08-08 12:49:01.525838: train_loss -0.6925 
2025-08-08 12:49:01.527648: val_loss -0.67 
2025-08-08 12:49:01.528430: Pseudo dice [np.float32(0.7676)] 
2025-08-08 12:49:01.529249: Epoch time: 18.32 s 
2025-08-08 12:49:01.529981: Yayy! New best EMA pseudo Dice: 0.7354000210762024 
2025-08-08 12:49:11.327806:  
2025-08-08 12:49:11.328607: Epoch 113 
2025-08-08 12:49:11.329337: Current learning rate: 0.00582 
2025-08-08 12:49:29.522603: train_loss -0.6583 
2025-08-08 12:49:29.524597: val_loss -0.669 
2025-08-08 12:49:29.525381: Pseudo dice [np.float32(0.7676)] 
2025-08-08 12:49:29.526151: Epoch time: 18.2 s 
2025-08-08 12:49:29.526879: Yayy! New best EMA pseudo Dice: 0.7386000156402588 
2025-08-08 12:49:39.951984:  
2025-08-08 12:49:39.953005: Epoch 114 
2025-08-08 12:49:39.953850: Current learning rate: 0.00578 
2025-08-08 12:49:57.959416: train_loss -0.6586 
2025-08-08 12:49:57.961375: val_loss -0.6596 
2025-08-08 12:49:57.962302: Pseudo dice [np.float32(0.7535)] 
2025-08-08 12:49:57.963136: Epoch time: 18.01 s 
2025-08-08 12:49:57.963882: Yayy! New best EMA pseudo Dice: 0.7401000261306763 
2025-08-08 12:50:07.829196:  
2025-08-08 12:50:07.830063: Epoch 115 
2025-08-08 12:50:07.830904: Current learning rate: 0.00574 
2025-08-08 12:50:25.805952: train_loss -0.6596 
2025-08-08 12:50:25.807633: val_loss -0.6393 
2025-08-08 12:50:25.808476: Pseudo dice [np.float32(0.7517)] 
2025-08-08 12:50:25.809332: Epoch time: 17.98 s 
2025-08-08 12:50:25.810109: Yayy! New best EMA pseudo Dice: 0.7411999702453613 
2025-08-08 12:50:35.676261:  
2025-08-08 12:50:35.677204: Epoch 116 
2025-08-08 12:50:35.678034: Current learning rate: 0.0057 
2025-08-08 12:50:53.678474: train_loss -0.6774 
2025-08-08 12:50:53.680418: val_loss -0.5436 
2025-08-08 12:50:53.681264: Pseudo dice [np.float32(0.665)] 
2025-08-08 12:50:53.682037: Epoch time: 18.01 s 
2025-08-08 12:50:54.949941:  
2025-08-08 12:50:54.951418: Epoch 117 
2025-08-08 12:50:54.952191: Current learning rate: 0.00567 
2025-08-08 12:51:12.911962: train_loss -0.654 
2025-08-08 12:51:12.913870: val_loss -0.5166 
2025-08-08 12:51:12.914656: Pseudo dice [np.float32(0.6362)] 
2025-08-08 12:51:12.915387: Epoch time: 17.97 s 
2025-08-08 12:51:14.235747:  
2025-08-08 12:51:14.237294: Epoch 118 
2025-08-08 12:51:14.238060: Current learning rate: 0.00563 
2025-08-08 12:51:32.443261: train_loss -0.6726 
2025-08-08 12:51:32.445270: val_loss -0.614 
2025-08-08 12:51:32.446112: Pseudo dice [np.float32(0.7317)] 
2025-08-08 12:51:32.446909: Epoch time: 18.21 s 
2025-08-08 12:51:33.775431:  
2025-08-08 12:51:33.776941: Epoch 119 
2025-08-08 12:51:33.777691: Current learning rate: 0.00559 
2025-08-08 12:51:54.497249: train_loss -0.666 
2025-08-08 12:51:54.604079: val_loss -0.6402 
2025-08-08 12:51:54.643806: Pseudo dice [np.float32(0.7426)] 
2025-08-08 12:51:54.679907: Epoch time: 20.73 s 
2025-08-08 12:51:56.154100:  
2025-08-08 12:51:56.264393: Epoch 120 
2025-08-08 12:51:56.304483: Current learning rate: 0.00555 
2025-08-08 12:52:14.484665: train_loss -0.6355 
2025-08-08 12:52:14.486564: val_loss -0.6651 
2025-08-08 12:52:14.487339: Pseudo dice [np.float32(0.7574)] 
2025-08-08 12:52:14.488147: Epoch time: 18.33 s 
2025-08-08 12:52:15.767673:  
2025-08-08 12:52:15.769217: Epoch 121 
2025-08-08 12:52:15.769961: Current learning rate: 0.00551 
2025-08-08 12:52:34.011789: train_loss -0.6273 
2025-08-08 12:52:34.013633: val_loss -0.6471 
2025-08-08 12:52:34.014444: Pseudo dice [np.float32(0.7513)] 
2025-08-08 12:52:34.015580: Epoch time: 18.25 s 
2025-08-08 12:52:35.289955:  
2025-08-08 12:52:35.291476: Epoch 122 
2025-08-08 12:52:35.292286: Current learning rate: 0.00547 
2025-08-08 12:52:53.283808: train_loss -0.6797 
2025-08-08 12:52:53.285673: val_loss -0.6807 
2025-08-08 12:52:53.286508: Pseudo dice [np.float32(0.7698)] 
2025-08-08 12:52:53.287254: Epoch time: 18.0 s 
2025-08-08 12:52:54.650975:  
2025-08-08 12:52:54.652583: Epoch 123 
2025-08-08 12:52:54.653349: Current learning rate: 0.00544 
2025-08-08 12:53:12.659813: train_loss -0.6346 
2025-08-08 12:53:12.661769: val_loss -0.536 
2025-08-08 12:53:12.662505: Pseudo dice [np.float32(0.6726)] 
2025-08-08 12:53:12.663300: Epoch time: 18.01 s 
2025-08-08 12:53:13.945403:  
2025-08-08 12:53:13.946990: Epoch 124 
2025-08-08 12:53:13.947697: Current learning rate: 0.0054 
2025-08-08 12:53:31.944065: train_loss -0.639 
2025-08-08 12:53:31.945901: val_loss -0.5894 
2025-08-08 12:53:31.946877: Pseudo dice [np.float32(0.7107)] 
2025-08-08 12:53:31.947650: Epoch time: 18.0 s 
2025-08-08 12:53:33.223650:  
2025-08-08 12:53:33.225165: Epoch 125 
2025-08-08 12:53:33.225910: Current learning rate: 0.00536 
2025-08-08 12:53:51.231696: train_loss -0.6476 
2025-08-08 12:53:51.233760: val_loss -0.6625 
2025-08-08 12:53:51.234620: Pseudo dice [np.float32(0.7614)] 
2025-08-08 12:53:51.235466: Epoch time: 18.01 s 
2025-08-08 12:53:52.485799:  
2025-08-08 12:53:52.487375: Epoch 126 
2025-08-08 12:53:52.488210: Current learning rate: 0.00532 
2025-08-08 12:54:11.324069: train_loss -0.6776 
2025-08-08 12:54:11.325765: val_loss -0.6567 
2025-08-08 12:54:11.326640: Pseudo dice [np.float32(0.7545)] 
2025-08-08 12:54:11.327475: Epoch time: 18.84 s 
2025-08-08 12:54:12.632852:  
2025-08-08 12:54:12.634631: Epoch 127 
2025-08-08 12:54:12.635469: Current learning rate: 0.00528 
2025-08-08 12:54:30.611881: train_loss -0.6741 
2025-08-08 12:54:30.613593: val_loss -0.6462 
2025-08-08 12:54:30.614425: Pseudo dice [np.float32(0.7446)] 
2025-08-08 12:54:30.615202: Epoch time: 17.98 s 
2025-08-08 12:54:31.918963:  
2025-08-08 12:54:32.145259: Epoch 128 
2025-08-08 12:54:32.181242: Current learning rate: 0.00524 
2025-08-08 12:54:50.395331: train_loss -0.6729 
2025-08-08 12:54:50.397243: val_loss -0.5897 
2025-08-08 12:54:50.398109: Pseudo dice [np.float32(0.7159)] 
2025-08-08 12:54:50.398903: Epoch time: 18.48 s 
2025-08-08 12:54:51.664610:  
2025-08-08 12:54:51.666079: Epoch 129 
2025-08-08 12:54:51.666956: Current learning rate: 0.0052 
2025-08-08 12:55:09.625760: train_loss -0.6657 
2025-08-08 12:55:09.627666: val_loss -0.6346 
2025-08-08 12:55:09.628524: Pseudo dice [np.float32(0.7417)] 
2025-08-08 12:55:09.629341: Epoch time: 17.96 s 
2025-08-08 12:55:10.990195:  
2025-08-08 12:55:10.991683: Epoch 130 
2025-08-08 12:55:10.992484: Current learning rate: 0.00517 
2025-08-08 12:55:29.157229: train_loss -0.6285 
2025-08-08 12:55:29.159094: val_loss -0.6684 
2025-08-08 12:55:29.159935: Pseudo dice [np.float32(0.766)] 
2025-08-08 12:55:29.160700: Epoch time: 18.17 s 
2025-08-08 12:55:30.444247:  
2025-08-08 12:55:30.445776: Epoch 131 
2025-08-08 12:55:30.446569: Current learning rate: 0.00513 
2025-08-08 12:55:48.413008: train_loss -0.6443 
2025-08-08 12:55:48.414996: val_loss -0.6088 
2025-08-08 12:55:48.415826: Pseudo dice [np.float32(0.7209)] 
2025-08-08 12:55:48.416631: Epoch time: 17.97 s 
2025-08-08 12:55:49.703897:  
2025-08-08 12:55:49.705444: Epoch 132 
2025-08-08 12:55:49.706260: Current learning rate: 0.00509 
2025-08-08 12:56:07.664607: train_loss -0.6366 
2025-08-08 12:56:07.666726: val_loss -0.6435 
2025-08-08 12:56:07.667600: Pseudo dice [np.float32(0.7481)] 
2025-08-08 12:56:07.668451: Epoch time: 17.96 s 
2025-08-08 12:56:09.036064:  
2025-08-08 12:56:09.037724: Epoch 133 
2025-08-08 12:56:09.038656: Current learning rate: 0.00505 
2025-08-08 12:56:29.948602: train_loss -0.6483 
2025-08-08 12:56:30.058159: val_loss -0.6758 
2025-08-08 12:56:30.089310: Pseudo dice [np.float32(0.7696)] 
2025-08-08 12:56:30.120477: Epoch time: 20.92 s 
2025-08-08 12:56:32.200170:  
2025-08-08 12:56:32.387406: Epoch 134 
2025-08-08 12:56:32.388257: Current learning rate: 0.00501 
2025-08-08 12:56:50.382097: train_loss -0.6461 
2025-08-08 12:56:50.384101: val_loss -0.6783 
2025-08-08 12:56:50.384986: Pseudo dice [np.float32(0.7682)] 
2025-08-08 12:56:50.385760: Epoch time: 18.19 s 
2025-08-08 12:56:50.386476: Yayy! New best EMA pseudo Dice: 0.7425000071525574 
2025-08-08 12:57:00.186721:  
2025-08-08 12:57:00.187574: Epoch 135 
2025-08-08 12:57:00.188317: Current learning rate: 0.00497 
2025-08-08 12:57:18.151107: train_loss -0.6809 
2025-08-08 12:57:18.153047: val_loss -0.6955 
2025-08-08 12:57:18.153809: Pseudo dice [np.float32(0.7848)] 
2025-08-08 12:57:18.154579: Epoch time: 17.97 s 
2025-08-08 12:57:18.155369: Yayy! New best EMA pseudo Dice: 0.7468000054359436 
2025-08-08 12:57:27.909093:  
2025-08-08 12:57:27.910061: Epoch 136 
2025-08-08 12:57:27.910923: Current learning rate: 0.00493 
2025-08-08 12:57:45.915224: train_loss -0.7011 
2025-08-08 12:57:45.917168: val_loss -0.6636 
2025-08-08 12:57:45.918004: Pseudo dice [np.float32(0.7603)] 
2025-08-08 12:57:45.918737: Epoch time: 18.01 s 
2025-08-08 12:57:45.919453: Yayy! New best EMA pseudo Dice: 0.7480999827384949 
2025-08-08 12:57:55.655123:  
2025-08-08 12:57:55.656031: Epoch 137 
2025-08-08 12:57:55.656791: Current learning rate: 0.00489 
2025-08-08 12:58:13.630468: train_loss -0.6651 
2025-08-08 12:58:13.632091: val_loss -0.6293 
2025-08-08 12:58:13.632920: Pseudo dice [np.float32(0.7495)] 
2025-08-08 12:58:13.633681: Epoch time: 17.98 s 
2025-08-08 12:58:13.634458: Yayy! New best EMA pseudo Dice: 0.7483000159263611 
2025-08-08 12:58:23.468516:  
2025-08-08 12:58:23.469458: Epoch 138 
2025-08-08 12:58:23.470278: Current learning rate: 0.00485 
2025-08-08 12:58:41.467863: train_loss -0.68 
2025-08-08 12:58:41.469715: val_loss -0.6897 
2025-08-08 12:58:41.470472: Pseudo dice [np.float32(0.7789)] 
2025-08-08 12:58:41.471162: Epoch time: 18.0 s 
2025-08-08 12:58:41.471839: Yayy! New best EMA pseudo Dice: 0.7512999773025513 
2025-08-08 12:58:51.251021:  
2025-08-08 12:58:51.251957: Epoch 139 
2025-08-08 12:58:51.252719: Current learning rate: 0.00482 
2025-08-08 12:59:09.214039: train_loss -0.6659 
2025-08-08 12:59:09.215991: val_loss -0.6662 
2025-08-08 12:59:09.216846: Pseudo dice [np.float32(0.7678)] 
2025-08-08 12:59:09.217760: Epoch time: 17.97 s 
2025-08-08 12:59:09.218542: Yayy! New best EMA pseudo Dice: 0.753000020980835 
2025-08-08 12:59:19.092828:  
2025-08-08 12:59:19.093720: Epoch 140 
2025-08-08 12:59:19.094477: Current learning rate: 0.00478 
2025-08-08 12:59:37.063616: train_loss -0.6555 
2025-08-08 12:59:37.065918: val_loss -0.6111 
2025-08-08 12:59:37.066820: Pseudo dice [np.float32(0.7268)] 
2025-08-08 12:59:37.067679: Epoch time: 17.97 s 
2025-08-08 12:59:38.405195:  
2025-08-08 12:59:38.406814: Epoch 141 
2025-08-08 12:59:38.407692: Current learning rate: 0.00474 
2025-08-08 12:59:56.352046: train_loss -0.6437 
2025-08-08 12:59:56.353961: val_loss -0.6524 
2025-08-08 12:59:56.354800: Pseudo dice [np.float32(0.7556)] 
2025-08-08 12:59:56.355628: Epoch time: 17.95 s 
2025-08-08 12:59:57.648798:  
2025-08-08 12:59:57.650416: Epoch 142 
2025-08-08 12:59:57.651203: Current learning rate: 0.0047 
2025-08-08 13:00:15.625059: train_loss -0.6723 
2025-08-08 13:00:15.627466: val_loss -0.6008 
2025-08-08 13:00:15.628237: Pseudo dice [np.float32(0.7222)] 
2025-08-08 13:00:15.629002: Epoch time: 17.98 s 
2025-08-08 13:00:16.917879:  
2025-08-08 13:00:16.919398: Epoch 143 
2025-08-08 13:00:16.920183: Current learning rate: 0.00466 
2025-08-08 13:00:37.672029: train_loss -0.6818 
2025-08-08 13:00:37.675371: val_loss -0.6378 
2025-08-08 13:00:37.676468: Pseudo dice [np.float32(0.7449)] 
2025-08-08 13:00:37.678645: Epoch time: 20.76 s 
2025-08-08 13:00:38.937931:  
2025-08-08 13:00:38.943748: Epoch 144 
2025-08-08 13:00:38.944501: Current learning rate: 0.00462 
2025-08-08 13:00:56.918433: train_loss -0.6731 
2025-08-08 13:00:56.920042: val_loss -0.6797 
2025-08-08 13:00:56.920882: Pseudo dice [np.float32(0.7711)] 
2025-08-08 13:00:56.921658: Epoch time: 17.98 s 
2025-08-08 13:00:58.182996:  
2025-08-08 13:00:58.184222: Epoch 145 
2025-08-08 13:00:58.184961: Current learning rate: 0.00458 
2025-08-08 13:01:16.163710: train_loss -0.6599 
2025-08-08 13:01:16.165236: val_loss -0.6667 
2025-08-08 13:01:16.166133: Pseudo dice [np.float32(0.7625)] 
2025-08-08 13:01:16.167038: Epoch time: 17.98 s 
2025-08-08 13:01:17.520901:  
2025-08-08 13:01:17.522118: Epoch 146 
2025-08-08 13:01:17.523037: Current learning rate: 0.00454 
2025-08-08 13:01:35.487184: train_loss -0.7049 
2025-08-08 13:01:35.488944: val_loss -0.708 
2025-08-08 13:01:35.489779: Pseudo dice [np.float32(0.7911)] 
2025-08-08 13:01:35.490610: Epoch time: 17.97 s 
2025-08-08 13:01:35.491419: Yayy! New best EMA pseudo Dice: 0.755299985408783 
2025-08-08 13:01:45.412187:  
2025-08-08 13:01:45.413174: Epoch 147 
2025-08-08 13:01:45.414019: Current learning rate: 0.0045 
2025-08-08 13:02:04.196191: train_loss -0.6765 
2025-08-08 13:02:04.197860: val_loss -0.6253 
2025-08-08 13:02:04.198811: Pseudo dice [np.float32(0.74)] 
2025-08-08 13:02:04.199542: Epoch time: 18.79 s 
2025-08-08 13:02:05.457869:  
2025-08-08 13:02:05.459390: Epoch 148 
2025-08-08 13:02:05.460116: Current learning rate: 0.00446 
2025-08-08 13:02:23.433591: train_loss -0.6561 
2025-08-08 13:02:23.435227: val_loss -0.6719 
2025-08-08 13:02:23.436015: Pseudo dice [np.float32(0.7779)] 
2025-08-08 13:02:23.436812: Epoch time: 17.98 s 
2025-08-08 13:02:23.437677: Yayy! New best EMA pseudo Dice: 0.7562000155448914 
2025-08-08 13:02:40.061339:  
2025-08-08 13:02:40.062722: Epoch 149 
2025-08-08 13:02:40.063514: Current learning rate: 0.00442 
2025-08-08 13:02:58.030150: train_loss -0.6734 
2025-08-08 13:02:58.031745: val_loss -0.6349 
2025-08-08 13:02:58.032611: Pseudo dice [np.float32(0.7366)] 
2025-08-08 13:02:58.033440: Epoch time: 17.97 s 
2025-08-08 13:03:14.422914:  
2025-08-08 13:03:14.636422: Epoch 150 
2025-08-08 13:03:14.671940: Current learning rate: 0.00438 
2025-08-08 13:03:32.921162: train_loss -0.6831 
2025-08-08 13:03:32.922959: val_loss -0.6762 
2025-08-08 13:03:32.923820: Pseudo dice [np.float32(0.7713)] 
2025-08-08 13:03:32.924580: Epoch time: 18.5 s 
2025-08-08 13:03:34.219072:  
2025-08-08 13:03:34.220506: Epoch 151 
2025-08-08 13:03:34.221305: Current learning rate: 0.00434 
2025-08-08 13:03:52.396851: train_loss -0.6849 
2025-08-08 13:03:52.398904: val_loss -0.6821 
2025-08-08 13:03:52.399720: Pseudo dice [np.float32(0.7804)] 
2025-08-08 13:03:52.400525: Epoch time: 18.18 s 
2025-08-08 13:03:52.401265: Yayy! New best EMA pseudo Dice: 0.758400022983551 
2025-08-08 13:04:02.146094:  
2025-08-08 13:04:02.147011: Epoch 152 
2025-08-08 13:04:02.147783: Current learning rate: 0.0043 
2025-08-08 13:04:20.294965: train_loss -0.649 
2025-08-08 13:04:20.297053: val_loss -0.7203 
2025-08-08 13:04:20.298021: Pseudo dice [np.float32(0.7956)] 
2025-08-08 13:04:20.298996: Epoch time: 18.15 s 
2025-08-08 13:04:20.299885: Yayy! New best EMA pseudo Dice: 0.7620999813079834 
2025-08-08 13:04:30.119164:  
2025-08-08 13:04:30.120155: Epoch 153 
2025-08-08 13:04:30.121088: Current learning rate: 0.00427 
2025-08-08 13:04:48.419698: train_loss -0.6666 
2025-08-08 13:04:48.421568: val_loss -0.7248 
2025-08-08 13:04:48.422442: Pseudo dice [np.float32(0.8009)] 
2025-08-08 13:04:48.423229: Epoch time: 18.3 s 
2025-08-08 13:04:48.424012: Yayy! New best EMA pseudo Dice: 0.765999972820282 
2025-08-08 13:04:58.940747:  
2025-08-08 13:04:58.941707: Epoch 154 
2025-08-08 13:04:58.942508: Current learning rate: 0.00423 
2025-08-08 13:05:16.938473: train_loss -0.6471 
2025-08-08 13:05:16.940668: val_loss -0.6736 
2025-08-08 13:05:16.941477: Pseudo dice [np.float32(0.7698)] 
2025-08-08 13:05:16.942336: Epoch time: 18.0 s 
2025-08-08 13:05:16.943097: Yayy! New best EMA pseudo Dice: 0.7663000226020813 
2025-08-08 13:05:26.757176:  
2025-08-08 13:05:26.759041: Epoch 155 
2025-08-08 13:05:26.759828: Current learning rate: 0.00419 
2025-08-08 13:05:44.733184: train_loss -0.6859 
2025-08-08 13:05:44.735316: val_loss -0.6665 
2025-08-08 13:05:44.736221: Pseudo dice [np.float32(0.7682)] 
2025-08-08 13:05:44.737080: Epoch time: 17.98 s 
2025-08-08 13:05:44.737903: Yayy! New best EMA pseudo Dice: 0.7664999961853027 
2025-08-08 13:05:54.491162:  
2025-08-08 13:05:54.492144: Epoch 156 
2025-08-08 13:05:54.492984: Current learning rate: 0.00415 
2025-08-08 13:06:12.476651: train_loss -0.6933 
2025-08-08 13:06:12.478463: val_loss -0.6652 
2025-08-08 13:06:12.479211: Pseudo dice [np.float32(0.7615)] 
2025-08-08 13:06:12.479942: Epoch time: 17.99 s 
2025-08-08 13:06:13.847586:  
2025-08-08 13:06:13.849053: Epoch 157 
2025-08-08 13:06:13.849771: Current learning rate: 0.00411 
2025-08-08 13:06:31.828129: train_loss -0.6715 
2025-08-08 13:06:31.830110: val_loss -0.6586 
2025-08-08 13:06:31.831050: Pseudo dice [np.float32(0.7673)] 
2025-08-08 13:06:31.831946: Epoch time: 17.98 s 
2025-08-08 13:06:33.120686:  
2025-08-08 13:06:33.122529: Epoch 158 
2025-08-08 13:06:33.123225: Current learning rate: 0.00407 
2025-08-08 13:06:51.091353: train_loss -0.6907 
2025-08-08 13:06:51.093351: val_loss -0.6717 
2025-08-08 13:06:51.094165: Pseudo dice [np.float32(0.7706)] 
2025-08-08 13:06:51.095059: Epoch time: 17.97 s 
2025-08-08 13:06:51.095972: Yayy! New best EMA pseudo Dice: 0.7666000127792358 
2025-08-08 13:07:00.934478:  
2025-08-08 13:07:00.935422: Epoch 159 
2025-08-08 13:07:00.936301: Current learning rate: 0.00403 
2025-08-08 13:07:18.901827: train_loss -0.6571 
2025-08-08 13:07:18.903756: val_loss -0.7028 
2025-08-08 13:07:18.904571: Pseudo dice [np.float32(0.7872)] 
2025-08-08 13:07:18.905371: Epoch time: 17.97 s 
2025-08-08 13:07:18.906085: Yayy! New best EMA pseudo Dice: 0.7687000036239624 
2025-08-08 13:07:29.741883:  
2025-08-08 13:07:29.954789: Epoch 160 
2025-08-08 13:07:29.986094: Current learning rate: 0.00399 
2025-08-08 13:07:48.185798: train_loss -0.7248 
2025-08-08 13:07:48.187738: val_loss -0.6803 
2025-08-08 13:07:48.188514: Pseudo dice [np.float32(0.7787)] 
2025-08-08 13:07:48.189373: Epoch time: 18.45 s 
2025-08-08 13:07:48.190112: Yayy! New best EMA pseudo Dice: 0.7696999907493591 
2025-08-08 13:07:57.922521:  
2025-08-08 13:07:58.117852: Epoch 161 
2025-08-08 13:07:58.162431: Current learning rate: 0.00395 
2025-08-08 13:08:16.419841: train_loss -0.6709 
2025-08-08 13:08:16.421664: val_loss -0.7198 
2025-08-08 13:08:16.422508: Pseudo dice [np.float32(0.8039)] 
2025-08-08 13:08:16.423270: Epoch time: 18.5 s 
2025-08-08 13:08:16.424001: Yayy! New best EMA pseudo Dice: 0.7731000185012817 
2025-08-08 13:08:26.189864:  
2025-08-08 13:08:26.190725: Epoch 162 
2025-08-08 13:08:26.191574: Current learning rate: 0.00391 
2025-08-08 13:08:44.160026: train_loss -0.6879 
2025-08-08 13:08:44.162053: val_loss -0.6785 
2025-08-08 13:08:44.162834: Pseudo dice [np.float32(0.7779)] 
2025-08-08 13:08:44.163630: Epoch time: 17.97 s 
2025-08-08 13:08:44.164363: Yayy! New best EMA pseudo Dice: 0.7735999822616577 
2025-08-08 13:08:53.912136:  
2025-08-08 13:08:53.913102: Epoch 163 
2025-08-08 13:08:53.913907: Current learning rate: 0.00387 
2025-08-08 13:09:11.879384: train_loss -0.7075 
2025-08-08 13:09:11.881267: val_loss -0.6681 
2025-08-08 13:09:11.882170: Pseudo dice [np.float32(0.7633)] 
2025-08-08 13:09:11.882988: Epoch time: 17.97 s 
2025-08-08 13:09:13.181630:  
2025-08-08 13:09:13.183186: Epoch 164 
2025-08-08 13:09:13.183972: Current learning rate: 0.00383 
2025-08-08 13:09:31.150925: train_loss -0.7065 
2025-08-08 13:09:31.152887: val_loss -0.6444 
2025-08-08 13:09:31.153731: Pseudo dice [np.float32(0.7498)] 
2025-08-08 13:09:31.154477: Epoch time: 17.97 s 
2025-08-08 13:09:32.429072:  
2025-08-08 13:09:32.430538: Epoch 165 
2025-08-08 13:09:32.431335: Current learning rate: 0.00379 
2025-08-08 13:09:50.385081: train_loss -0.6664 
2025-08-08 13:09:50.387231: val_loss -0.6582 
2025-08-08 13:09:50.388127: Pseudo dice [np.float32(0.7529)] 
2025-08-08 13:09:50.388941: Epoch time: 17.96 s 
2025-08-08 13:09:51.655289:  
2025-08-08 13:09:51.656770: Epoch 166 
2025-08-08 13:09:51.657535: Current learning rate: 0.00375 
2025-08-08 13:10:09.633039: train_loss -0.7044 
2025-08-08 13:10:09.635336: val_loss -0.6749 
2025-08-08 13:10:09.636276: Pseudo dice [np.float32(0.7619)] 
2025-08-08 13:10:09.637143: Epoch time: 17.98 s 
2025-08-08 13:10:10.996884:  
2025-08-08 13:10:10.998373: Epoch 167 
2025-08-08 13:10:10.999234: Current learning rate: 0.00371 
2025-08-08 13:10:28.946024: train_loss -0.6818 
2025-08-08 13:10:28.948419: val_loss -0.6939 
2025-08-08 13:10:28.949236: Pseudo dice [np.float32(0.7876)] 
2025-08-08 13:10:28.950031: Epoch time: 17.95 s 
2025-08-08 13:10:30.296517:  
2025-08-08 13:10:30.298002: Epoch 168 
2025-08-08 13:10:30.298716: Current learning rate: 0.00367 
2025-08-08 13:10:48.240150: train_loss -0.7011 
2025-08-08 13:10:48.242011: val_loss -0.6388 
2025-08-08 13:10:48.242872: Pseudo dice [np.float32(0.7394)] 
2025-08-08 13:10:48.243667: Epoch time: 17.95 s 
2025-08-08 13:10:49.519754:  
2025-08-08 13:10:49.521379: Epoch 169 
2025-08-08 13:10:49.522224: Current learning rate: 0.00363 
2025-08-08 13:11:07.449256: train_loss -0.6875 
2025-08-08 13:11:07.451129: val_loss -0.687 
2025-08-08 13:11:07.451902: Pseudo dice [np.float32(0.7799)] 
2025-08-08 13:11:07.452693: Epoch time: 17.93 s 
2025-08-08 13:11:08.821989:  
2025-08-08 13:11:08.823607: Epoch 170 
2025-08-08 13:11:08.824480: Current learning rate: 0.00359 
2025-08-08 13:11:26.793386: train_loss -0.707 
2025-08-08 13:11:26.795350: val_loss -0.6647 
2025-08-08 13:11:26.796135: Pseudo dice [np.float32(0.7676)] 
2025-08-08 13:11:26.796860: Epoch time: 17.98 s 
2025-08-08 13:11:28.173440:  
2025-08-08 13:11:28.174971: Epoch 171 
2025-08-08 13:11:28.175776: Current learning rate: 0.00355 
2025-08-08 13:11:46.150563: train_loss -0.687 
2025-08-08 13:11:46.152545: val_loss -0.6087 
2025-08-08 13:11:46.153321: Pseudo dice [np.float32(0.7233)] 
2025-08-08 13:11:46.154042: Epoch time: 17.98 s 
2025-08-08 13:11:47.426934:  
2025-08-08 13:11:47.428565: Epoch 172 
2025-08-08 13:11:47.429324: Current learning rate: 0.00351 
2025-08-08 13:12:05.364761: train_loss -0.6874 
2025-08-08 13:12:05.366634: val_loss -0.6877 
2025-08-08 13:12:05.367435: Pseudo dice [np.float32(0.7795)] 
2025-08-08 13:12:05.368196: Epoch time: 17.94 s 
2025-08-08 13:12:06.735305:  
2025-08-08 13:12:06.736761: Epoch 173 
2025-08-08 13:12:06.737488: Current learning rate: 0.00346 
2025-08-08 13:12:24.697106: train_loss -0.6975 
2025-08-08 13:12:24.698968: val_loss -0.7124 
2025-08-08 13:12:24.699743: Pseudo dice [np.float32(0.7982)] 
2025-08-08 13:12:24.700448: Epoch time: 17.97 s 
2025-08-08 13:12:26.062868:  
2025-08-08 13:12:26.064624: Epoch 174 
2025-08-08 13:12:26.065413: Current learning rate: 0.00342 
2025-08-08 13:12:44.019099: train_loss -0.6834 
2025-08-08 13:12:44.021426: val_loss -0.6808 
2025-08-08 13:12:44.022351: Pseudo dice [np.float32(0.7697)] 
2025-08-08 13:12:44.023235: Epoch time: 17.96 s 
2025-08-08 13:12:45.308211:  
2025-08-08 13:12:45.310031: Epoch 175 
2025-08-08 13:12:45.310907: Current learning rate: 0.00338 
2025-08-08 13:13:03.256926: train_loss -0.7286 
2025-08-08 13:13:03.258754: val_loss -0.6544 
2025-08-08 13:13:03.259564: Pseudo dice [np.float32(0.754)] 
2025-08-08 13:13:03.260378: Epoch time: 17.95 s 
2025-08-08 13:13:05.201930:  
2025-08-08 13:13:05.203434: Epoch 176 
2025-08-08 13:13:05.204236: Current learning rate: 0.00334 
2025-08-08 13:13:23.216380: train_loss -0.7066 
2025-08-08 13:13:23.218282: val_loss -0.6653 
2025-08-08 13:13:23.219185: Pseudo dice [np.float32(0.7652)] 
2025-08-08 13:13:23.219981: Epoch time: 18.02 s 
2025-08-08 13:13:24.499516:  
2025-08-08 13:13:24.501165: Epoch 177 
2025-08-08 13:13:24.501978: Current learning rate: 0.0033 
2025-08-08 13:13:42.515484: train_loss -0.702 
2025-08-08 13:13:42.517498: val_loss -0.6605 
2025-08-08 13:13:42.518341: Pseudo dice [np.float32(0.7715)] 
2025-08-08 13:13:42.519112: Epoch time: 18.02 s 
2025-08-08 13:13:43.814854:  
2025-08-08 13:13:43.816422: Epoch 178 
2025-08-08 13:13:43.817253: Current learning rate: 0.00326 
2025-08-08 13:14:01.808121: train_loss -0.6701 
2025-08-08 13:14:01.810134: val_loss -0.713 
2025-08-08 13:14:01.811009: Pseudo dice [np.float32(0.798)] 
2025-08-08 13:14:01.812017: Epoch time: 18.0 s 
2025-08-08 13:14:03.097576:  
2025-08-08 13:14:03.099159: Epoch 179 
2025-08-08 13:14:03.100020: Current learning rate: 0.00322 
2025-08-08 13:14:21.088032: train_loss -0.7043 
2025-08-08 13:14:21.089957: val_loss -0.6659 
2025-08-08 13:14:21.090713: Pseudo dice [np.float32(0.763)] 
2025-08-08 13:14:21.091385: Epoch time: 17.99 s 
2025-08-08 13:14:22.386569:  
2025-08-08 13:14:22.388005: Epoch 180 
2025-08-08 13:14:22.388857: Current learning rate: 0.00318 
2025-08-08 13:14:40.357530: train_loss -0.695 
2025-08-08 13:14:40.359377: val_loss -0.6504 
2025-08-08 13:14:40.360204: Pseudo dice [np.float32(0.7506)] 
2025-08-08 13:14:40.360974: Epoch time: 17.97 s 
2025-08-08 13:14:41.756500:  
2025-08-08 13:14:41.758398: Epoch 181 
2025-08-08 13:14:41.759247: Current learning rate: 0.00314 
2025-08-08 13:14:59.722269: train_loss -0.6859 
2025-08-08 13:14:59.724321: val_loss -0.6987 
2025-08-08 13:14:59.725148: Pseudo dice [np.float32(0.7872)] 
2025-08-08 13:14:59.725937: Epoch time: 17.97 s 
2025-08-08 13:15:01.020043:  
2025-08-08 13:15:01.021550: Epoch 182 
2025-08-08 13:15:01.022350: Current learning rate: 0.0031 
2025-08-08 13:15:18.974976: train_loss -0.7148 
2025-08-08 13:15:18.976949: val_loss -0.7199 
2025-08-08 13:15:18.977741: Pseudo dice [np.float32(0.8059)] 
2025-08-08 13:15:18.978603: Epoch time: 17.96 s 
2025-08-08 13:15:20.329694:  
2025-08-08 13:15:20.331222: Epoch 183 
2025-08-08 13:15:20.332009: Current learning rate: 0.00306 
2025-08-08 13:15:39.469969: train_loss -0.7135 
2025-08-08 13:15:39.471784: val_loss -0.677 
2025-08-08 13:15:39.472582: Pseudo dice [np.float32(0.7655)] 
2025-08-08 13:15:39.473313: Epoch time: 19.14 s 
2025-08-08 13:15:40.738156:  
2025-08-08 13:15:40.739680: Epoch 184 
2025-08-08 13:15:40.740452: Current learning rate: 0.00302 
2025-08-08 13:15:58.719964: train_loss -0.7074 
2025-08-08 13:15:58.721483: val_loss -0.6495 
2025-08-08 13:15:58.722310: Pseudo dice [np.float32(0.7457)] 
2025-08-08 13:15:58.723094: Epoch time: 17.99 s 
2025-08-08 13:16:00.119846:  
2025-08-08 13:16:00.336596: Epoch 185 
2025-08-08 13:16:00.372301: Current learning rate: 0.00297 
2025-08-08 13:16:18.585591: train_loss -0.7462 
2025-08-08 13:16:18.587397: val_loss -0.6786 
2025-08-08 13:16:18.588304: Pseudo dice [np.float32(0.7712)] 
2025-08-08 13:16:18.589083: Epoch time: 18.47 s 
2025-08-08 13:16:19.957117:  
2025-08-08 13:16:19.958656: Epoch 186 
2025-08-08 13:16:19.959479: Current learning rate: 0.00293 
2025-08-08 13:16:38.194950: train_loss -0.708 
2025-08-08 13:16:38.196941: val_loss -0.6579 
2025-08-08 13:16:38.198055: Pseudo dice [np.float32(0.7566)] 
2025-08-08 13:16:38.198967: Epoch time: 18.24 s 
2025-08-08 13:16:39.566743:  
2025-08-08 13:16:39.568368: Epoch 187 
2025-08-08 13:16:39.569209: Current learning rate: 0.00289 
2025-08-08 13:16:57.542668: train_loss -0.7325 
2025-08-08 13:16:57.544771: val_loss -0.6882 
2025-08-08 13:16:57.545550: Pseudo dice [np.float32(0.7713)] 
2025-08-08 13:16:57.546305: Epoch time: 17.98 s 
2025-08-08 13:16:58.843060:  
2025-08-08 13:16:58.844571: Epoch 188 
2025-08-08 13:16:58.845392: Current learning rate: 0.00285 
2025-08-08 13:17:16.802259: train_loss -0.7044 
2025-08-08 13:17:16.804199: val_loss -0.6758 
2025-08-08 13:17:16.805037: Pseudo dice [np.float32(0.7708)] 
2025-08-08 13:17:16.805792: Epoch time: 17.96 s 
2025-08-08 13:17:18.097131:  
2025-08-08 13:17:18.098670: Epoch 189 
2025-08-08 13:17:18.099499: Current learning rate: 0.00281 
2025-08-08 13:17:39.120053: train_loss -0.7075 
2025-08-08 13:17:39.221785: val_loss -0.6765 
2025-08-08 13:17:39.257298: Pseudo dice [np.float32(0.7763)] 
2025-08-08 13:17:39.297319: Epoch time: 21.03 s 
2025-08-08 13:17:40.857335:  
2025-08-08 13:17:41.083487: Epoch 190 
2025-08-08 13:17:41.114815: Current learning rate: 0.00277 
2025-08-08 13:17:59.107636: train_loss -0.7386 
2025-08-08 13:17:59.109466: val_loss -0.6949 
2025-08-08 13:17:59.110404: Pseudo dice [np.float32(0.7798)] 
2025-08-08 13:17:59.111168: Epoch time: 18.25 s 
2025-08-08 13:18:00.538646:  
2025-08-08 13:18:00.539954: Epoch 191 
2025-08-08 13:18:00.540796: Current learning rate: 0.00273 
2025-08-08 13:18:18.476260: train_loss -0.7437 
2025-08-08 13:18:18.478265: val_loss -0.6854 
2025-08-08 13:18:18.479186: Pseudo dice [np.float32(0.7798)] 
2025-08-08 13:18:18.480026: Epoch time: 17.94 s 
2025-08-08 13:18:19.918598:  
2025-08-08 13:18:19.919772: Epoch 192 
2025-08-08 13:18:19.920614: Current learning rate: 0.00268 
2025-08-08 13:18:37.878895: train_loss -0.7104 
2025-08-08 13:18:37.880967: val_loss -0.646 
2025-08-08 13:18:37.881743: Pseudo dice [np.float32(0.745)] 
2025-08-08 13:18:37.882530: Epoch time: 17.96 s 
2025-08-08 13:18:39.315948:  
2025-08-08 13:18:39.317120: Epoch 193 
2025-08-08 13:18:39.317887: Current learning rate: 0.00264 
2025-08-08 13:18:57.256924: train_loss -0.7234 
2025-08-08 13:18:57.258711: val_loss -0.6981 
2025-08-08 13:18:57.259497: Pseudo dice [np.float32(0.7825)] 
2025-08-08 13:18:57.260451: Epoch time: 17.94 s 
2025-08-08 13:18:58.686993:  
2025-08-08 13:18:58.689509: Epoch 194 
2025-08-08 13:18:58.690264: Current learning rate: 0.0026 
2025-08-08 13:19:16.648966: train_loss -0.7142 
2025-08-08 13:19:16.650965: val_loss -0.669 
2025-08-08 13:19:16.651720: Pseudo dice [np.float32(0.7598)] 
2025-08-08 13:19:16.652530: Epoch time: 17.97 s 
2025-08-08 13:19:18.599798:  
2025-08-08 13:19:18.600671: Epoch 195 
2025-08-08 13:19:18.601504: Current learning rate: 0.00256 
2025-08-08 13:19:36.589597: train_loss -0.6924 
2025-08-08 13:19:36.591532: val_loss -0.6912 
2025-08-08 13:19:36.592441: Pseudo dice [np.float32(0.7789)] 
2025-08-08 13:19:36.593319: Epoch time: 17.99 s 
2025-08-08 13:19:37.908802:  
2025-08-08 13:19:37.910347: Epoch 196 
2025-08-08 13:19:37.911199: Current learning rate: 0.00252 
2025-08-08 13:19:55.914556: train_loss -0.7191 
2025-08-08 13:19:55.916543: val_loss -0.694 
2025-08-08 13:19:55.917451: Pseudo dice [np.float32(0.7829)] 
2025-08-08 13:19:55.918295: Epoch time: 18.01 s 
2025-08-08 13:19:57.289457:  
2025-08-08 13:19:57.291079: Epoch 197 
2025-08-08 13:19:57.291941: Current learning rate: 0.00248 
2025-08-08 13:20:15.274258: train_loss -0.7162 
2025-08-08 13:20:15.276202: val_loss -0.73 
2025-08-08 13:20:15.277087: Pseudo dice [np.float32(0.8091)] 
2025-08-08 13:20:15.277939: Epoch time: 17.99 s 
2025-08-08 13:20:15.278831: Yayy! New best EMA pseudo Dice: 0.7753000259399414 
2025-08-08 13:20:25.247071:  
2025-08-08 13:20:25.248021: Epoch 198 
2025-08-08 13:20:25.248902: Current learning rate: 0.00243 
2025-08-08 13:20:43.219785: train_loss -0.6952 
2025-08-08 13:20:43.221624: val_loss -0.6786 
2025-08-08 13:20:43.222369: Pseudo dice [np.float32(0.768)] 
2025-08-08 13:20:43.223132: Epoch time: 17.98 s 
2025-08-08 13:20:44.527755:  
2025-08-08 13:20:44.529736: Epoch 199 
2025-08-08 13:20:44.530600: Current learning rate: 0.00239 
2025-08-08 13:21:03.676692: train_loss -0.7097 
2025-08-08 13:21:03.678188: val_loss -0.6412 
2025-08-08 13:21:03.678959: Pseudo dice [np.float32(0.7458)] 
2025-08-08 13:21:03.679715: Epoch time: 19.15 s 
2025-08-08 13:21:20.244292:  
2025-08-08 13:21:20.245824: Epoch 200 
2025-08-08 13:21:20.246704: Current learning rate: 0.00235 
2025-08-08 13:21:38.314242: train_loss -0.7194 
2025-08-08 13:21:38.315909: val_loss -0.6443 
2025-08-08 13:21:38.316937: Pseudo dice [np.float32(0.7445)] 
2025-08-08 13:21:38.317855: Epoch time: 18.07 s 
2025-08-08 13:21:39.661443:  
2025-08-08 13:21:39.878603: Epoch 201 
2025-08-08 13:21:39.914283: Current learning rate: 0.00231 
2025-08-08 13:21:58.194555: train_loss -0.738 
2025-08-08 13:21:58.196534: val_loss -0.6598 
2025-08-08 13:21:58.197265: Pseudo dice [np.float32(0.772)] 
2025-08-08 13:21:58.198060: Epoch time: 18.54 s 
2025-08-08 13:21:59.587151:  
2025-08-08 13:21:59.588678: Epoch 202 
2025-08-08 13:21:59.589490: Current learning rate: 0.00226 
2025-08-08 13:22:17.832816: train_loss -0.7195 
2025-08-08 13:22:17.834719: val_loss -0.6497 
2025-08-08 13:22:17.835531: Pseudo dice [np.float32(0.7536)] 
2025-08-08 13:22:17.836313: Epoch time: 18.25 s 
2025-08-08 13:22:19.245645:  
2025-08-08 13:22:19.247164: Epoch 203 
2025-08-08 13:22:19.247978: Current learning rate: 0.00222 
2025-08-08 13:22:40.250824: train_loss -0.7241 
2025-08-08 13:22:40.354351: val_loss -0.6962 
2025-08-08 13:22:40.385357: Pseudo dice [np.float32(0.7921)] 
2025-08-08 13:22:40.416607: Epoch time: 21.01 s 
2025-08-08 13:22:42.153384:  
2025-08-08 13:22:42.155840: Epoch 204 
2025-08-08 13:22:42.156526: Current learning rate: 0.00218 
2025-08-08 13:23:00.151181: train_loss -0.7091 
2025-08-08 13:23:00.153134: val_loss -0.6811 
2025-08-08 13:23:00.153989: Pseudo dice [np.float32(0.7679)] 
2025-08-08 13:23:00.154757: Epoch time: 18.0 s 
2025-08-08 13:23:01.496135:  
2025-08-08 13:23:01.498670: Epoch 205 
2025-08-08 13:23:01.499461: Current learning rate: 0.00214 
2025-08-08 13:23:19.751331: train_loss -0.727 
2025-08-08 13:23:19.753155: val_loss -0.661 
2025-08-08 13:23:19.753945: Pseudo dice [np.float32(0.7595)] 
2025-08-08 13:23:19.754690: Epoch time: 18.26 s 
2025-08-08 13:23:21.096646:  
2025-08-08 13:23:21.098113: Epoch 206 
2025-08-08 13:23:21.098924: Current learning rate: 0.00209 
2025-08-08 13:23:39.279719: train_loss -0.7241 
2025-08-08 13:23:39.281375: val_loss -0.6306 
2025-08-08 13:23:39.282234: Pseudo dice [np.float32(0.7424)] 
2025-08-08 13:23:39.283107: Epoch time: 18.19 s 
2025-08-08 13:23:40.566036:  
2025-08-08 13:23:40.567341: Epoch 207 
2025-08-08 13:23:40.568209: Current learning rate: 0.00205 
2025-08-08 13:23:58.567897: train_loss -0.7369 
2025-08-08 13:23:58.666878: val_loss -0.6479 
2025-08-08 13:23:58.697639: Pseudo dice [np.float32(0.7653)] 
2025-08-08 13:23:58.729110: Epoch time: 18.01 s 
2025-08-08 13:24:00.265574:  
2025-08-08 13:24:00.505416: Epoch 208 
2025-08-08 13:24:00.541045: Current learning rate: 0.00201 
2025-08-08 13:24:18.635666: train_loss -0.725 
2025-08-08 13:24:18.637616: val_loss -0.6427 
2025-08-08 13:24:18.638401: Pseudo dice [np.float32(0.7457)] 
2025-08-08 13:24:18.639217: Epoch time: 18.37 s 
2025-08-08 13:24:19.919143:  
2025-08-08 13:24:19.920618: Epoch 209 
2025-08-08 13:24:19.921404: Current learning rate: 0.00196 
2025-08-08 13:24:38.130111: train_loss -0.7439 
2025-08-08 13:24:38.132171: val_loss -0.6528 
2025-08-08 13:24:38.132938: Pseudo dice [np.float32(0.7513)] 
2025-08-08 13:24:38.133673: Epoch time: 18.21 s 
2025-08-08 13:24:39.497955:  
2025-08-08 13:24:39.499478: Epoch 210 
2025-08-08 13:24:39.500256: Current learning rate: 0.00192 
2025-08-08 13:25:00.561882: train_loss -0.6988 
2025-08-08 13:25:00.675531: val_loss -0.6918 
2025-08-08 13:25:00.704378: Pseudo dice [np.float32(0.7836)] 
2025-08-08 13:25:00.740072: Epoch time: 21.07 s 
2025-08-08 13:25:02.087559:  
2025-08-08 13:25:02.089676: Epoch 211 
2025-08-08 13:25:02.090495: Current learning rate: 0.00188 
2025-08-08 13:25:20.062194: train_loss -0.7531 
2025-08-08 13:25:20.088569: val_loss -0.6516 
2025-08-08 13:25:20.089477: Pseudo dice [np.float32(0.7601)] 
2025-08-08 13:25:20.090327: Epoch time: 17.98 s 
2025-08-08 13:25:21.358167:  
2025-08-08 13:25:21.360587: Epoch 212 
2025-08-08 13:25:21.361488: Current learning rate: 0.00184 
2025-08-08 13:25:39.306466: train_loss -0.744 
2025-08-08 13:25:39.308344: val_loss -0.6876 
2025-08-08 13:25:39.309149: Pseudo dice [np.float32(0.7731)] 
2025-08-08 13:25:39.309900: Epoch time: 17.95 s 
2025-08-08 13:25:40.588556:  
2025-08-08 13:25:40.591415: Epoch 213 
2025-08-08 13:25:40.592239: Current learning rate: 0.00179 
2025-08-08 13:25:58.562802: train_loss -0.7403 
2025-08-08 13:25:58.564696: val_loss -0.6854 
2025-08-08 13:25:58.565561: Pseudo dice [np.float32(0.782)] 
2025-08-08 13:25:58.566377: Epoch time: 17.98 s 
2025-08-08 13:25:59.825155:  
2025-08-08 13:25:59.828018: Epoch 214 
2025-08-08 13:25:59.828880: Current learning rate: 0.00175 
2025-08-08 13:26:17.800312: train_loss -0.7345 
2025-08-08 13:26:17.802353: val_loss -0.6523 
2025-08-08 13:26:17.803282: Pseudo dice [np.float32(0.7605)] 
2025-08-08 13:26:17.804164: Epoch time: 17.98 s 
2025-08-08 13:26:19.072942:  
2025-08-08 13:26:19.075611: Epoch 215 
2025-08-08 13:26:19.076454: Current learning rate: 0.0017 
2025-08-08 13:26:37.047876: train_loss -0.7477 
2025-08-08 13:26:37.050046: val_loss -0.6763 
2025-08-08 13:26:37.051112: Pseudo dice [np.float32(0.7726)] 
2025-08-08 13:26:37.052015: Epoch time: 17.98 s 
2025-08-08 13:26:39.044897:  
2025-08-08 13:26:39.257977: Epoch 216 
2025-08-08 13:26:39.289221: Current learning rate: 0.00166 
2025-08-08 13:26:57.413826: train_loss -0.6876 
2025-08-08 13:26:57.415702: val_loss -0.6917 
2025-08-08 13:26:57.416466: Pseudo dice [np.float32(0.7765)] 
2025-08-08 13:26:57.417187: Epoch time: 18.37 s 
2025-08-08 13:26:58.721119:  
2025-08-08 13:26:58.722710: Epoch 217 
2025-08-08 13:26:58.723438: Current learning rate: 0.00162 
2025-08-08 13:27:16.713417: train_loss -0.727 
2025-08-08 13:27:16.715314: val_loss -0.6355 
2025-08-08 13:27:16.716078: Pseudo dice [np.float32(0.7436)] 
2025-08-08 13:27:16.716821: Epoch time: 18.0 s 
2025-08-08 13:27:17.979954:  
2025-08-08 13:27:17.981533: Epoch 218 
2025-08-08 13:27:17.982300: Current learning rate: 0.00157 
2025-08-08 13:27:35.978489: train_loss -0.7194 
2025-08-08 13:27:35.980359: val_loss -0.686 
2025-08-08 13:27:35.981127: Pseudo dice [np.float32(0.7845)] 
2025-08-08 13:27:35.981835: Epoch time: 18.0 s 
2025-08-08 13:27:37.305138:  
2025-08-08 13:27:37.306632: Epoch 219 
2025-08-08 13:27:37.307426: Current learning rate: 0.00153 
2025-08-08 13:27:55.309835: train_loss -0.7497 
2025-08-08 13:27:55.311627: val_loss -0.6961 
2025-08-08 13:27:55.312430: Pseudo dice [np.float32(0.7851)] 
2025-08-08 13:27:55.313183: Epoch time: 18.01 s 
2025-08-08 13:27:56.651836:  
2025-08-08 13:27:56.653553: Epoch 220 
2025-08-08 13:27:56.654296: Current learning rate: 0.00148 
2025-08-08 13:28:14.648085: train_loss -0.748 
2025-08-08 13:28:14.649925: val_loss -0.6416 
2025-08-08 13:28:14.650697: Pseudo dice [np.float32(0.7486)] 
2025-08-08 13:28:14.651495: Epoch time: 18.0 s 
2025-08-08 13:28:15.973513:  
2025-08-08 13:28:15.975131: Epoch 221 
2025-08-08 13:28:15.975914: Current learning rate: 0.00144 
2025-08-08 13:28:33.972744: train_loss -0.7608 
2025-08-08 13:28:33.974684: val_loss -0.68 
2025-08-08 13:28:33.975486: Pseudo dice [np.float32(0.7804)] 
2025-08-08 13:28:33.976264: Epoch time: 18.0 s 
2025-08-08 13:28:35.237863:  
2025-08-08 13:28:35.239676: Epoch 222 
2025-08-08 13:28:35.240507: Current learning rate: 0.00139 
2025-08-08 13:28:53.254621: train_loss -0.7256 
2025-08-08 13:28:53.256549: val_loss -0.7118 
2025-08-08 13:28:53.257333: Pseudo dice [np.float32(0.7977)] 
2025-08-08 13:28:53.258147: Epoch time: 18.02 s 
2025-08-08 13:28:54.525194:  
2025-08-08 13:28:54.526650: Epoch 223 
2025-08-08 13:28:54.527482: Current learning rate: 0.00135 
2025-08-08 13:29:12.530323: train_loss -0.7372 
2025-08-08 13:29:12.532338: val_loss -0.7008 
2025-08-08 13:29:12.533247: Pseudo dice [np.float32(0.7884)] 
2025-08-08 13:29:12.534139: Epoch time: 18.01 s 
2025-08-08 13:29:13.807820:  
2025-08-08 13:29:13.809500: Epoch 224 
2025-08-08 13:29:13.810479: Current learning rate: 0.0013 
2025-08-08 13:29:31.784114: train_loss -0.7512 
2025-08-08 13:29:31.786286: val_loss -0.6667 
2025-08-08 13:29:31.787027: Pseudo dice [np.float32(0.7737)] 
2025-08-08 13:29:31.787784: Epoch time: 17.98 s 
2025-08-08 13:29:33.170075:  
2025-08-08 13:29:33.171640: Epoch 225 
2025-08-08 13:29:33.172442: Current learning rate: 0.00126 
2025-08-08 13:29:51.162292: train_loss -0.735 
2025-08-08 13:29:51.164250: val_loss -0.6903 
2025-08-08 13:29:51.165042: Pseudo dice [np.float32(0.7839)] 
2025-08-08 13:29:51.165939: Epoch time: 18.0 s 
2025-08-08 13:29:52.494573:  
2025-08-08 13:29:52.496091: Epoch 226 
2025-08-08 13:29:52.496866: Current learning rate: 0.00121 
2025-08-08 13:30:10.485408: train_loss -0.7478 
2025-08-08 13:30:10.487440: val_loss -0.6934 
2025-08-08 13:30:10.488338: Pseudo dice [np.float32(0.7822)] 
2025-08-08 13:30:10.489158: Epoch time: 17.99 s 
2025-08-08 13:30:11.839283:  
2025-08-08 13:30:11.841049: Epoch 227 
2025-08-08 13:30:11.841946: Current learning rate: 0.00117 
2025-08-08 13:30:29.824297: train_loss -0.7454 
2025-08-08 13:30:29.826152: val_loss -0.7042 
2025-08-08 13:30:29.826897: Pseudo dice [np.float32(0.7924)] 
2025-08-08 13:30:29.827699: Epoch time: 17.99 s 
2025-08-08 13:30:29.828456: Yayy! New best EMA pseudo Dice: 0.7767000198364258 
2025-08-08 13:30:39.530470:  
2025-08-08 13:30:39.533070: Epoch 228 
2025-08-08 13:30:39.533904: Current learning rate: 0.00112 
2025-08-08 13:30:57.556541: train_loss -0.7612 
2025-08-08 13:30:57.558336: val_loss -0.6647 
2025-08-08 13:30:57.559082: Pseudo dice [np.float32(0.7656)] 
2025-08-08 13:30:57.559846: Epoch time: 18.03 s 
2025-08-08 13:30:58.863656:  
2025-08-08 13:30:58.866331: Epoch 229 
2025-08-08 13:30:58.867080: Current learning rate: 0.00108 
2025-08-08 13:31:16.891859: train_loss -0.7269 
2025-08-08 13:31:16.893770: val_loss -0.6478 
2025-08-08 13:31:16.894507: Pseudo dice [np.float32(0.7502)] 
2025-08-08 13:31:16.895207: Epoch time: 18.03 s 
2025-08-08 13:31:18.150999:  
2025-08-08 13:31:18.153604: Epoch 230 
2025-08-08 13:31:18.154362: Current learning rate: 0.00103 
2025-08-08 13:31:36.391968: train_loss -0.7354 
2025-08-08 13:31:36.394003: val_loss -0.6897 
2025-08-08 13:31:36.394846: Pseudo dice [np.float32(0.7827)] 
2025-08-08 13:31:36.395740: Epoch time: 18.24 s 
2025-08-08 13:31:37.677772:  
2025-08-08 13:31:37.679378: Epoch 231 
2025-08-08 13:31:37.680304: Current learning rate: 0.00098 
2025-08-08 13:31:55.958678: train_loss -0.7291 
2025-08-08 13:31:55.960549: val_loss -0.6659 
2025-08-08 13:31:55.961314: Pseudo dice [np.float32(0.7659)] 
2025-08-08 13:31:55.962094: Epoch time: 18.28 s 
2025-08-08 13:31:57.225321:  
2025-08-08 13:31:57.226877: Epoch 232 
2025-08-08 13:31:57.227673: Current learning rate: 0.00094 
2025-08-08 13:32:15.186171: train_loss -0.7308 
2025-08-08 13:32:15.187807: val_loss -0.6482 
2025-08-08 13:32:15.188794: Pseudo dice [np.float32(0.7543)] 
2025-08-08 13:32:15.189630: Epoch time: 17.96 s 
2025-08-08 13:32:16.437979:  
2025-08-08 13:32:16.439229: Epoch 233 
2025-08-08 13:32:16.440118: Current learning rate: 0.00089 
2025-08-08 13:32:35.901310: train_loss -0.7799 
2025-08-08 13:32:36.004443: val_loss -0.6332 
2025-08-08 13:32:36.039838: Pseudo dice [np.float32(0.7422)] 
2025-08-08 13:32:36.111104: Epoch time: 19.47 s 
2025-08-08 13:32:37.585679:  
2025-08-08 13:32:37.816343: Epoch 234 
2025-08-08 13:32:37.856697: Current learning rate: 0.00084 
2025-08-08 13:32:56.039455: train_loss -0.7496 
2025-08-08 13:32:56.041230: val_loss -0.7041 
2025-08-08 13:32:56.041946: Pseudo dice [np.float32(0.7949)] 
2025-08-08 13:32:56.042687: Epoch time: 18.46 s 
2025-08-08 13:32:57.384672:  
2025-08-08 13:32:57.386362: Epoch 235 
2025-08-08 13:32:57.387236: Current learning rate: 0.00079 
2025-08-08 13:33:15.337621: train_loss -0.76 
2025-08-08 13:33:15.339462: val_loss -0.7 
2025-08-08 13:33:15.340243: Pseudo dice [np.float32(0.7861)] 
2025-08-08 13:33:15.341002: Epoch time: 17.96 s 
2025-08-08 13:33:16.659213:  
2025-08-08 13:33:16.660872: Epoch 236 
2025-08-08 13:33:16.661927: Current learning rate: 0.00075 
2025-08-08 13:33:34.874756: train_loss -0.7406 
2025-08-08 13:33:34.876530: val_loss -0.6829 
2025-08-08 13:33:34.877311: Pseudo dice [np.float32(0.7761)] 
2025-08-08 13:33:34.878059: Epoch time: 18.22 s 
2025-08-08 13:33:36.224138:  
2025-08-08 13:33:36.225764: Epoch 237 
2025-08-08 13:33:36.226542: Current learning rate: 0.0007 
2025-08-08 13:33:56.148143: train_loss -0.7391 
2025-08-08 13:33:56.150098: val_loss -0.6957 
2025-08-08 13:33:56.150898: Pseudo dice [np.float32(0.7864)] 
2025-08-08 13:33:56.151696: Epoch time: 19.93 s 
2025-08-08 13:33:57.417637:  
2025-08-08 13:33:57.419211: Epoch 238 
2025-08-08 13:33:57.420054: Current learning rate: 0.00065 
2025-08-08 13:34:15.402495: train_loss -0.7182 
2025-08-08 13:34:15.404304: val_loss -0.7032 
2025-08-08 13:34:15.405034: Pseudo dice [np.float32(0.792)] 
2025-08-08 13:34:15.405793: Epoch time: 17.99 s 
2025-08-08 13:34:17.568424:  
2025-08-08 13:34:17.803427: Epoch 239 
2025-08-08 13:34:17.839193: Current learning rate: 0.0006 
2025-08-08 13:34:36.098347: train_loss -0.7632 
2025-08-08 13:34:36.100415: val_loss -0.7134 
2025-08-08 13:34:36.101224: Pseudo dice [np.float32(0.7957)] 
2025-08-08 13:34:36.101995: Epoch time: 18.53 s 
2025-08-08 13:34:36.102749: Yayy! New best EMA pseudo Dice: 0.777999997138977 
2025-08-08 13:34:45.831076:  
2025-08-08 13:34:45.832853: Epoch 240 
2025-08-08 13:34:45.833631: Current learning rate: 0.00055 
2025-08-08 13:35:04.122102: train_loss -0.7754 
2025-08-08 13:35:04.124156: val_loss -0.712 
2025-08-08 13:35:04.124953: Pseudo dice [np.float32(0.7982)] 
2025-08-08 13:35:04.125725: Epoch time: 18.29 s 
2025-08-08 13:35:04.126458: Yayy! New best EMA pseudo Dice: 0.7799999713897705 
2025-08-08 13:35:13.928770:  
2025-08-08 13:35:13.929717: Epoch 241 
2025-08-08 13:35:13.930657: Current learning rate: 0.0005 
2025-08-08 13:35:32.183866: train_loss -0.7503 
2025-08-08 13:35:32.185990: val_loss -0.7003 
2025-08-08 13:35:32.186973: Pseudo dice [np.float32(0.789)] 
2025-08-08 13:35:32.187854: Epoch time: 18.26 s 
2025-08-08 13:35:32.188609: Yayy! New best EMA pseudo Dice: 0.7809000015258789 
2025-08-08 13:35:41.927065:  
2025-08-08 13:35:41.929136: Epoch 242 
2025-08-08 13:35:41.930001: Current learning rate: 0.00045 
2025-08-08 13:36:00.217713: train_loss -0.7354 
2025-08-08 13:36:00.219564: val_loss -0.6919 
2025-08-08 13:36:00.220298: Pseudo dice [np.float32(0.7783)] 
2025-08-08 13:36:00.221018: Epoch time: 18.29 s 
2025-08-08 13:36:01.570305:  
2025-08-08 13:36:01.571759: Epoch 243 
2025-08-08 13:36:01.572514: Current learning rate: 0.0004 
2025-08-08 13:36:19.769703: train_loss -0.7623 
2025-08-08 13:36:19.771807: val_loss -0.6963 
2025-08-08 13:36:19.772687: Pseudo dice [np.float32(0.7881)] 
2025-08-08 13:36:19.773509: Epoch time: 18.2 s 
2025-08-08 13:36:19.774314: Yayy! New best EMA pseudo Dice: 0.7814000248908997 
2025-08-08 13:36:29.600639:  
2025-08-08 13:36:29.601789: Epoch 244 
2025-08-08 13:36:29.602612: Current learning rate: 0.00035 
2025-08-08 13:36:47.884182: train_loss -0.7749 
2025-08-08 13:36:47.886008: val_loss -0.6987 
2025-08-08 13:36:47.886793: Pseudo dice [np.float32(0.7881)] 
2025-08-08 13:36:47.887539: Epoch time: 18.29 s 
2025-08-08 13:36:47.888267: Yayy! New best EMA pseudo Dice: 0.7821000218391418 
2025-08-08 13:36:57.721589:  
2025-08-08 13:36:57.722499: Epoch 245 
2025-08-08 13:36:57.723296: Current learning rate: 0.0003 
2025-08-08 13:37:15.684571: train_loss -0.7267 
2025-08-08 13:37:15.686628: val_loss -0.68 
2025-08-08 13:37:15.687461: Pseudo dice [np.float32(0.7745)] 
2025-08-08 13:37:15.688206: Epoch time: 17.97 s 
2025-08-08 13:37:17.038392:  
2025-08-08 13:37:17.039881: Epoch 246 
2025-08-08 13:37:17.040713: Current learning rate: 0.00024 
2025-08-08 13:37:35.280910: train_loss -0.7603 
2025-08-08 13:37:35.282887: val_loss -0.6913 
2025-08-08 13:37:35.283760: Pseudo dice [np.float32(0.7805)] 
2025-08-08 13:37:35.284638: Epoch time: 18.25 s 
2025-08-08 13:37:36.632910:  
2025-08-08 13:37:36.634456: Epoch 247 
2025-08-08 13:37:36.635332: Current learning rate: 0.00019 
2025-08-08 13:37:54.632812: train_loss -0.7477 
2025-08-08 13:37:54.634731: val_loss -0.7027 
2025-08-08 13:37:54.635534: Pseudo dice [np.float32(0.7802)] 
2025-08-08 13:37:54.636580: Epoch time: 18.0 s 
2025-08-08 13:37:55.978036:  
2025-08-08 13:37:55.979764: Epoch 248 
2025-08-08 13:37:55.980556: Current learning rate: 0.00013 
2025-08-08 13:38:13.948268: train_loss -0.7806 
2025-08-08 13:38:13.950086: val_loss -0.6793 
2025-08-08 13:38:13.950863: Pseudo dice [np.float32(0.7814)] 
2025-08-08 13:38:13.951685: Epoch time: 17.97 s 
2025-08-08 13:38:15.296408:  
2025-08-08 13:38:15.297993: Epoch 249 
2025-08-08 13:38:15.298764: Current learning rate: 7e-05 
2025-08-08 13:38:36.206105: train_loss -0.7693 
2025-08-08 13:38:36.321444: val_loss -0.7107 
2025-08-08 13:38:36.356854: Pseudo dice [np.float32(0.7973)] 
2025-08-08 13:38:36.392493: Epoch time: 20.91 s 
2025-08-08 13:38:36.428294: Yayy! New best EMA pseudo Dice: 0.782800018787384 
2025-08-08 13:38:54.935503: Training done. 
2025-08-08 13:38:55.079721: Using splits from existing split file: /zhome/4b/5/187216/dm-i-ai-2025/tumor_segmentation/data_nnUNet/preprocessed/Dataset001_TumorSegmentation/splits_final.json 
2025-08-08 13:38:55.082043: The split file contains 1 splits. 
2025-08-08 13:38:55.083425: Desired fold for training: 0 
2025-08-08 13:38:55.084523: This split has 581 training and 27 validation cases. 
2025-08-08 13:38:55.086226: predicting patient_002 
2025-08-08 13:38:55.091286: patient_002, shape torch.Size([1, 1, 426, 400]), rank 0 
2025-08-08 13:39:50.992006: predicting patient_013 
2025-08-08 13:39:50.998559: patient_013, shape torch.Size([1, 1, 889, 400]), rank 0 
2025-08-08 13:39:51.541189: predicting patient_014 
2025-08-08 13:39:51.545835: patient_014, shape torch.Size([1, 1, 489, 400]), rank 0 
2025-08-08 13:39:51.867084: predicting patient_015 
2025-08-08 13:39:51.872162: patient_015, shape torch.Size([1, 1, 489, 400]), rank 0 
2025-08-08 13:39:52.182984: predicting patient_019 
2025-08-08 13:39:52.188034: patient_019, shape torch.Size([1, 1, 489, 400]), rank 0 
2025-08-08 13:39:52.495249: predicting patient_025 
2025-08-08 13:39:52.500021: patient_025, shape torch.Size([1, 1, 489, 400]), rank 0 
2025-08-08 13:39:52.810642: predicting patient_030 
2025-08-08 13:39:52.815612: patient_030, shape torch.Size([1, 1, 489, 400]), rank 0 
2025-08-08 13:39:53.122736: predicting patient_036 
2025-08-08 13:39:53.126812: patient_036, shape torch.Size([1, 1, 427, 400]), rank 0 
2025-08-08 13:39:53.438958: predicting patient_042 
2025-08-08 13:39:53.443735: patient_042, shape torch.Size([1, 1, 489, 400]), rank 0 
2025-08-08 13:39:53.749644: predicting patient_060 
2025-08-08 13:39:53.753936: patient_060, shape torch.Size([1, 1, 489, 400]), rank 0 
2025-08-08 13:39:54.012456: predicting patient_065 
2025-08-08 13:39:54.016942: patient_065, shape torch.Size([1, 1, 486, 400]), rank 0 
2025-08-08 13:39:54.282026: predicting patient_066 
2025-08-08 13:39:54.287865: patient_066, shape torch.Size([1, 1, 739, 400]), rank 0 
2025-08-08 13:39:54.712245: predicting patient_074 
2025-08-08 13:39:54.716484: patient_074, shape torch.Size([1, 1, 489, 400]), rank 0 
2025-08-08 13:39:54.981372: predicting patient_099 
2025-08-08 13:39:54.986118: patient_099, shape torch.Size([1, 1, 477, 400]), rank 0 
2025-08-08 13:39:55.254055: predicting patient_111 
2025-08-08 13:39:55.258102: patient_111, shape torch.Size([1, 1, 426, 400]), rank 0 
2025-08-08 13:39:55.523453: predicting patient_120 
2025-08-08 13:39:55.527820: patient_120, shape torch.Size([1, 1, 426, 400]), rank 0 
2025-08-08 13:39:55.789653: predicting patient_121 
2025-08-08 13:39:55.793797: patient_121, shape torch.Size([1, 1, 426, 400]), rank 0 
2025-08-08 13:39:56.051303: predicting patient_125 
2025-08-08 13:39:56.055671: patient_125, shape torch.Size([1, 1, 489, 400]), rank 0 
2025-08-08 13:39:56.323645: predicting patient_128 
2025-08-08 13:39:56.327710: patient_128, shape torch.Size([1, 1, 489, 400]), rank 0 
2025-08-08 13:39:56.587522: predicting patient_131 
2025-08-08 13:39:56.592079: patient_131, shape torch.Size([1, 1, 489, 400]), rank 0 
2025-08-08 13:39:56.855973: predicting patient_134 
2025-08-08 13:39:56.860336: patient_134, shape torch.Size([1, 1, 444, 400]), rank 0 
2025-08-08 13:39:57.119391: predicting patient_142 
2025-08-08 13:39:57.124011: patient_142, shape torch.Size([1, 1, 489, 400]), rank 0 
2025-08-08 13:39:57.384227: predicting patient_152 
2025-08-08 13:39:57.389123: patient_152, shape torch.Size([1, 1, 865, 400]), rank 0 
2025-08-08 13:39:57.888170: predicting patient_161 
2025-08-08 13:39:57.892179: patient_161, shape torch.Size([1, 1, 426, 400]), rank 0 
2025-08-08 13:39:58.154404: predicting patient_171 
2025-08-08 13:39:58.158192: patient_171, shape torch.Size([1, 1, 426, 400]), rank 0 
2025-08-08 13:39:58.422040: predicting patient_176 
2025-08-08 13:39:58.426984: patient_176, shape torch.Size([1, 1, 489, 400]), rank 0 
2025-08-08 13:39:58.686953: predicting patient_177 
2025-08-08 13:39:58.691139: patient_177, shape torch.Size([1, 1, 426, 400]), rank 0 
2025-08-08 13:40:10.244131: Validation complete 
2025-08-08 13:40:10.245841: Mean Validation Dice:  0.6916662530279484 
