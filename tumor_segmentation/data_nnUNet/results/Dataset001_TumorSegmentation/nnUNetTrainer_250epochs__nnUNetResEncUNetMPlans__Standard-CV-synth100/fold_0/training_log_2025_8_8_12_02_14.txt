
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-08-08 12:02:17.875917: Using torch.compile... 
2025-08-08 12:02:19.803322: do_dummy_2d_data_aug: False 
2025-08-08 12:02:19.807230: Using splits from existing split file: /zhome/4b/5/187216/dm-i-ai-2025/tumor_segmentation/data_nnUNet/preprocessed/Dataset001_TumorSegmentation/splits_final.json 
2025-08-08 12:02:19.808439: The split file contains 1 splits. 
2025-08-08 12:02:19.809095: Desired fold for training: 0 
2025-08-08 12:02:19.809733: This split has 516 training and 27 validation cases. 

This is the configuration used by this training:
Configuration name: Standard-CV-synth100
 {'data_identifier': 'nnUNetPlans_Standard-CV-synth100', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 8, 'patch_size': [256, 256], 'median_image_size_in_voxels': [489.0, 400.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_blocks_per_stage': [1, 3, 4, 6, 6, 6, 6], 'n_conv_per_stage_decoder': [1, 1, 1, 1, 1, 1], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '2d'} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_TumorSegmentation', 'plans_name': 'nnUNetResEncUNetMPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 489, 400], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'nnUNetPlannerResEncM', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 239.0, 'mean': 58.64480943229735, 'median': 30.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 200.0, 'std': 65.01235322952341}}} 
 
2025-08-08 12:02:20.583373: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-08-08 12:02:20.657492:  
2025-08-08 12:02:20.659145: Epoch 0 
2025-08-08 12:02:20.661666: Current learning rate: 0.01 
2025-08-08 12:02:55.561070: train_loss -0.0348 
2025-08-08 12:02:55.563654: val_loss -0.1789 
2025-08-08 12:02:55.564650: Pseudo dice [np.float32(0.1911)] 
2025-08-08 12:02:55.565582: Epoch time: 34.91 s 
2025-08-08 12:02:55.566639: Yayy! New best EMA pseudo Dice: 0.19110000133514404 
2025-08-08 12:03:05.078700:  
2025-08-08 12:03:05.079925: Epoch 1 
2025-08-08 12:03:05.081012: Current learning rate: 0.00996 
2025-08-08 12:03:23.101716: train_loss -0.1428 
2025-08-08 12:03:23.104546: val_loss -0.301 
2025-08-08 12:03:23.105676: Pseudo dice [np.float32(0.4593)] 
2025-08-08 12:03:23.106702: Epoch time: 18.03 s 
2025-08-08 12:03:23.107664: Yayy! New best EMA pseudo Dice: 0.21789999306201935 
2025-08-08 12:03:32.626217:  
2025-08-08 12:03:32.627548: Epoch 2 
2025-08-08 12:03:32.628667: Current learning rate: 0.00993 
2025-08-08 12:03:50.883473: train_loss -0.2189 
2025-08-08 12:03:50.885772: val_loss -0.1944 
2025-08-08 12:03:50.886732: Pseudo dice [np.float32(0.4195)] 
2025-08-08 12:03:50.887534: Epoch time: 18.26 s 
2025-08-08 12:03:50.888355: Yayy! New best EMA pseudo Dice: 0.23810000717639923 
2025-08-08 12:04:00.493481:  
2025-08-08 12:04:00.494727: Epoch 3 
2025-08-08 12:04:00.495663: Current learning rate: 0.00989 
2025-08-08 12:04:18.494100: train_loss -0.2617 
2025-08-08 12:04:18.496654: val_loss -0.3969 
2025-08-08 12:04:18.497658: Pseudo dice [np.float32(0.5538)] 
2025-08-08 12:04:18.498811: Epoch time: 18.01 s 
2025-08-08 12:04:18.499768: Yayy! New best EMA pseudo Dice: 0.2696000039577484 
2025-08-08 12:04:28.072305:  
2025-08-08 12:04:28.073532: Epoch 4 
2025-08-08 12:04:28.074574: Current learning rate: 0.00986 
2025-08-08 12:04:46.094507: train_loss -0.3092 
2025-08-08 12:04:46.096602: val_loss -0.4139 
2025-08-08 12:04:46.097374: Pseudo dice [np.float32(0.5704)] 
2025-08-08 12:04:46.098161: Epoch time: 18.03 s 
2025-08-08 12:04:46.099036: Yayy! New best EMA pseudo Dice: 0.299699991941452 
2025-08-08 12:04:55.577443:  
2025-08-08 12:04:55.578988: Epoch 5 
2025-08-08 12:04:55.580165: Current learning rate: 0.00982 
2025-08-08 12:05:13.702287: train_loss -0.326 
2025-08-08 12:05:13.704839: val_loss -0.4247 
2025-08-08 12:05:13.705717: Pseudo dice [np.float32(0.58)] 
2025-08-08 12:05:13.706679: Epoch time: 18.13 s 
2025-08-08 12:05:13.707479: Yayy! New best EMA pseudo Dice: 0.3276999890804291 
2025-08-08 12:05:23.223903:  
2025-08-08 12:05:23.224962: Epoch 6 
2025-08-08 12:05:23.225867: Current learning rate: 0.00978 
2025-08-08 12:05:41.344868: train_loss -0.4159 
2025-08-08 12:05:41.347250: val_loss -0.4177 
2025-08-08 12:05:41.348246: Pseudo dice [np.float32(0.5879)] 
2025-08-08 12:05:41.349092: Epoch time: 18.13 s 
2025-08-08 12:05:41.349941: Yayy! New best EMA pseudo Dice: 0.35370001196861267 
2025-08-08 12:05:50.912507:  
2025-08-08 12:05:50.914075: Epoch 7 
2025-08-08 12:05:50.915197: Current learning rate: 0.00975 
2025-08-08 12:06:09.136246: train_loss -0.3545 
2025-08-08 12:06:09.138740: val_loss -0.5041 
2025-08-08 12:06:09.139739: Pseudo dice [np.float32(0.6258)] 
2025-08-08 12:06:09.140843: Epoch time: 18.23 s 
2025-08-08 12:06:09.141783: Yayy! New best EMA pseudo Dice: 0.38100001215934753 
2025-08-08 12:06:18.701100:  
2025-08-08 12:06:18.702473: Epoch 8 
2025-08-08 12:06:18.703450: Current learning rate: 0.00971 
2025-08-08 12:06:36.754015: train_loss -0.3263 
2025-08-08 12:06:36.756506: val_loss -0.4067 
2025-08-08 12:06:36.757498: Pseudo dice [np.float32(0.5549)] 
2025-08-08 12:06:36.758510: Epoch time: 18.06 s 
2025-08-08 12:06:36.759339: Yayy! New best EMA pseudo Dice: 0.3984000086784363 
2025-08-08 12:06:46.276663:  
2025-08-08 12:06:46.278031: Epoch 9 
2025-08-08 12:06:46.279089: Current learning rate: 0.00968 
2025-08-08 12:07:04.406196: train_loss -0.4121 
2025-08-08 12:07:04.408360: val_loss -0.5004 
2025-08-08 12:07:04.409306: Pseudo dice [np.float32(0.6427)] 
2025-08-08 12:07:04.410117: Epoch time: 18.13 s 
2025-08-08 12:07:04.410925: Yayy! New best EMA pseudo Dice: 0.4228000044822693 
2025-08-08 12:07:14.520826:  
2025-08-08 12:07:14.522166: Epoch 10 
2025-08-08 12:07:14.523235: Current learning rate: 0.00964 
2025-08-08 12:07:32.690393: train_loss -0.4163 
2025-08-08 12:07:32.693017: val_loss -0.5125 
2025-08-08 12:07:32.693930: Pseudo dice [np.float32(0.6324)] 
2025-08-08 12:07:32.694963: Epoch time: 18.17 s 
2025-08-08 12:07:32.695995: Yayy! New best EMA pseudo Dice: 0.44369998574256897 
2025-08-08 12:07:42.463680:  
2025-08-08 12:07:42.465334: Epoch 11 
2025-08-08 12:07:42.466220: Current learning rate: 0.0096 
2025-08-08 12:08:00.583359: train_loss -0.4187 
2025-08-08 12:08:00.586050: val_loss -0.4258 
2025-08-08 12:08:00.587219: Pseudo dice [np.float32(0.5966)] 
2025-08-08 12:08:00.588150: Epoch time: 18.12 s 
2025-08-08 12:08:00.588957: Yayy! New best EMA pseudo Dice: 0.45899999141693115 
2025-08-08 12:08:10.398119:  
2025-08-08 12:08:10.399423: Epoch 12 
2025-08-08 12:08:10.400260: Current learning rate: 0.00957 
2025-08-08 12:08:28.427411: train_loss -0.457 
2025-08-08 12:08:28.429660: val_loss -0.5069 
2025-08-08 12:08:28.430871: Pseudo dice [np.float32(0.647)] 
2025-08-08 12:08:28.431680: Epoch time: 18.03 s 
2025-08-08 12:08:28.432399: Yayy! New best EMA pseudo Dice: 0.47780001163482666 
2025-08-08 12:08:38.232030:  
2025-08-08 12:08:38.233157: Epoch 13 
2025-08-08 12:08:38.234264: Current learning rate: 0.00953 
2025-08-08 12:08:56.327062: train_loss -0.4546 
2025-08-08 12:08:56.329838: val_loss -0.5742 
2025-08-08 12:08:56.330890: Pseudo dice [np.float32(0.7)] 
2025-08-08 12:08:56.331919: Epoch time: 18.1 s 
2025-08-08 12:08:56.332919: Yayy! New best EMA pseudo Dice: 0.5 
2025-08-08 12:09:06.053875:  
2025-08-08 12:09:06.055532: Epoch 14 
2025-08-08 12:09:06.056501: Current learning rate: 0.00949 
2025-08-08 12:09:24.163477: train_loss -0.4402 
2025-08-08 12:09:24.166654: val_loss -0.5585 
2025-08-08 12:09:24.167764: Pseudo dice [np.float32(0.6735)] 
2025-08-08 12:09:24.169230: Epoch time: 18.11 s 
2025-08-08 12:09:24.170238: Yayy! New best EMA pseudo Dice: 0.5174000263214111 
2025-08-08 12:09:34.011867:  
2025-08-08 12:09:34.013240: Epoch 15 
2025-08-08 12:09:34.014106: Current learning rate: 0.00946 
2025-08-08 12:09:52.161375: train_loss -0.4998 
2025-08-08 12:09:52.163443: val_loss -0.5226 
2025-08-08 12:09:52.164309: Pseudo dice [np.float32(0.6641)] 
2025-08-08 12:09:52.165142: Epoch time: 18.16 s 
2025-08-08 12:09:52.165915: Yayy! New best EMA pseudo Dice: 0.5321000218391418 
2025-08-08 12:10:01.704825:  
2025-08-08 12:10:01.706144: Epoch 16 
2025-08-08 12:10:01.707243: Current learning rate: 0.00942 
2025-08-08 12:10:19.830341: train_loss -0.4724 
2025-08-08 12:10:19.832570: val_loss -0.5239 
2025-08-08 12:10:19.833507: Pseudo dice [np.float32(0.6623)] 
2025-08-08 12:10:19.834934: Epoch time: 18.13 s 
2025-08-08 12:10:19.835845: Yayy! New best EMA pseudo Dice: 0.5450999736785889 
2025-08-08 12:10:29.254836:  
2025-08-08 12:10:29.256417: Epoch 17 
2025-08-08 12:10:29.257226: Current learning rate: 0.00939 
2025-08-08 12:10:47.353656: train_loss -0.4697 
2025-08-08 12:10:47.355801: val_loss -0.4414 
2025-08-08 12:10:47.356734: Pseudo dice [np.float32(0.5746)] 
2025-08-08 12:10:47.357775: Epoch time: 18.11 s 
2025-08-08 12:10:47.358942: Yayy! New best EMA pseudo Dice: 0.5479999780654907 
2025-08-08 12:10:56.895863:  
2025-08-08 12:10:56.897474: Epoch 18 
2025-08-08 12:10:56.898384: Current learning rate: 0.00935 
2025-08-08 12:11:14.939888: train_loss -0.4799 
2025-08-08 12:11:14.942137: val_loss -0.5311 
2025-08-08 12:11:14.943087: Pseudo dice [np.float32(0.6605)] 
2025-08-08 12:11:14.943937: Epoch time: 18.05 s 
2025-08-08 12:11:14.944757: Yayy! New best EMA pseudo Dice: 0.5593000054359436 
2025-08-08 12:11:24.768085:  
2025-08-08 12:11:24.769341: Epoch 19 
2025-08-08 12:11:24.770543: Current learning rate: 0.00931 
2025-08-08 12:11:42.914832: train_loss -0.4803 
2025-08-08 12:11:42.917170: val_loss -0.5984 
2025-08-08 12:11:42.918102: Pseudo dice [np.float32(0.7071)] 
2025-08-08 12:11:42.919134: Epoch time: 18.15 s 
2025-08-08 12:11:42.920058: Yayy! New best EMA pseudo Dice: 0.5741000175476074 
2025-08-08 12:11:52.749010:  
2025-08-08 12:11:52.750178: Epoch 20 
2025-08-08 12:11:52.751025: Current learning rate: 0.00928 
2025-08-08 12:12:10.949989: train_loss -0.4957 
2025-08-08 12:12:10.952164: val_loss -0.5641 
2025-08-08 12:12:10.953051: Pseudo dice [np.float32(0.6805)] 
2025-08-08 12:12:10.953911: Epoch time: 18.21 s 
2025-08-08 12:12:10.954745: Yayy! New best EMA pseudo Dice: 0.5846999883651733 
2025-08-08 12:12:20.427843:  
2025-08-08 12:12:20.429068: Epoch 21 
2025-08-08 12:12:20.430610: Current learning rate: 0.00924 
2025-08-08 12:12:38.560547: train_loss -0.4915 
2025-08-08 12:12:38.562626: val_loss -0.5401 
2025-08-08 12:12:38.563478: Pseudo dice [np.float32(0.6615)] 
2025-08-08 12:12:38.564388: Epoch time: 18.14 s 
2025-08-08 12:12:38.565193: Yayy! New best EMA pseudo Dice: 0.5924000144004822 
2025-08-08 12:12:48.057251:  
2025-08-08 12:12:48.058469: Epoch 22 
2025-08-08 12:12:48.059314: Current learning rate: 0.0092 
2025-08-08 12:13:06.100497: train_loss -0.4852 
2025-08-08 12:13:06.102592: val_loss -0.479 
2025-08-08 12:13:06.103469: Pseudo dice [np.float32(0.6368)] 
2025-08-08 12:13:06.104242: Epoch time: 18.05 s 
2025-08-08 12:13:06.105003: Yayy! New best EMA pseudo Dice: 0.5968000292778015 
2025-08-08 12:13:15.903174:  
2025-08-08 12:13:15.904626: Epoch 23 
2025-08-08 12:13:15.905595: Current learning rate: 0.00917 
2025-08-08 12:13:34.101244: train_loss -0.4283 
2025-08-08 12:13:34.103452: val_loss -0.5917 
2025-08-08 12:13:34.104352: Pseudo dice [np.float32(0.7057)] 
2025-08-08 12:13:34.105178: Epoch time: 18.2 s 
2025-08-08 12:13:34.105989: Yayy! New best EMA pseudo Dice: 0.607699990272522 
2025-08-08 12:13:43.520594:  
2025-08-08 12:13:43.522188: Epoch 24 
2025-08-08 12:13:43.523302: Current learning rate: 0.00913 
2025-08-08 12:14:01.632709: train_loss -0.4684 
2025-08-08 12:14:01.635027: val_loss -0.5218 
2025-08-08 12:14:01.636009: Pseudo dice [np.float32(0.6596)] 
2025-08-08 12:14:01.636884: Epoch time: 18.12 s 
2025-08-08 12:14:01.637886: Yayy! New best EMA pseudo Dice: 0.6129000186920166 
2025-08-08 12:14:11.088976:  
2025-08-08 12:14:11.090518: Epoch 25 
2025-08-08 12:14:11.091456: Current learning rate: 0.0091 
2025-08-08 12:14:29.188179: train_loss -0.4957 
2025-08-08 12:14:29.190486: val_loss -0.6171 
2025-08-08 12:14:29.191349: Pseudo dice [np.float32(0.7205)] 
2025-08-08 12:14:29.192338: Epoch time: 18.11 s 
2025-08-08 12:14:29.193169: Yayy! New best EMA pseudo Dice: 0.6237000226974487 
2025-08-08 12:14:38.680544:  
2025-08-08 12:14:38.681889: Epoch 26 
2025-08-08 12:14:38.682647: Current learning rate: 0.00906 
2025-08-08 12:14:56.784042: train_loss -0.5036 
2025-08-08 12:14:56.786331: val_loss -0.5964 
2025-08-08 12:14:56.787174: Pseudo dice [np.float32(0.7046)] 
2025-08-08 12:14:56.788173: Epoch time: 18.11 s 
2025-08-08 12:14:56.789294: Yayy! New best EMA pseudo Dice: 0.6317999958992004 
2025-08-08 12:15:06.567350:  
2025-08-08 12:15:06.569608: Epoch 27 
2025-08-08 12:15:06.570857: Current learning rate: 0.00902 
2025-08-08 12:15:24.688174: train_loss -0.4631 
2025-08-08 12:15:24.690415: val_loss -0.5673 
2025-08-08 12:15:24.691249: Pseudo dice [np.float32(0.6834)] 
2025-08-08 12:15:24.692080: Epoch time: 18.13 s 
2025-08-08 12:15:24.692919: Yayy! New best EMA pseudo Dice: 0.636900007724762 
2025-08-08 12:15:34.487573:  
2025-08-08 12:15:34.488725: Epoch 28 
2025-08-08 12:15:34.489827: Current learning rate: 0.00899 
2025-08-08 12:15:52.656692: train_loss -0.4877 
2025-08-08 12:15:52.658949: val_loss -0.6271 
2025-08-08 12:15:52.659784: Pseudo dice [np.float32(0.7306)] 
2025-08-08 12:15:52.660609: Epoch time: 18.17 s 
2025-08-08 12:15:52.661371: Yayy! New best EMA pseudo Dice: 0.6463000178337097 
2025-08-08 12:16:02.155851:  
2025-08-08 12:16:02.157072: Epoch 29 
2025-08-08 12:16:02.158003: Current learning rate: 0.00895 
2025-08-08 12:16:20.236508: train_loss -0.5163 
2025-08-08 12:16:20.238974: val_loss -0.5503 
2025-08-08 12:16:20.239945: Pseudo dice [np.float32(0.6706)] 
2025-08-08 12:16:20.240756: Epoch time: 18.09 s 
2025-08-08 12:16:20.241511: Yayy! New best EMA pseudo Dice: 0.6486999988555908 
2025-08-08 12:16:30.253252:  
2025-08-08 12:16:30.254310: Epoch 30 
2025-08-08 12:16:30.255442: Current learning rate: 0.00891 
2025-08-08 12:16:48.449159: train_loss -0.4961 
2025-08-08 12:16:48.451310: val_loss -0.6152 
2025-08-08 12:16:48.452324: Pseudo dice [np.float32(0.7136)] 
2025-08-08 12:16:48.453141: Epoch time: 18.2 s 
2025-08-08 12:16:48.453947: Yayy! New best EMA pseudo Dice: 0.6552000045776367 
2025-08-08 12:16:57.912267:  
2025-08-08 12:16:57.913529: Epoch 31 
2025-08-08 12:16:57.914665: Current learning rate: 0.00888 
2025-08-08 12:17:16.086744: train_loss -0.5293 
2025-08-08 12:17:16.089108: val_loss -0.5111 
2025-08-08 12:17:16.090164: Pseudo dice [np.float32(0.6361)] 
2025-08-08 12:17:16.091155: Epoch time: 18.18 s 
2025-08-08 12:17:17.292706:  
2025-08-08 12:17:17.295928: Epoch 32 
2025-08-08 12:17:17.296778: Current learning rate: 0.00884 
2025-08-08 12:17:35.627133: train_loss -0.5338 
2025-08-08 12:17:35.629855: val_loss -0.543 
2025-08-08 12:17:35.630769: Pseudo dice [np.float32(0.6655)] 
2025-08-08 12:17:35.631958: Epoch time: 18.34 s 
2025-08-08 12:17:36.798878:  
2025-08-08 12:17:36.802363: Epoch 33 
2025-08-08 12:17:36.803268: Current learning rate: 0.0088 
2025-08-08 12:17:54.921424: train_loss -0.5607 
2025-08-08 12:17:54.923986: val_loss -0.5768 
2025-08-08 12:17:54.924953: Pseudo dice [np.float32(0.6959)] 
2025-08-08 12:17:54.925840: Epoch time: 18.13 s 
2025-08-08 12:17:54.926672: Yayy! New best EMA pseudo Dice: 0.6586999893188477 
2025-08-08 12:18:04.856804:  
2025-08-08 12:18:04.860619: Epoch 34 
2025-08-08 12:18:04.861639: Current learning rate: 0.00877 
2025-08-08 12:18:23.002715: train_loss -0.5563 
2025-08-08 12:18:23.005005: val_loss -0.6337 
2025-08-08 12:18:23.005941: Pseudo dice [np.float32(0.7281)] 
2025-08-08 12:18:23.006755: Epoch time: 18.15 s 
2025-08-08 12:18:23.007471: Yayy! New best EMA pseudo Dice: 0.6656000018119812 
2025-08-08 12:18:32.588761:  
2025-08-08 12:18:32.590199: Epoch 35 
2025-08-08 12:18:32.591141: Current learning rate: 0.00873 
2025-08-08 12:18:50.678734: train_loss -0.5702 
2025-08-08 12:18:50.681032: val_loss -0.5926 
2025-08-08 12:18:50.681868: Pseudo dice [np.float32(0.7096)] 
2025-08-08 12:18:50.682642: Epoch time: 18.09 s 
2025-08-08 12:18:50.683398: Yayy! New best EMA pseudo Dice: 0.6700000166893005 
2025-08-08 12:19:00.233418:  
2025-08-08 12:19:00.234701: Epoch 36 
2025-08-08 12:19:00.235707: Current learning rate: 0.00869 
2025-08-08 12:19:18.380990: train_loss -0.5343 
2025-08-08 12:19:18.391104: val_loss -0.6008 
2025-08-08 12:19:18.406692: Pseudo dice [np.float32(0.7106)] 
2025-08-08 12:19:18.412119: Epoch time: 18.15 s 
2025-08-08 12:19:18.413171: Yayy! New best EMA pseudo Dice: 0.6740999817848206 
2025-08-08 12:19:27.917703:  
2025-08-08 12:19:27.918980: Epoch 37 
2025-08-08 12:19:27.920158: Current learning rate: 0.00866 
2025-08-08 12:19:46.107056: train_loss -0.5584 
2025-08-08 12:19:46.109464: val_loss -0.6122 
2025-08-08 12:19:46.110465: Pseudo dice [np.float32(0.7234)] 
2025-08-08 12:19:46.111310: Epoch time: 18.19 s 
2025-08-08 12:19:46.112152: Yayy! New best EMA pseudo Dice: 0.6790000200271606 
2025-08-08 12:19:55.609331:  
2025-08-08 12:19:55.610432: Epoch 38 
2025-08-08 12:19:55.611525: Current learning rate: 0.00862 
2025-08-08 12:20:13.790209: train_loss -0.5565 
2025-08-08 12:20:13.792248: val_loss -0.6225 
2025-08-08 12:20:13.793113: Pseudo dice [np.float32(0.7203)] 
2025-08-08 12:20:13.793978: Epoch time: 18.19 s 
2025-08-08 12:20:13.794850: Yayy! New best EMA pseudo Dice: 0.6830999851226807 
2025-08-08 12:20:23.368038:  
2025-08-08 12:20:23.369179: Epoch 39 
2025-08-08 12:20:23.370147: Current learning rate: 0.00858 
2025-08-08 12:20:41.476190: train_loss -0.5263 
2025-08-08 12:20:41.478672: val_loss -0.5877 
2025-08-08 12:20:41.479572: Pseudo dice [np.float32(0.6897)] 
2025-08-08 12:20:41.480697: Epoch time: 18.11 s 
2025-08-08 12:20:41.481544: Yayy! New best EMA pseudo Dice: 0.6837999820709229 
2025-08-08 12:20:51.248279:  
2025-08-08 12:20:51.249655: Epoch 40 
2025-08-08 12:20:51.250810: Current learning rate: 0.00855 
2025-08-08 12:21:09.464019: train_loss -0.5447 
2025-08-08 12:21:09.466354: val_loss -0.5108 
2025-08-08 12:21:09.467301: Pseudo dice [np.float32(0.6359)] 
2025-08-08 12:21:09.468154: Epoch time: 18.22 s 
2025-08-08 12:21:10.628739:  
2025-08-08 12:21:10.632267: Epoch 41 
2025-08-08 12:21:10.633294: Current learning rate: 0.00851 
2025-08-08 12:21:28.789029: train_loss -0.5223 
2025-08-08 12:21:28.791613: val_loss -0.5355 
2025-08-08 12:21:28.792608: Pseudo dice [np.float32(0.663)] 
2025-08-08 12:21:28.793436: Epoch time: 18.17 s 
2025-08-08 12:21:29.938914:  
2025-08-08 12:21:29.940919: Epoch 42 
2025-08-08 12:21:29.941927: Current learning rate: 0.00847 
2025-08-08 12:21:48.110847: train_loss -0.5802 
2025-08-08 12:21:48.113003: val_loss -0.6281 
2025-08-08 12:21:48.113735: Pseudo dice [np.float32(0.7201)] 
2025-08-08 12:21:48.114476: Epoch time: 18.18 s 
2025-08-08 12:21:49.263950:  
2025-08-08 12:21:49.267161: Epoch 43 
2025-08-08 12:21:49.268258: Current learning rate: 0.00844 
2025-08-08 12:22:07.405582: train_loss -0.5397 
2025-08-08 12:22:07.407912: val_loss -0.6251 
2025-08-08 12:22:07.408864: Pseudo dice [np.float32(0.7319)] 
2025-08-08 12:22:07.409742: Epoch time: 18.15 s 
2025-08-08 12:22:07.410464: Yayy! New best EMA pseudo Dice: 0.6866999864578247 
2025-08-08 12:22:17.161539:  
2025-08-08 12:22:17.162674: Epoch 44 
2025-08-08 12:22:17.163496: Current learning rate: 0.0084 
2025-08-08 12:22:35.309488: train_loss -0.5411 
2025-08-08 12:22:35.311484: val_loss -0.6125 
2025-08-08 12:22:35.312392: Pseudo dice [np.float32(0.7266)] 
2025-08-08 12:22:35.313194: Epoch time: 18.15 s 
2025-08-08 12:22:35.313993: Yayy! New best EMA pseudo Dice: 0.6906999945640564 
2025-08-08 12:22:44.844961:  
2025-08-08 12:22:44.846383: Epoch 45 
2025-08-08 12:22:44.847507: Current learning rate: 0.00836 
2025-08-08 12:23:02.973247: train_loss -0.5108 
2025-08-08 12:23:02.975489: val_loss -0.5665 
2025-08-08 12:23:02.976338: Pseudo dice [np.float32(0.6816)] 
2025-08-08 12:23:02.977185: Epoch time: 18.13 s 
2025-08-08 12:23:04.125922:  
2025-08-08 12:23:04.129318: Epoch 46 
2025-08-08 12:23:04.130444: Current learning rate: 0.00833 
2025-08-08 12:23:22.327400: train_loss -0.5863 
2025-08-08 12:23:22.330014: val_loss -0.6307 
2025-08-08 12:23:22.330933: Pseudo dice [np.float32(0.7248)] 
2025-08-08 12:23:22.331798: Epoch time: 18.21 s 
2025-08-08 12:23:22.332612: Yayy! New best EMA pseudo Dice: 0.6933000087738037 
2025-08-08 12:23:31.890597:  
2025-08-08 12:23:31.891936: Epoch 47 
2025-08-08 12:23:31.893036: Current learning rate: 0.00829 
2025-08-08 12:23:49.973775: train_loss -0.5929 
2025-08-08 12:23:49.976299: val_loss -0.5642 
2025-08-08 12:23:49.977324: Pseudo dice [np.float32(0.6778)] 
2025-08-08 12:23:49.978222: Epoch time: 18.09 s 
2025-08-08 12:23:51.149806:  
2025-08-08 12:23:51.153106: Epoch 48 
2025-08-08 12:23:51.154093: Current learning rate: 0.00825 
2025-08-08 12:24:09.349216: train_loss -0.5376 
2025-08-08 12:24:09.351799: val_loss -0.6067 
2025-08-08 12:24:09.352865: Pseudo dice [np.float32(0.7108)] 
2025-08-08 12:24:09.353743: Epoch time: 18.2 s 
2025-08-08 12:24:09.354688: Yayy! New best EMA pseudo Dice: 0.6935999989509583 
2025-08-08 12:24:19.298152:  
2025-08-08 12:24:19.299298: Epoch 49 
2025-08-08 12:24:19.300256: Current learning rate: 0.00822 
2025-08-08 12:24:37.592722: train_loss -0.5695 
2025-08-08 12:24:37.594955: val_loss -0.5918 
2025-08-08 12:24:37.595883: Pseudo dice [np.float32(0.7048)] 
2025-08-08 12:24:37.596768: Epoch time: 18.3 s 
2025-08-08 12:24:46.095806: Yayy! New best EMA pseudo Dice: 0.6948000192642212 
2025-08-08 12:24:55.909544:  
2025-08-08 12:24:55.911618: Epoch 50 
2025-08-08 12:24:55.912670: Current learning rate: 0.00818 
2025-08-08 12:25:14.128152: train_loss -0.59 
2025-08-08 12:25:14.130737: val_loss -0.6332 
2025-08-08 12:25:14.131731: Pseudo dice [np.float32(0.732)] 
2025-08-08 12:25:14.132587: Epoch time: 18.22 s 
2025-08-08 12:25:14.133437: Yayy! New best EMA pseudo Dice: 0.6984999775886536 
2025-08-08 12:25:23.949596:  
2025-08-08 12:25:23.950765: Epoch 51 
2025-08-08 12:25:23.951740: Current learning rate: 0.00814 
2025-08-08 12:25:42.108170: train_loss -0.5474 
2025-08-08 12:25:42.110350: val_loss -0.5544 
2025-08-08 12:25:42.111131: Pseudo dice [np.float32(0.6825)] 
2025-08-08 12:25:42.111915: Epoch time: 18.16 s 
2025-08-08 12:25:43.286900:  
2025-08-08 12:25:43.289893: Epoch 52 
2025-08-08 12:25:43.290677: Current learning rate: 0.00811 
2025-08-08 12:26:01.473743: train_loss -0.581 
2025-08-08 12:26:01.476018: val_loss -0.4421 
2025-08-08 12:26:01.477003: Pseudo dice [np.float32(0.5876)] 
2025-08-08 12:26:01.477919: Epoch time: 18.19 s 
2025-08-08 12:26:02.656033:  
2025-08-08 12:26:02.657768: Epoch 53 
2025-08-08 12:26:02.659161: Current learning rate: 0.00807 
2025-08-08 12:26:20.914564: train_loss -0.5747 
2025-08-08 12:26:20.916870: val_loss -0.5194 
2025-08-08 12:26:20.917836: Pseudo dice [np.float32(0.6483)] 
2025-08-08 12:26:20.918693: Epoch time: 18.26 s 
2025-08-08 12:26:22.075982:  
2025-08-08 12:26:22.077925: Epoch 54 
2025-08-08 12:26:22.078744: Current learning rate: 0.00803 
2025-08-08 12:26:40.246056: train_loss -0.5832 
2025-08-08 12:26:40.248255: val_loss -0.6403 
2025-08-08 12:26:40.249201: Pseudo dice [np.float32(0.7416)] 
2025-08-08 12:26:40.250122: Epoch time: 18.17 s 
2025-08-08 12:26:41.433383:  
2025-08-08 12:26:41.436569: Epoch 55 
2025-08-08 12:26:41.437640: Current learning rate: 0.008 
2025-08-08 12:26:59.623248: train_loss -0.5805 
2025-08-08 12:26:59.625386: val_loss -0.6045 
2025-08-08 12:26:59.626329: Pseudo dice [np.float32(0.7218)] 
2025-08-08 12:26:59.627237: Epoch time: 18.19 s 
2025-08-08 12:27:00.812373:  
2025-08-08 12:27:00.814234: Epoch 56 
2025-08-08 12:27:00.815536: Current learning rate: 0.00796 
2025-08-08 12:27:18.999454: train_loss -0.5511 
2025-08-08 12:27:19.001870: val_loss -0.5893 
2025-08-08 12:27:19.002940: Pseudo dice [np.float32(0.6905)] 
2025-08-08 12:27:19.003927: Epoch time: 18.19 s 
2025-08-08 12:27:20.150470:  
2025-08-08 12:27:20.154016: Epoch 57 
2025-08-08 12:27:20.155104: Current learning rate: 0.00792 
2025-08-08 12:27:38.325386: train_loss -0.6143 
2025-08-08 12:27:38.327801: val_loss -0.6481 
2025-08-08 12:27:38.328729: Pseudo dice [np.float32(0.741)] 
2025-08-08 12:27:38.329550: Epoch time: 18.18 s 
2025-08-08 12:27:39.473136:  
2025-08-08 12:27:39.474851: Epoch 58 
2025-08-08 12:27:39.475615: Current learning rate: 0.00789 
2025-08-08 12:27:57.711523: train_loss -0.5928 
2025-08-08 12:27:57.714478: val_loss -0.6565 
2025-08-08 12:27:57.715373: Pseudo dice [np.float32(0.7544)] 
2025-08-08 12:27:57.716184: Epoch time: 18.24 s 
2025-08-08 12:27:57.717030: Yayy! New best EMA pseudo Dice: 0.7021999955177307 
2025-08-08 12:28:07.522446:  
2025-08-08 12:28:07.524193: Epoch 59 
2025-08-08 12:28:07.525239: Current learning rate: 0.00785 
2025-08-08 12:28:25.682844: train_loss -0.6239 
2025-08-08 12:28:25.684955: val_loss -0.6445 
2025-08-08 12:28:25.685743: Pseudo dice [np.float32(0.7377)] 
2025-08-08 12:28:25.686591: Epoch time: 18.17 s 
2025-08-08 12:28:25.687321: Yayy! New best EMA pseudo Dice: 0.7056999802589417 
2025-08-08 12:28:35.211389:  
2025-08-08 12:28:35.212999: Epoch 60 
2025-08-08 12:28:35.214206: Current learning rate: 0.00781 
2025-08-08 12:28:53.354989: train_loss -0.5495 
2025-08-08 12:28:53.357229: val_loss -0.4992 
2025-08-08 12:28:53.358191: Pseudo dice [np.float32(0.6204)] 
2025-08-08 12:28:53.359122: Epoch time: 18.15 s 
2025-08-08 12:28:54.518376:  
2025-08-08 12:28:54.521984: Epoch 61 
2025-08-08 12:28:54.522987: Current learning rate: 0.00777 
2025-08-08 12:29:12.690459: train_loss -0.5727 
2025-08-08 12:29:12.692661: val_loss -0.646 
2025-08-08 12:29:12.693484: Pseudo dice [np.float32(0.7422)] 
2025-08-08 12:29:12.694324: Epoch time: 18.18 s 
2025-08-08 12:29:13.859735:  
2025-08-08 12:29:13.861884: Epoch 62 
2025-08-08 12:29:13.862912: Current learning rate: 0.00774 
2025-08-08 12:29:31.969062: train_loss -0.5485 
2025-08-08 12:29:31.971641: val_loss -0.6252 
2025-08-08 12:29:31.972610: Pseudo dice [np.float32(0.72)] 
2025-08-08 12:29:31.973637: Epoch time: 18.11 s 
2025-08-08 12:29:33.124789:  
2025-08-08 12:29:33.128289: Epoch 63 
2025-08-08 12:29:33.129216: Current learning rate: 0.0077 
2025-08-08 12:29:51.222600: train_loss -0.6292 
2025-08-08 12:29:51.224726: val_loss -0.6216 
2025-08-08 12:29:51.225569: Pseudo dice [np.float32(0.7224)] 
2025-08-08 12:29:51.226371: Epoch time: 18.1 s 
2025-08-08 12:29:52.360615:  
2025-08-08 12:29:52.362531: Epoch 64 
2025-08-08 12:29:52.363496: Current learning rate: 0.00766 
2025-08-08 12:30:10.482771: train_loss -0.5687 
2025-08-08 12:30:10.485081: val_loss -0.5375 
2025-08-08 12:30:10.485976: Pseudo dice [np.float32(0.6522)] 
2025-08-08 12:30:10.486870: Epoch time: 18.13 s 
2025-08-08 12:30:11.642250:  
2025-08-08 12:30:11.645807: Epoch 65 
2025-08-08 12:30:11.646650: Current learning rate: 0.00763 
2025-08-08 12:30:29.781209: train_loss -0.5864 
2025-08-08 12:30:29.783702: val_loss -0.6273 
2025-08-08 12:30:29.784652: Pseudo dice [np.float32(0.7266)] 
2025-08-08 12:30:29.785652: Epoch time: 18.15 s 
2025-08-08 12:30:30.940350:  
2025-08-08 12:30:30.942695: Epoch 66 
2025-08-08 12:30:30.943838: Current learning rate: 0.00759 
2025-08-08 12:30:49.156057: train_loss -0.5793 
2025-08-08 12:30:49.158228: val_loss -0.6378 
2025-08-08 12:30:49.159100: Pseudo dice [np.float32(0.7333)] 
2025-08-08 12:30:49.159893: Epoch time: 18.22 s 
2025-08-08 12:30:49.160650: Yayy! New best EMA pseudo Dice: 0.7057999968528748 
2025-08-08 12:30:58.683250:  
2025-08-08 12:30:58.684663: Epoch 67 
2025-08-08 12:30:58.685802: Current learning rate: 0.00755 
2025-08-08 12:31:16.858914: train_loss -0.5939 
2025-08-08 12:31:16.860949: val_loss -0.6384 
2025-08-08 12:31:16.861758: Pseudo dice [np.float32(0.7451)] 
2025-08-08 12:31:16.862547: Epoch time: 18.18 s 
2025-08-08 12:31:16.863243: Yayy! New best EMA pseudo Dice: 0.7096999883651733 
2025-08-08 12:31:26.388215:  
2025-08-08 12:31:26.389548: Epoch 68 
2025-08-08 12:31:26.390705: Current learning rate: 0.00751 
2025-08-08 12:31:44.478288: train_loss -0.5786 
2025-08-08 12:31:44.480542: val_loss -0.5974 
2025-08-08 12:31:44.481405: Pseudo dice [np.float32(0.7057)] 
2025-08-08 12:31:44.482270: Epoch time: 18.09 s 
2025-08-08 12:31:45.630317:  
2025-08-08 12:31:45.633335: Epoch 69 
2025-08-08 12:31:45.634145: Current learning rate: 0.00748 
2025-08-08 12:32:03.689519: train_loss -0.5881 
2025-08-08 12:32:03.692005: val_loss -0.6874 
2025-08-08 12:32:03.692912: Pseudo dice [np.float32(0.7716)] 
2025-08-08 12:32:03.693912: Epoch time: 18.06 s 
2025-08-08 12:32:03.694683: Yayy! New best EMA pseudo Dice: 0.7156000137329102 
2025-08-08 12:32:13.233542:  
2025-08-08 12:32:13.234559: Epoch 70 
2025-08-08 12:32:13.235605: Current learning rate: 0.00744 
2025-08-08 12:32:31.283806: train_loss -0.6405 
2025-08-08 12:32:31.286062: val_loss -0.5497 
2025-08-08 12:32:31.286891: Pseudo dice [np.float32(0.6829)] 
2025-08-08 12:32:31.287650: Epoch time: 18.05 s 
2025-08-08 12:32:32.473275:  
2025-08-08 12:32:32.476170: Epoch 71 
2025-08-08 12:32:32.477054: Current learning rate: 0.0074 
2025-08-08 12:32:50.560542: train_loss -0.642 
2025-08-08 12:32:50.563098: val_loss -0.615 
2025-08-08 12:32:50.564029: Pseudo dice [np.float32(0.7246)] 
2025-08-08 12:32:50.564997: Epoch time: 18.09 s 
2025-08-08 12:32:51.743677:  
2025-08-08 12:32:51.745585: Epoch 72 
2025-08-08 12:32:51.746593: Current learning rate: 0.00737 
2025-08-08 12:33:09.821193: train_loss -0.5849 
2025-08-08 12:33:09.823799: val_loss -0.6167 
2025-08-08 12:33:09.824702: Pseudo dice [np.float32(0.729)] 
2025-08-08 12:33:09.825665: Epoch time: 18.08 s 
2025-08-08 12:33:11.587590:  
2025-08-08 12:33:11.589705: Epoch 73 
2025-08-08 12:33:11.590643: Current learning rate: 0.00733 
2025-08-08 12:33:29.741329: train_loss -0.615 
2025-08-08 12:33:29.744676: val_loss -0.5791 
2025-08-08 12:33:29.745566: Pseudo dice [np.float32(0.7027)] 
2025-08-08 12:33:29.746370: Epoch time: 18.16 s 
2025-08-08 12:33:30.927151:  
2025-08-08 12:33:30.930404: Epoch 74 
2025-08-08 12:33:30.931242: Current learning rate: 0.00729 
2025-08-08 12:33:49.105064: train_loss -0.5101 
2025-08-08 12:33:49.107165: val_loss -0.6361 
2025-08-08 12:33:49.108153: Pseudo dice [np.float32(0.7395)] 
2025-08-08 12:33:49.109160: Epoch time: 18.18 s 
2025-08-08 12:33:49.110030: Yayy! New best EMA pseudo Dice: 0.7164000272750854 
2025-08-08 12:33:58.661696:  
2025-08-08 12:33:58.663172: Epoch 75 
2025-08-08 12:33:58.664257: Current learning rate: 0.00725 
2025-08-08 12:34:16.757268: train_loss -0.6036 
2025-08-08 12:34:16.760059: val_loss -0.6459 
2025-08-08 12:34:16.761361: Pseudo dice [np.float32(0.7539)] 
2025-08-08 12:34:16.762372: Epoch time: 18.1 s 
2025-08-08 12:34:16.763208: Yayy! New best EMA pseudo Dice: 0.7200999855995178 
2025-08-08 12:34:26.336839:  
2025-08-08 12:34:26.338077: Epoch 76 
2025-08-08 12:34:26.339044: Current learning rate: 0.00722 
2025-08-08 12:34:44.457363: train_loss -0.6096 
2025-08-08 12:34:44.459876: val_loss -0.6023 
2025-08-08 12:34:44.460708: Pseudo dice [np.float32(0.7139)] 
2025-08-08 12:34:44.461436: Epoch time: 18.13 s 
2025-08-08 12:34:45.611066:  
2025-08-08 12:34:45.614110: Epoch 77 
2025-08-08 12:34:45.614983: Current learning rate: 0.00718 
2025-08-08 12:35:03.766808: train_loss -0.6329 
2025-08-08 12:35:03.768948: val_loss -0.7087 
2025-08-08 12:35:03.769829: Pseudo dice [np.float32(0.7915)] 
2025-08-08 12:35:03.770662: Epoch time: 18.16 s 
2025-08-08 12:35:03.771417: Yayy! New best EMA pseudo Dice: 0.7267000079154968 
2025-08-08 12:35:13.333697:  
2025-08-08 12:35:13.334930: Epoch 78 
2025-08-08 12:35:13.336120: Current learning rate: 0.00714 
2025-08-08 12:35:31.498403: train_loss -0.5702 
2025-08-08 12:35:31.500507: val_loss -0.5755 
2025-08-08 12:35:31.501343: Pseudo dice [np.float32(0.7006)] 
2025-08-08 12:35:31.502158: Epoch time: 18.17 s 
2025-08-08 12:35:32.743917:  
2025-08-08 12:35:32.746763: Epoch 79 
2025-08-08 12:35:32.747545: Current learning rate: 0.0071 
2025-08-08 12:35:51.039005: train_loss -0.6341 
2025-08-08 12:35:51.041265: val_loss -0.6777 
2025-08-08 12:35:51.042144: Pseudo dice [np.float32(0.7661)] 
2025-08-08 12:35:51.042922: Epoch time: 18.3 s 
2025-08-08 12:35:51.043836: Yayy! New best EMA pseudo Dice: 0.7282999753952026 
2025-08-08 12:36:00.588980:  
2025-08-08 12:36:00.590065: Epoch 80 
2025-08-08 12:36:00.591160: Current learning rate: 0.00707 
2025-08-08 12:36:18.735739: train_loss -0.6097 
2025-08-08 12:36:18.738578: val_loss -0.6456 
2025-08-08 12:36:18.739576: Pseudo dice [np.float32(0.746)] 
2025-08-08 12:36:18.740636: Epoch time: 18.15 s 
2025-08-08 12:36:18.741566: Yayy! New best EMA pseudo Dice: 0.7300999760627747 
2025-08-08 12:36:28.315485:  
2025-08-08 12:36:28.316958: Epoch 81 
2025-08-08 12:36:28.317956: Current learning rate: 0.00703 
2025-08-08 12:36:46.631547: train_loss -0.6396 
2025-08-08 12:36:46.633751: val_loss -0.4897 
2025-08-08 12:36:46.634564: Pseudo dice [np.float32(0.6259)] 
2025-08-08 12:36:46.635373: Epoch time: 18.32 s 
2025-08-08 12:36:47.864376:  
2025-08-08 12:36:47.867466: Epoch 82 
2025-08-08 12:36:47.870220: Current learning rate: 0.00699 
2025-08-08 12:37:05.911233: train_loss -0.6391 
2025-08-08 12:37:05.913543: val_loss -0.6142 
2025-08-08 12:37:05.914469: Pseudo dice [np.float32(0.7344)] 
2025-08-08 12:37:05.915288: Epoch time: 18.05 s 
2025-08-08 12:37:07.097254:  
2025-08-08 12:37:07.099186: Epoch 83 
2025-08-08 12:37:07.100135: Current learning rate: 0.00696 
2025-08-08 12:37:25.257590: train_loss -0.6369 
2025-08-08 12:37:25.259966: val_loss -0.6484 
2025-08-08 12:37:25.261202: Pseudo dice [np.float32(0.7485)] 
2025-08-08 12:37:25.262379: Epoch time: 18.16 s 
2025-08-08 12:37:26.434535:  
2025-08-08 12:37:26.437938: Epoch 84 
2025-08-08 12:37:26.439009: Current learning rate: 0.00692 
2025-08-08 12:37:44.547346: train_loss -0.6353 
2025-08-08 12:37:44.549948: val_loss -0.6099 
2025-08-08 12:37:44.550981: Pseudo dice [np.float32(0.7282)] 
2025-08-08 12:37:44.551924: Epoch time: 18.12 s 
2025-08-08 12:37:45.723762:  
2025-08-08 12:37:45.725416: Epoch 85 
2025-08-08 12:37:45.726295: Current learning rate: 0.00688 
2025-08-08 12:38:03.800098: train_loss -0.6217 
2025-08-08 12:38:03.802566: val_loss -0.6279 
2025-08-08 12:38:03.803453: Pseudo dice [np.float32(0.732)] 
2025-08-08 12:38:03.804251: Epoch time: 18.08 s 
2025-08-08 12:38:04.996017:  
2025-08-08 12:38:04.999228: Epoch 86 
2025-08-08 12:38:05.000139: Current learning rate: 0.00684 
2025-08-08 12:38:23.146305: train_loss -0.6052 
2025-08-08 12:38:23.148557: val_loss -0.5597 
2025-08-08 12:38:23.149620: Pseudo dice [np.float32(0.6882)] 
2025-08-08 12:38:23.150610: Epoch time: 18.15 s 
2025-08-08 12:38:24.327032:  
2025-08-08 12:38:24.328689: Epoch 87 
2025-08-08 12:38:24.329476: Current learning rate: 0.0068 
2025-08-08 12:38:42.478082: train_loss -0.6137 
2025-08-08 12:38:42.480275: val_loss -0.6348 
2025-08-08 12:38:42.481138: Pseudo dice [np.float32(0.7331)] 
2025-08-08 12:38:42.481949: Epoch time: 18.15 s 
2025-08-08 12:38:43.619798:  
2025-08-08 12:38:43.622818: Epoch 88 
2025-08-08 12:38:43.623686: Current learning rate: 0.00677 
2025-08-08 12:39:01.631926: train_loss -0.6336 
2025-08-08 12:39:01.634100: val_loss -0.6626 
2025-08-08 12:39:01.634979: Pseudo dice [np.float32(0.7521)] 
2025-08-08 12:39:01.635812: Epoch time: 18.02 s 
2025-08-08 12:39:02.809903:  
2025-08-08 12:39:02.812159: Epoch 89 
2025-08-08 12:39:02.813328: Current learning rate: 0.00673 
2025-08-08 12:39:20.862273: train_loss -0.6009 
2025-08-08 12:39:20.864591: val_loss -0.4797 
2025-08-08 12:39:20.865547: Pseudo dice [np.float32(0.6202)] 
2025-08-08 12:39:20.866491: Epoch time: 18.06 s 
2025-08-08 12:39:21.993328:  
2025-08-08 12:39:21.996337: Epoch 90 
2025-08-08 12:39:21.997077: Current learning rate: 0.00669 
2025-08-08 12:39:40.030276: train_loss -0.5688 
2025-08-08 12:39:40.032599: val_loss -0.6007 
2025-08-08 12:39:40.033549: Pseudo dice [np.float32(0.7031)] 
2025-08-08 12:39:40.034441: Epoch time: 18.04 s 
2025-08-08 12:39:41.191459:  
2025-08-08 12:39:41.193362: Epoch 91 
2025-08-08 12:39:41.194426: Current learning rate: 0.00665 
2025-08-08 12:39:59.275180: train_loss -0.6198 
2025-08-08 12:39:59.277630: val_loss -0.6429 
2025-08-08 12:39:59.278537: Pseudo dice [np.float32(0.7458)] 
2025-08-08 12:39:59.279386: Epoch time: 18.09 s 
2025-08-08 12:40:00.449420:  
2025-08-08 12:40:00.452685: Epoch 92 
2025-08-08 12:40:00.453815: Current learning rate: 0.00662 
2025-08-08 12:40:18.518710: train_loss -0.6319 
2025-08-08 12:40:18.521205: val_loss -0.6652 
2025-08-08 12:40:18.522179: Pseudo dice [np.float32(0.7615)] 
2025-08-08 12:40:18.523129: Epoch time: 18.07 s 
2025-08-08 12:40:19.683393:  
2025-08-08 12:40:19.685475: Epoch 93 
2025-08-08 12:40:19.686407: Current learning rate: 0.00658 
2025-08-08 12:40:37.760308: train_loss -0.6227 
2025-08-08 12:40:37.763083: val_loss -0.5386 
2025-08-08 12:40:37.764164: Pseudo dice [np.float32(0.6801)] 
2025-08-08 12:40:37.764998: Epoch time: 18.08 s 
2025-08-08 12:40:38.947032:  
2025-08-08 12:40:38.950103: Epoch 94 
2025-08-08 12:40:38.950898: Current learning rate: 0.00654 
2025-08-08 12:40:57.154319: train_loss -0.6165 
2025-08-08 12:40:57.156517: val_loss -0.6901 
2025-08-08 12:40:57.157424: Pseudo dice [np.float32(0.7786)] 
2025-08-08 12:40:57.158209: Epoch time: 18.21 s 
2025-08-08 12:40:58.912111:  
2025-08-08 12:40:58.914396: Epoch 95 
2025-08-08 12:40:58.915464: Current learning rate: 0.0065 
2025-08-08 12:41:17.096266: train_loss -0.632 
2025-08-08 12:41:17.098606: val_loss -0.5197 
2025-08-08 12:41:17.099488: Pseudo dice [np.float32(0.6299)] 
2025-08-08 12:41:17.100275: Epoch time: 18.19 s 
2025-08-08 12:41:18.268758:  
2025-08-08 12:41:18.272157: Epoch 96 
2025-08-08 12:41:18.273014: Current learning rate: 0.00647 
2025-08-08 12:41:36.402677: train_loss -0.625 
2025-08-08 12:41:36.404817: val_loss -0.4816 
2025-08-08 12:41:36.405817: Pseudo dice [np.float32(0.6116)] 
2025-08-08 12:41:36.406726: Epoch time: 18.14 s 
2025-08-08 12:41:37.599070:  
2025-08-08 12:41:37.600980: Epoch 97 
2025-08-08 12:41:37.602093: Current learning rate: 0.00643 
2025-08-08 12:41:55.699297: train_loss -0.6246 
2025-08-08 12:41:55.701976: val_loss -0.6447 
2025-08-08 12:41:55.702983: Pseudo dice [np.float32(0.7406)] 
2025-08-08 12:41:55.704102: Epoch time: 18.1 s 
2025-08-08 12:41:56.877765:  
2025-08-08 12:41:56.881371: Epoch 98 
2025-08-08 12:41:56.882537: Current learning rate: 0.00639 
2025-08-08 12:42:14.965504: train_loss -0.6429 
2025-08-08 12:42:14.967964: val_loss -0.6286 
2025-08-08 12:42:14.968995: Pseudo dice [np.float32(0.7309)] 
2025-08-08 12:42:14.970036: Epoch time: 18.09 s 
2025-08-08 12:42:16.155640:  
2025-08-08 12:42:16.157950: Epoch 99 
2025-08-08 12:42:16.159071: Current learning rate: 0.00635 
2025-08-08 12:42:34.436128: train_loss -0.6519 
2025-08-08 12:42:34.438354: val_loss -0.6527 
2025-08-08 12:42:34.439386: Pseudo dice [np.float32(0.7605)] 
2025-08-08 12:42:34.440523: Epoch time: 18.29 s 
2025-08-08 12:42:43.970184:  
2025-08-08 12:42:43.971693: Epoch 100 
2025-08-08 12:42:43.972685: Current learning rate: 0.00631 
2025-08-08 12:43:02.122554: train_loss -0.6605 
2025-08-08 12:43:02.124712: val_loss -0.6225 
2025-08-08 12:43:02.125527: Pseudo dice [np.float32(0.7255)] 
2025-08-08 12:43:02.126283: Epoch time: 18.16 s 
2025-08-08 12:43:03.322030:  
2025-08-08 12:43:03.325019: Epoch 101 
2025-08-08 12:43:03.325744: Current learning rate: 0.00628 
2025-08-08 12:43:21.385532: train_loss -0.671 
2025-08-08 12:43:21.387918: val_loss -0.5943 
2025-08-08 12:43:21.388954: Pseudo dice [np.float32(0.7181)] 
2025-08-08 12:43:21.389894: Epoch time: 18.07 s 
2025-08-08 12:43:22.563284:  
2025-08-08 12:43:22.565214: Epoch 102 
2025-08-08 12:43:22.566133: Current learning rate: 0.00624 
2025-08-08 12:43:40.765096: train_loss -0.6097 
2025-08-08 12:43:40.767272: val_loss -0.6619 
2025-08-08 12:43:40.768088: Pseudo dice [np.float32(0.7655)] 
2025-08-08 12:43:40.768852: Epoch time: 18.21 s 
2025-08-08 12:43:41.951300:  
2025-08-08 12:43:41.954230: Epoch 103 
2025-08-08 12:43:41.955076: Current learning rate: 0.0062 
2025-08-08 12:44:00.139108: train_loss -0.6373 
2025-08-08 12:44:00.141394: val_loss -0.6842 
2025-08-08 12:44:00.142442: Pseudo dice [np.float32(0.7767)] 
2025-08-08 12:44:00.143279: Epoch time: 18.19 s 
2025-08-08 12:44:01.320248:  
2025-08-08 12:44:01.322296: Epoch 104 
2025-08-08 12:44:01.323220: Current learning rate: 0.00616 
2025-08-08 12:44:19.445514: train_loss -0.6387 
2025-08-08 12:44:19.447538: val_loss -0.6588 
2025-08-08 12:44:19.448436: Pseudo dice [np.float32(0.7501)] 
2025-08-08 12:44:19.449253: Epoch time: 18.13 s 
2025-08-08 12:44:20.621089:  
2025-08-08 12:44:20.624079: Epoch 105 
2025-08-08 12:44:20.625074: Current learning rate: 0.00612 
2025-08-08 12:44:38.779632: train_loss -0.6449 
2025-08-08 12:44:38.781769: val_loss -0.5207 
2025-08-08 12:44:38.782648: Pseudo dice [np.float32(0.6323)] 
2025-08-08 12:44:38.783453: Epoch time: 18.16 s 
2025-08-08 12:44:39.974108:  
2025-08-08 12:44:39.976047: Epoch 106 
2025-08-08 12:44:39.976976: Current learning rate: 0.00609 
2025-08-08 12:44:58.076203: train_loss -0.6502 
2025-08-08 12:44:58.078247: val_loss -0.6857 
2025-08-08 12:44:58.079164: Pseudo dice [np.float32(0.7802)] 
2025-08-08 12:44:58.080019: Epoch time: 18.11 s 
2025-08-08 12:44:59.272613:  
2025-08-08 12:44:59.275841: Epoch 107 
2025-08-08 12:44:59.276962: Current learning rate: 0.00605 
2025-08-08 12:45:17.409893: train_loss -0.6367 
2025-08-08 12:45:17.412859: val_loss -0.666 
2025-08-08 12:45:17.413931: Pseudo dice [np.float32(0.7576)] 
2025-08-08 12:45:17.415131: Epoch time: 18.14 s 
2025-08-08 12:45:18.586232:  
2025-08-08 12:45:18.588299: Epoch 108 
2025-08-08 12:45:18.589451: Current learning rate: 0.00601 
2025-08-08 12:45:36.712609: train_loss -0.6225 
2025-08-08 12:45:36.715072: val_loss -0.6845 
2025-08-08 12:45:36.716016: Pseudo dice [np.float32(0.7706)] 
2025-08-08 12:45:36.716871: Epoch time: 18.13 s 
2025-08-08 12:45:36.717916: Yayy! New best EMA pseudo Dice: 0.7328000068664551 
2025-08-08 12:45:46.231783:  
2025-08-08 12:45:46.232978: Epoch 109 
2025-08-08 12:45:46.234240: Current learning rate: 0.00597 
2025-08-08 12:46:04.427710: train_loss -0.6605 
2025-08-08 12:46:04.430165: val_loss -0.6517 
2025-08-08 12:46:04.431026: Pseudo dice [np.float32(0.7528)] 
2025-08-08 12:46:04.431866: Epoch time: 18.2 s 
2025-08-08 12:46:04.432638: Yayy! New best EMA pseudo Dice: 0.7347999811172485 
2025-08-08 12:46:14.108592:  
2025-08-08 12:46:14.109685: Epoch 110 
2025-08-08 12:46:14.110551: Current learning rate: 0.00593 
2025-08-08 12:46:32.171543: train_loss -0.6804 
2025-08-08 12:46:32.173712: val_loss -0.6496 
2025-08-08 12:46:32.174738: Pseudo dice [np.float32(0.7389)] 
2025-08-08 12:46:32.175558: Epoch time: 18.07 s 
2025-08-08 12:46:32.176342: Yayy! New best EMA pseudo Dice: 0.7351999878883362 
2025-08-08 12:46:41.706935:  
2025-08-08 12:46:41.708114: Epoch 111 
2025-08-08 12:46:41.709208: Current learning rate: 0.0059 
2025-08-08 12:46:59.835298: train_loss -0.6235 
2025-08-08 12:46:59.837736: val_loss -0.6653 
2025-08-08 12:46:59.838668: Pseudo dice [np.float32(0.7539)] 
2025-08-08 12:46:59.839619: Epoch time: 18.13 s 
2025-08-08 12:46:59.840435: Yayy! New best EMA pseudo Dice: 0.7371000051498413 
2025-08-08 12:47:09.380981:  
2025-08-08 12:47:09.382080: Epoch 112 
2025-08-08 12:47:09.383070: Current learning rate: 0.00586 
2025-08-08 12:47:27.459214: train_loss -0.6957 
2025-08-08 12:47:27.461863: val_loss -0.6756 
2025-08-08 12:47:27.462703: Pseudo dice [np.float32(0.7686)] 
2025-08-08 12:47:27.463611: Epoch time: 18.08 s 
2025-08-08 12:47:27.464566: Yayy! New best EMA pseudo Dice: 0.7402999997138977 
2025-08-08 12:47:37.024443:  
2025-08-08 12:47:37.025744: Epoch 113 
2025-08-08 12:47:37.026756: Current learning rate: 0.00582 
2025-08-08 12:47:55.151504: train_loss -0.6636 
2025-08-08 12:47:55.153764: val_loss -0.6468 
2025-08-08 12:47:55.154802: Pseudo dice [np.float32(0.7536)] 
2025-08-08 12:47:55.155763: Epoch time: 18.13 s 
2025-08-08 12:47:55.156706: Yayy! New best EMA pseudo Dice: 0.741599977016449 
2025-08-08 12:48:04.601467:  
2025-08-08 12:48:04.602642: Epoch 114 
2025-08-08 12:48:04.603647: Current learning rate: 0.00578 
2025-08-08 12:48:22.845813: train_loss -0.6562 
2025-08-08 12:48:22.847983: val_loss -0.6968 
2025-08-08 12:48:22.848849: Pseudo dice [np.float32(0.7837)] 
2025-08-08 12:48:22.849626: Epoch time: 18.25 s 
2025-08-08 12:48:22.850362: Yayy! New best EMA pseudo Dice: 0.7458000183105469 
2025-08-08 12:48:32.587407:  
2025-08-08 12:48:32.588602: Epoch 115 
2025-08-08 12:48:32.589712: Current learning rate: 0.00574 
2025-08-08 12:48:50.762919: train_loss -0.658 
2025-08-08 12:48:50.765278: val_loss -0.6858 
2025-08-08 12:48:50.766194: Pseudo dice [np.float32(0.7609)] 
2025-08-08 12:48:50.767233: Epoch time: 18.18 s 
2025-08-08 12:48:50.768050: Yayy! New best EMA pseudo Dice: 0.7473000288009644 
2025-08-08 12:49:00.602867:  
2025-08-08 12:49:00.604149: Epoch 116 
2025-08-08 12:49:00.605321: Current learning rate: 0.0057 
2025-08-08 12:49:18.800910: train_loss -0.6217 
2025-08-08 12:49:18.803202: val_loss -0.6586 
2025-08-08 12:49:18.804113: Pseudo dice [np.float32(0.7607)] 
2025-08-08 12:49:18.805374: Epoch time: 18.2 s 
2025-08-08 12:49:18.806353: Yayy! New best EMA pseudo Dice: 0.7487000226974487 
2025-08-08 12:49:28.393891:  
2025-08-08 12:49:28.395051: Epoch 117 
2025-08-08 12:49:28.395858: Current learning rate: 0.00567 
2025-08-08 12:49:46.558849: train_loss -0.609 
2025-08-08 12:49:46.560961: val_loss -0.6545 
2025-08-08 12:49:46.561852: Pseudo dice [np.float32(0.756)] 
2025-08-08 12:49:46.562812: Epoch time: 18.17 s 
2025-08-08 12:49:46.563731: Yayy! New best EMA pseudo Dice: 0.7494000196456909 
2025-08-08 12:49:56.141830:  
2025-08-08 12:49:56.142900: Epoch 118 
2025-08-08 12:49:56.143838: Current learning rate: 0.00563 
2025-08-08 12:50:14.351773: train_loss -0.6245 
2025-08-08 12:50:14.353982: val_loss -0.6709 
2025-08-08 12:50:14.354947: Pseudo dice [np.float32(0.769)] 
2025-08-08 12:50:14.355829: Epoch time: 18.21 s 
2025-08-08 12:50:14.356790: Yayy! New best EMA pseudo Dice: 0.7513999938964844 
2025-08-08 12:50:24.490124:  
2025-08-08 12:50:24.491120: Epoch 119 
2025-08-08 12:50:24.491966: Current learning rate: 0.00559 
2025-08-08 12:50:42.673392: train_loss -0.611 
2025-08-08 12:50:42.675488: val_loss -0.6761 
2025-08-08 12:50:42.676338: Pseudo dice [np.float32(0.759)] 
2025-08-08 12:50:42.677207: Epoch time: 18.19 s 
2025-08-08 12:50:42.678151: Yayy! New best EMA pseudo Dice: 0.7520999908447266 
2025-08-08 12:50:52.548501:  
2025-08-08 12:50:52.549946: Epoch 120 
2025-08-08 12:50:52.551236: Current learning rate: 0.00555 
2025-08-08 12:51:10.763093: train_loss -0.6688 
2025-08-08 12:51:10.765582: val_loss -0.6372 
2025-08-08 12:51:10.766574: Pseudo dice [np.float32(0.7418)] 
2025-08-08 12:51:10.767439: Epoch time: 18.22 s 
2025-08-08 12:51:11.967105:  
2025-08-08 12:51:11.970456: Epoch 121 
2025-08-08 12:51:11.971516: Current learning rate: 0.00551 
2025-08-08 12:51:30.104168: train_loss -0.6569 
2025-08-08 12:51:30.106321: val_loss -0.671 
2025-08-08 12:51:30.107312: Pseudo dice [np.float32(0.7702)] 
2025-08-08 12:51:30.108314: Epoch time: 18.14 s 
2025-08-08 12:51:30.109222: Yayy! New best EMA pseudo Dice: 0.753000020980835 
2025-08-08 12:51:39.980628:  
2025-08-08 12:51:39.981978: Epoch 122 
2025-08-08 12:51:39.983010: Current learning rate: 0.00547 
2025-08-08 12:51:58.063211: train_loss -0.6526 
2025-08-08 12:51:58.065519: val_loss -0.6808 
2025-08-08 12:51:58.066356: Pseudo dice [np.float32(0.7687)] 
2025-08-08 12:51:58.067096: Epoch time: 18.09 s 
2025-08-08 12:51:58.067820: Yayy! New best EMA pseudo Dice: 0.7545999884605408 
2025-08-08 12:52:07.755336:  
2025-08-08 12:52:07.756725: Epoch 123 
2025-08-08 12:52:07.757986: Current learning rate: 0.00544 
2025-08-08 12:52:25.897518: train_loss -0.6658 
2025-08-08 12:52:25.899922: val_loss -0.66 
2025-08-08 12:52:25.900834: Pseudo dice [np.float32(0.7558)] 
2025-08-08 12:52:25.901609: Epoch time: 18.15 s 
2025-08-08 12:52:25.902486: Yayy! New best EMA pseudo Dice: 0.7547000050544739 
2025-08-08 12:52:35.530041:  
2025-08-08 12:52:35.531352: Epoch 124 
2025-08-08 12:52:35.532482: Current learning rate: 0.0054 
2025-08-08 12:52:53.587519: train_loss -0.648 
2025-08-08 12:52:53.590204: val_loss -0.6475 
2025-08-08 12:52:53.591300: Pseudo dice [np.float32(0.7579)] 
2025-08-08 12:52:53.592249: Epoch time: 18.06 s 
2025-08-08 12:52:53.593169: Yayy! New best EMA pseudo Dice: 0.7549999952316284 
2025-08-08 12:53:03.159100:  
2025-08-08 12:53:03.160286: Epoch 125 
2025-08-08 12:53:03.161312: Current learning rate: 0.00536 
2025-08-08 12:53:21.239994: train_loss -0.6785 
2025-08-08 12:53:21.242313: val_loss -0.6784 
2025-08-08 12:53:21.243203: Pseudo dice [np.float32(0.7771)] 
2025-08-08 12:53:21.244088: Epoch time: 18.09 s 
2025-08-08 12:53:21.244899: Yayy! New best EMA pseudo Dice: 0.7572000026702881 
2025-08-08 12:53:30.823947:  
2025-08-08 12:53:30.825255: Epoch 126 
2025-08-08 12:53:30.826407: Current learning rate: 0.00532 
2025-08-08 12:53:48.856314: train_loss -0.6383 
2025-08-08 12:53:48.858686: val_loss -0.7078 
2025-08-08 12:53:48.859712: Pseudo dice [np.float32(0.792)] 
2025-08-08 12:53:48.860639: Epoch time: 18.04 s 
2025-08-08 12:53:48.861462: Yayy! New best EMA pseudo Dice: 0.760699987411499 
2025-08-08 12:53:58.394320:  
2025-08-08 12:53:58.395489: Epoch 127 
2025-08-08 12:53:58.396430: Current learning rate: 0.00528 
2025-08-08 12:54:16.408186: train_loss -0.6412 
2025-08-08 12:54:16.410358: val_loss -0.6863 
2025-08-08 12:54:16.411379: Pseudo dice [np.float32(0.7727)] 
2025-08-08 12:54:16.412278: Epoch time: 18.02 s 
2025-08-08 12:54:16.413139: Yayy! New best EMA pseudo Dice: 0.761900007724762 
2025-08-08 12:54:25.903478:  
2025-08-08 12:54:25.904998: Epoch 128 
2025-08-08 12:54:25.906043: Current learning rate: 0.00524 
2025-08-08 12:54:43.994127: train_loss -0.6699 
2025-08-08 12:54:43.996279: val_loss -0.5577 
2025-08-08 12:54:43.997132: Pseudo dice [np.float32(0.6949)] 
2025-08-08 12:54:43.997909: Epoch time: 18.1 s 
2025-08-08 12:54:45.171198:  
2025-08-08 12:54:45.173497: Epoch 129 
2025-08-08 12:54:45.174595: Current learning rate: 0.0052 
2025-08-08 12:55:03.316523: train_loss -0.6585 
2025-08-08 12:55:03.318666: val_loss -0.6954 
2025-08-08 12:55:03.319557: Pseudo dice [np.float32(0.7898)] 
2025-08-08 12:55:03.320390: Epoch time: 18.15 s 
2025-08-08 12:55:04.502774:  
2025-08-08 12:55:04.506297: Epoch 130 
2025-08-08 12:55:04.507302: Current learning rate: 0.00517 
2025-08-08 12:55:22.744642: train_loss -0.6831 
2025-08-08 12:55:22.747030: val_loss -0.6973 
2025-08-08 12:55:22.747963: Pseudo dice [np.float32(0.7852)] 
2025-08-08 12:55:22.748970: Epoch time: 18.25 s 
2025-08-08 12:55:23.916014:  
2025-08-08 12:55:23.918104: Epoch 131 
2025-08-08 12:55:23.919376: Current learning rate: 0.00513 
2025-08-08 12:55:42.115179: train_loss -0.6678 
2025-08-08 12:55:42.117786: val_loss -0.6672 
2025-08-08 12:55:42.118838: Pseudo dice [np.float32(0.7561)] 
2025-08-08 12:55:42.119768: Epoch time: 18.2 s 
2025-08-08 12:55:43.282586:  
2025-08-08 12:55:43.285629: Epoch 132 
2025-08-08 12:55:43.286500: Current learning rate: 0.00509 
2025-08-08 12:56:01.405104: train_loss -0.7158 
2025-08-08 12:56:01.407416: val_loss -0.6456 
2025-08-08 12:56:01.408235: Pseudo dice [np.float32(0.7374)] 
2025-08-08 12:56:01.408969: Epoch time: 18.13 s 
2025-08-08 12:56:02.576960:  
2025-08-08 12:56:02.578953: Epoch 133 
2025-08-08 12:56:02.579756: Current learning rate: 0.00505 
2025-08-08 12:56:20.751639: train_loss -0.6955 
2025-08-08 12:56:20.753897: val_loss -0.6744 
2025-08-08 12:56:20.754759: Pseudo dice [np.float32(0.7709)] 
2025-08-08 12:56:20.755615: Epoch time: 18.18 s 
2025-08-08 12:56:21.952875:  
2025-08-08 12:56:21.956139: Epoch 134 
2025-08-08 12:56:21.957051: Current learning rate: 0.00501 
2025-08-08 12:56:40.092615: train_loss -0.6493 
2025-08-08 12:56:40.094955: val_loss -0.6644 
2025-08-08 12:56:40.096008: Pseudo dice [np.float32(0.7618)] 
2025-08-08 12:56:40.097040: Epoch time: 18.14 s 
2025-08-08 12:56:41.279468:  
2025-08-08 12:56:41.281490: Epoch 135 
2025-08-08 12:56:41.282606: Current learning rate: 0.00497 
2025-08-08 12:56:59.400429: train_loss -0.6581 
2025-08-08 12:56:59.402630: val_loss -0.6701 
2025-08-08 12:56:59.403600: Pseudo dice [np.float32(0.7662)] 
2025-08-08 12:56:59.404644: Epoch time: 18.13 s 
2025-08-08 12:57:00.595243:  
2025-08-08 12:57:00.598707: Epoch 136 
2025-08-08 12:57:00.599776: Current learning rate: 0.00493 
2025-08-08 12:57:18.674554: train_loss -0.6576 
2025-08-08 12:57:18.676902: val_loss -0.667 
2025-08-08 12:57:18.677868: Pseudo dice [np.float32(0.7593)] 
2025-08-08 12:57:18.678789: Epoch time: 18.08 s 
2025-08-08 12:57:19.881773:  
2025-08-08 12:57:19.883742: Epoch 137 
2025-08-08 12:57:19.884647: Current learning rate: 0.00489 
2025-08-08 12:57:38.016820: train_loss -0.6462 
2025-08-08 12:57:38.019472: val_loss -0.6234 
2025-08-08 12:57:38.020530: Pseudo dice [np.float32(0.7458)] 
2025-08-08 12:57:38.021539: Epoch time: 18.14 s 
2025-08-08 12:57:39.276795:  
2025-08-08 12:57:39.279980: Epoch 138 
2025-08-08 12:57:39.280779: Current learning rate: 0.00485 
2025-08-08 12:57:57.417039: train_loss -0.6799 
2025-08-08 12:57:57.419234: val_loss -0.6823 
2025-08-08 12:57:57.420170: Pseudo dice [np.float32(0.7726)] 
2025-08-08 12:57:57.420987: Epoch time: 18.14 s 
2025-08-08 12:57:59.140410:  
2025-08-08 12:57:59.142891: Epoch 139 
2025-08-08 12:57:59.143758: Current learning rate: 0.00482 
2025-08-08 12:58:17.403342: train_loss -0.6857 
2025-08-08 12:58:17.405576: val_loss -0.6389 
2025-08-08 12:58:17.406511: Pseudo dice [np.float32(0.7466)] 
2025-08-08 12:58:17.407376: Epoch time: 18.27 s 
2025-08-08 12:58:18.598450:  
2025-08-08 12:58:18.600614: Epoch 140 
2025-08-08 12:58:18.601852: Current learning rate: 0.00478 
2025-08-08 12:58:36.748294: train_loss -0.6504 
2025-08-08 12:58:36.751080: val_loss -0.6831 
2025-08-08 12:58:36.751983: Pseudo dice [np.float32(0.7813)] 
2025-08-08 12:58:36.752903: Epoch time: 18.15 s 
2025-08-08 12:58:37.953533:  
2025-08-08 12:58:37.956853: Epoch 141 
2025-08-08 12:58:37.958033: Current learning rate: 0.00474 
2025-08-08 12:58:56.134241: train_loss -0.6667 
2025-08-08 12:58:56.136718: val_loss -0.7251 
2025-08-08 12:58:56.137657: Pseudo dice [np.float32(0.7981)] 
2025-08-08 12:58:56.138605: Epoch time: 18.18 s 
2025-08-08 12:58:56.139472: Yayy! New best EMA pseudo Dice: 0.7649000287055969 
2025-08-08 12:59:05.694353:  
2025-08-08 12:59:05.695879: Epoch 142 
2025-08-08 12:59:05.697076: Current learning rate: 0.0047 
2025-08-08 12:59:23.862409: train_loss -0.6925 
2025-08-08 12:59:23.864559: val_loss -0.7109 
2025-08-08 12:59:23.865527: Pseudo dice [np.float32(0.7969)] 
2025-08-08 12:59:23.866383: Epoch time: 18.17 s 
2025-08-08 12:59:23.867202: Yayy! New best EMA pseudo Dice: 0.7681000232696533 
2025-08-08 12:59:33.457924:  
2025-08-08 12:59:33.459364: Epoch 143 
2025-08-08 12:59:33.460759: Current learning rate: 0.00466 
2025-08-08 12:59:51.665015: train_loss -0.7136 
2025-08-08 12:59:51.667170: val_loss -0.686 
2025-08-08 12:59:51.668127: Pseudo dice [np.float32(0.7753)] 
2025-08-08 12:59:51.669111: Epoch time: 18.21 s 
2025-08-08 12:59:51.670149: Yayy! New best EMA pseudo Dice: 0.7688000202178955 
2025-08-08 13:00:01.213237:  
2025-08-08 13:00:01.214514: Epoch 144 
2025-08-08 13:00:01.215625: Current learning rate: 0.00462 
2025-08-08 13:00:19.376923: train_loss -0.7041 
2025-08-08 13:00:19.380518: val_loss -0.7139 
2025-08-08 13:00:19.381334: Pseudo dice [np.float32(0.8018)] 
2025-08-08 13:00:19.382106: Epoch time: 18.17 s 
2025-08-08 13:00:19.382885: Yayy! New best EMA pseudo Dice: 0.7720999717712402 
2025-08-08 13:00:28.966665:  
2025-08-08 13:00:28.967747: Epoch 145 
2025-08-08 13:00:28.968592: Current learning rate: 0.00458 
2025-08-08 13:00:47.120050: train_loss -0.6346 
2025-08-08 13:00:47.122064: val_loss -0.6659 
2025-08-08 13:00:47.122912: Pseudo dice [np.float32(0.764)] 
2025-08-08 13:00:47.123694: Epoch time: 18.16 s 
2025-08-08 13:00:48.329857:  
2025-08-08 13:00:48.333061: Epoch 146 
2025-08-08 13:00:48.333960: Current learning rate: 0.00454 
2025-08-08 13:01:06.526355: train_loss -0.6807 
2025-08-08 13:01:06.528570: val_loss -0.7032 
2025-08-08 13:01:06.529577: Pseudo dice [np.float32(0.7852)] 
2025-08-08 13:01:06.530430: Epoch time: 18.2 s 
2025-08-08 13:01:06.531220: Yayy! New best EMA pseudo Dice: 0.7727000117301941 
2025-08-08 13:01:16.111765:  
2025-08-08 13:01:16.112903: Epoch 147 
2025-08-08 13:01:16.113714: Current learning rate: 0.0045 
2025-08-08 13:01:34.231246: train_loss -0.6879 
2025-08-08 13:01:34.233740: val_loss -0.6066 
2025-08-08 13:01:34.234567: Pseudo dice [np.float32(0.7127)] 
2025-08-08 13:01:34.235333: Epoch time: 18.12 s 
2025-08-08 13:01:35.435647:  
2025-08-08 13:01:35.438944: Epoch 148 
2025-08-08 13:01:35.440097: Current learning rate: 0.00446 
2025-08-08 13:01:53.659158: train_loss -0.6722 
2025-08-08 13:01:53.661703: val_loss -0.6975 
2025-08-08 13:01:53.662693: Pseudo dice [np.float32(0.7885)] 
2025-08-08 13:01:53.663608: Epoch time: 18.23 s 
2025-08-08 13:01:54.889924:  
2025-08-08 13:01:54.891809: Epoch 149 
2025-08-08 13:01:54.892789: Current learning rate: 0.00442 
2025-08-08 13:02:13.012481: train_loss -0.657 
2025-08-08 13:02:13.014960: val_loss -0.6416 
2025-08-08 13:02:13.015959: Pseudo dice [np.float32(0.7517)] 
2025-08-08 13:02:13.017439: Epoch time: 18.13 s 
2025-08-08 13:02:22.937843:  
2025-08-08 13:02:22.939145: Epoch 150 
2025-08-08 13:02:22.940191: Current learning rate: 0.00438 
2025-08-08 13:02:41.117341: train_loss -0.6959 
2025-08-08 13:02:41.119457: val_loss -0.6804 
2025-08-08 13:02:41.120289: Pseudo dice [np.float32(0.7725)] 
2025-08-08 13:02:41.121108: Epoch time: 18.18 s 
2025-08-08 13:02:42.338194:  
2025-08-08 13:02:42.340974: Epoch 151 
2025-08-08 13:02:42.341927: Current learning rate: 0.00434 
2025-08-08 13:03:00.407020: train_loss -0.7059 
2025-08-08 13:03:00.409414: val_loss -0.6513 
2025-08-08 13:03:00.410277: Pseudo dice [np.float32(0.7547)] 
2025-08-08 13:03:00.411124: Epoch time: 18.07 s 
2025-08-08 13:03:01.572751:  
2025-08-08 13:03:01.574557: Epoch 152 
2025-08-08 13:03:01.575402: Current learning rate: 0.0043 
2025-08-08 13:03:19.647597: train_loss -0.7221 
2025-08-08 13:03:19.649909: val_loss -0.7029 
2025-08-08 13:03:19.650828: Pseudo dice [np.float32(0.7924)] 
2025-08-08 13:03:19.651759: Epoch time: 18.08 s 
2025-08-08 13:03:20.812426:  
2025-08-08 13:03:20.815783: Epoch 153 
2025-08-08 13:03:20.817704: Current learning rate: 0.00427 
2025-08-08 13:03:38.829012: train_loss -0.6578 
2025-08-08 13:03:38.831558: val_loss -0.689 
2025-08-08 13:03:38.832510: Pseudo dice [np.float32(0.7833)] 
2025-08-08 13:03:38.833638: Epoch time: 18.02 s 
2025-08-08 13:03:40.029398:  
2025-08-08 13:03:40.031361: Epoch 154 
2025-08-08 13:03:40.032704: Current learning rate: 0.00423 
2025-08-08 13:03:58.146903: train_loss -0.725 
2025-08-08 13:03:58.149362: val_loss -0.6891 
2025-08-08 13:03:58.150322: Pseudo dice [np.float32(0.7829)] 
2025-08-08 13:03:58.151178: Epoch time: 18.12 s 
2025-08-08 13:03:59.337674:  
2025-08-08 13:03:59.341053: Epoch 155 
2025-08-08 13:03:59.342106: Current learning rate: 0.00419 
2025-08-08 13:04:17.470186: train_loss -0.6963 
2025-08-08 13:04:17.472691: val_loss -0.6942 
2025-08-08 13:04:17.473664: Pseudo dice [np.float32(0.7902)] 
2025-08-08 13:04:17.474603: Epoch time: 18.14 s 
2025-08-08 13:04:17.475633: Yayy! New best EMA pseudo Dice: 0.7735000252723694 
2025-08-08 13:04:27.046185:  
2025-08-08 13:04:27.047581: Epoch 156 
2025-08-08 13:04:27.048860: Current learning rate: 0.00415 
2025-08-08 13:04:45.159000: train_loss -0.6893 
2025-08-08 13:04:45.162891: val_loss -0.6396 
2025-08-08 13:04:45.163785: Pseudo dice [np.float32(0.7424)] 
2025-08-08 13:04:45.165679: Epoch time: 18.12 s 
2025-08-08 13:04:46.367847:  
2025-08-08 13:04:46.369894: Epoch 157 
2025-08-08 13:04:46.371177: Current learning rate: 0.00411 
2025-08-08 13:05:04.536568: train_loss -0.7212 
2025-08-08 13:05:04.538854: val_loss -0.7177 
2025-08-08 13:05:04.539682: Pseudo dice [np.float32(0.7985)] 
2025-08-08 13:05:04.540480: Epoch time: 18.17 s 
2025-08-08 13:05:05.743531:  
2025-08-08 13:05:05.746548: Epoch 158 
2025-08-08 13:05:05.747518: Current learning rate: 0.00407 
2025-08-08 13:05:23.804720: train_loss -0.6991 
2025-08-08 13:05:23.806947: val_loss -0.7058 
2025-08-08 13:05:23.807802: Pseudo dice [np.float32(0.7918)] 
2025-08-08 13:05:23.808629: Epoch time: 18.07 s 
2025-08-08 13:05:23.809511: Yayy! New best EMA pseudo Dice: 0.7750999927520752 
2025-08-08 13:05:34.191422:  
2025-08-08 13:05:34.193009: Epoch 159 
2025-08-08 13:05:34.194122: Current learning rate: 0.00403 
2025-08-08 13:05:52.434904: train_loss -0.7116 
2025-08-08 13:05:52.437300: val_loss -0.7083 
2025-08-08 13:05:52.438249: Pseudo dice [np.float32(0.7977)] 
2025-08-08 13:05:52.439105: Epoch time: 18.25 s 
2025-08-08 13:05:52.440108: Yayy! New best EMA pseudo Dice: 0.7773000001907349 
2025-08-08 13:06:02.082252:  
2025-08-08 13:06:02.083401: Epoch 160 
2025-08-08 13:06:02.084211: Current learning rate: 0.00399 
2025-08-08 13:06:20.393957: train_loss -0.6985 
2025-08-08 13:06:20.395991: val_loss -0.6936 
2025-08-08 13:06:20.396728: Pseudo dice [np.float32(0.7851)] 
2025-08-08 13:06:20.397589: Epoch time: 18.32 s 
2025-08-08 13:06:20.398455: Yayy! New best EMA pseudo Dice: 0.7781000137329102 
2025-08-08 13:06:29.999293:  
2025-08-08 13:06:30.000734: Epoch 161 
2025-08-08 13:06:30.002021: Current learning rate: 0.00395 
2025-08-08 13:06:48.164881: train_loss -0.7017 
2025-08-08 13:06:48.167375: val_loss -0.7266 
2025-08-08 13:06:48.168328: Pseudo dice [np.float32(0.8056)] 
2025-08-08 13:06:48.169180: Epoch time: 18.17 s 
2025-08-08 13:06:48.170022: Yayy! New best EMA pseudo Dice: 0.7809000015258789 
2025-08-08 13:06:57.711133:  
2025-08-08 13:06:57.712318: Epoch 162 
2025-08-08 13:06:57.713253: Current learning rate: 0.00391 
2025-08-08 13:07:15.798060: train_loss -0.6843 
2025-08-08 13:07:15.800210: val_loss -0.7043 
2025-08-08 13:07:15.801058: Pseudo dice [np.float32(0.7907)] 
2025-08-08 13:07:15.801857: Epoch time: 18.09 s 
2025-08-08 13:07:15.802681: Yayy! New best EMA pseudo Dice: 0.7817999720573425 
2025-08-08 13:07:25.354276:  
2025-08-08 13:07:25.355707: Epoch 163 
2025-08-08 13:07:25.356940: Current learning rate: 0.00387 
2025-08-08 13:07:43.441469: train_loss -0.7016 
2025-08-08 13:07:43.443901: val_loss -0.7115 
2025-08-08 13:07:43.444947: Pseudo dice [np.float32(0.7974)] 
2025-08-08 13:07:43.446015: Epoch time: 18.09 s 
2025-08-08 13:07:43.446906: Yayy! New best EMA pseudo Dice: 0.7833999991416931 
2025-08-08 13:07:53.344170:  
2025-08-08 13:07:53.345786: Epoch 164 
2025-08-08 13:07:53.346833: Current learning rate: 0.00383 
2025-08-08 13:08:11.425805: train_loss -0.7018 
2025-08-08 13:08:11.428080: val_loss -0.6691 
2025-08-08 13:08:11.428967: Pseudo dice [np.float32(0.7672)] 
2025-08-08 13:08:11.429746: Epoch time: 18.09 s 
2025-08-08 13:08:12.577672:  
2025-08-08 13:08:12.580771: Epoch 165 
2025-08-08 13:08:12.581802: Current learning rate: 0.00379 
2025-08-08 13:08:30.679389: train_loss -0.6841 
2025-08-08 13:08:30.681745: val_loss -0.7036 
2025-08-08 13:08:30.682698: Pseudo dice [np.float32(0.798)] 
2025-08-08 13:08:30.683695: Epoch time: 18.11 s 
2025-08-08 13:08:31.862854:  
2025-08-08 13:08:31.864703: Epoch 166 
2025-08-08 13:08:31.865743: Current learning rate: 0.00375 
2025-08-08 13:08:49.989453: train_loss -0.716 
2025-08-08 13:08:49.991648: val_loss -0.7086 
2025-08-08 13:08:49.992812: Pseudo dice [np.float32(0.7922)] 
2025-08-08 13:08:49.993644: Epoch time: 18.13 s 
2025-08-08 13:08:49.994386: Yayy! New best EMA pseudo Dice: 0.7843000292778015 
2025-08-08 13:08:59.530376:  
2025-08-08 13:08:59.531506: Epoch 167 
2025-08-08 13:08:59.532524: Current learning rate: 0.00371 
2025-08-08 13:09:17.683803: train_loss -0.7332 
2025-08-08 13:09:17.685812: val_loss -0.689 
2025-08-08 13:09:17.686670: Pseudo dice [np.float32(0.7737)] 
2025-08-08 13:09:17.687436: Epoch time: 18.16 s 
2025-08-08 13:09:18.871639:  
2025-08-08 13:09:18.874751: Epoch 168 
2025-08-08 13:09:18.875525: Current learning rate: 0.00367 
2025-08-08 13:09:36.891155: train_loss -0.7201 
2025-08-08 13:09:36.893309: val_loss -0.7217 
2025-08-08 13:09:36.894189: Pseudo dice [np.float32(0.8019)] 
2025-08-08 13:09:36.895070: Epoch time: 18.02 s 
2025-08-08 13:09:36.895957: Yayy! New best EMA pseudo Dice: 0.785099983215332 
2025-08-08 13:09:46.482188:  
2025-08-08 13:09:46.483308: Epoch 169 
2025-08-08 13:09:46.484137: Current learning rate: 0.00363 
2025-08-08 13:10:04.587129: train_loss -0.7044 
2025-08-08 13:10:04.589303: val_loss -0.6927 
2025-08-08 13:10:04.590194: Pseudo dice [np.float32(0.7846)] 
2025-08-08 13:10:04.590972: Epoch time: 18.11 s 
2025-08-08 13:10:05.795365:  
2025-08-08 13:10:05.798445: Epoch 170 
2025-08-08 13:10:05.799330: Current learning rate: 0.00359 
2025-08-08 13:10:23.942505: train_loss -0.7245 
2025-08-08 13:10:23.944587: val_loss -0.683 
2025-08-08 13:10:23.945499: Pseudo dice [np.float32(0.773)] 
2025-08-08 13:10:23.946336: Epoch time: 18.15 s 
2025-08-08 13:10:25.143281:  
2025-08-08 13:10:25.145144: Epoch 171 
2025-08-08 13:10:25.146144: Current learning rate: 0.00355 
2025-08-08 13:10:43.283371: train_loss -0.6985 
2025-08-08 13:10:43.285449: val_loss -0.682 
2025-08-08 13:10:43.286170: Pseudo dice [np.float32(0.7808)] 
2025-08-08 13:10:43.286981: Epoch time: 18.14 s 
2025-08-08 13:10:44.498252:  
2025-08-08 13:10:44.501133: Epoch 172 
2025-08-08 13:10:44.502079: Current learning rate: 0.00351 
2025-08-08 13:11:02.527279: train_loss -0.7319 
2025-08-08 13:11:02.529640: val_loss -0.6554 
2025-08-08 13:11:02.531110: Pseudo dice [np.float32(0.7448)] 
2025-08-08 13:11:02.532062: Epoch time: 18.03 s 
2025-08-08 13:11:03.738149:  
2025-08-08 13:11:03.739940: Epoch 173 
2025-08-08 13:11:03.740966: Current learning rate: 0.00346 
2025-08-08 13:11:21.856785: train_loss -0.711 
2025-08-08 13:11:21.858973: val_loss -0.6878 
2025-08-08 13:11:21.859870: Pseudo dice [np.float32(0.7795)] 
2025-08-08 13:11:21.860744: Epoch time: 18.12 s 
2025-08-08 13:11:23.062886:  
2025-08-08 13:11:23.064639: Epoch 174 
2025-08-08 13:11:23.065506: Current learning rate: 0.00342 
2025-08-08 13:11:41.188508: train_loss -0.7059 
2025-08-08 13:11:41.190836: val_loss -0.6212 
2025-08-08 13:11:41.191909: Pseudo dice [np.float32(0.7409)] 
2025-08-08 13:11:41.192880: Epoch time: 18.13 s 
2025-08-08 13:11:42.383467:  
2025-08-08 13:11:42.386626: Epoch 175 
2025-08-08 13:11:42.387728: Current learning rate: 0.00338 
2025-08-08 13:12:00.584889: train_loss -0.6627 
2025-08-08 13:12:00.587264: val_loss -0.6956 
2025-08-08 13:12:00.588263: Pseudo dice [np.float32(0.7926)] 
2025-08-08 13:12:00.589497: Epoch time: 18.21 s 
2025-08-08 13:12:01.823562:  
2025-08-08 13:12:01.825704: Epoch 176 
2025-08-08 13:12:01.826911: Current learning rate: 0.00334 
2025-08-08 13:12:19.998199: train_loss -0.6725 
2025-08-08 13:12:20.000295: val_loss -0.6443 
2025-08-08 13:12:20.001163: Pseudo dice [np.float32(0.7486)] 
2025-08-08 13:12:20.001969: Epoch time: 18.18 s 
2025-08-08 13:12:21.782917:  
2025-08-08 13:12:21.785182: Epoch 177 
2025-08-08 13:12:21.786364: Current learning rate: 0.0033 
2025-08-08 13:12:39.894354: train_loss -0.6941 
2025-08-08 13:12:39.896491: val_loss -0.6947 
2025-08-08 13:12:39.897338: Pseudo dice [np.float32(0.7942)] 
2025-08-08 13:12:39.898230: Epoch time: 18.12 s 
2025-08-08 13:12:41.116886:  
2025-08-08 13:12:41.120404: Epoch 178 
2025-08-08 13:12:41.121326: Current learning rate: 0.00326 
2025-08-08 13:12:59.165187: train_loss -0.6977 
2025-08-08 13:12:59.167435: val_loss -0.6978 
2025-08-08 13:12:59.168236: Pseudo dice [np.float32(0.7843)] 
2025-08-08 13:12:59.168960: Epoch time: 18.05 s 
2025-08-08 13:13:00.387320:  
2025-08-08 13:13:00.389100: Epoch 179 
2025-08-08 13:13:00.389976: Current learning rate: 0.00322 
2025-08-08 13:13:18.536181: train_loss -0.7167 
2025-08-08 13:13:18.538407: val_loss -0.7221 
2025-08-08 13:13:18.539215: Pseudo dice [np.float32(0.8083)] 
2025-08-08 13:13:18.539970: Epoch time: 18.15 s 
2025-08-08 13:13:19.715607:  
2025-08-08 13:13:19.718583: Epoch 180 
2025-08-08 13:13:19.719448: Current learning rate: 0.00318 
2025-08-08 13:13:37.860718: train_loss -0.7179 
2025-08-08 13:13:37.862833: val_loss -0.6923 
2025-08-08 13:13:37.863590: Pseudo dice [np.float32(0.7778)] 
2025-08-08 13:13:37.864371: Epoch time: 18.15 s 
2025-08-08 13:13:39.074046:  
2025-08-08 13:13:39.075894: Epoch 181 
2025-08-08 13:13:39.077004: Current learning rate: 0.00314 
2025-08-08 13:13:57.220826: train_loss -0.7208 
2025-08-08 13:13:57.223073: val_loss -0.7026 
2025-08-08 13:13:57.223905: Pseudo dice [np.float32(0.7906)] 
2025-08-08 13:13:57.224757: Epoch time: 18.15 s 
2025-08-08 13:13:58.427944:  
2025-08-08 13:13:58.431018: Epoch 182 
2025-08-08 13:13:58.431914: Current learning rate: 0.0031 
2025-08-08 13:14:16.602963: train_loss -0.7712 
2025-08-08 13:14:16.604998: val_loss -0.6935 
2025-08-08 13:14:16.605976: Pseudo dice [np.float32(0.7838)] 
2025-08-08 13:14:16.606947: Epoch time: 18.18 s 
2025-08-08 13:14:17.792921:  
2025-08-08 13:14:17.794981: Epoch 183 
2025-08-08 13:14:17.796066: Current learning rate: 0.00306 
2025-08-08 13:14:35.928651: train_loss -0.7261 
2025-08-08 13:14:35.930919: val_loss -0.681 
2025-08-08 13:14:35.931777: Pseudo dice [np.float32(0.7676)] 
2025-08-08 13:14:35.932631: Epoch time: 18.14 s 
2025-08-08 13:14:37.151361:  
2025-08-08 13:14:37.154366: Epoch 184 
2025-08-08 13:14:37.155158: Current learning rate: 0.00302 
2025-08-08 13:14:55.290919: train_loss -0.7212 
2025-08-08 13:14:55.293105: val_loss -0.6992 
2025-08-08 13:14:55.294021: Pseudo dice [np.float32(0.7864)] 
2025-08-08 13:14:55.294797: Epoch time: 18.14 s 
2025-08-08 13:14:56.527382:  
2025-08-08 13:14:56.529124: Epoch 185 
2025-08-08 13:14:56.530034: Current learning rate: 0.00297 
2025-08-08 13:15:14.648742: train_loss -0.7328 
2025-08-08 13:15:14.650946: val_loss -0.6881 
2025-08-08 13:15:14.651827: Pseudo dice [np.float32(0.7802)] 
2025-08-08 13:15:14.652624: Epoch time: 18.13 s 
2025-08-08 13:15:15.854657:  
2025-08-08 13:15:15.857743: Epoch 186 
2025-08-08 13:15:15.858547: Current learning rate: 0.00293 
2025-08-08 13:15:34.005552: train_loss -0.7066 
2025-08-08 13:15:34.008474: val_loss -0.7011 
2025-08-08 13:15:34.009412: Pseudo dice [np.float32(0.7896)] 
2025-08-08 13:15:34.010285: Epoch time: 18.16 s 
2025-08-08 13:15:35.215578:  
2025-08-08 13:15:35.217547: Epoch 187 
2025-08-08 13:15:35.218674: Current learning rate: 0.00289 
2025-08-08 13:15:53.363934: train_loss -0.694 
2025-08-08 13:15:53.366604: val_loss -0.7213 
2025-08-08 13:15:53.367537: Pseudo dice [np.float32(0.7947)] 
2025-08-08 13:15:53.368406: Epoch time: 18.15 s 
2025-08-08 13:15:54.584361:  
2025-08-08 13:15:54.587348: Epoch 188 
2025-08-08 13:15:54.588322: Current learning rate: 0.00285 
2025-08-08 13:16:12.738209: train_loss -0.7192 
2025-08-08 13:16:12.740621: val_loss -0.7255 
2025-08-08 13:16:12.741634: Pseudo dice [np.float32(0.809)] 
2025-08-08 13:16:12.742466: Epoch time: 18.16 s 
2025-08-08 13:16:12.743190: Yayy! New best EMA pseudo Dice: 0.7854999899864197 
2025-08-08 13:16:22.379042:  
2025-08-08 13:16:22.380168: Epoch 189 
2025-08-08 13:16:22.381294: Current learning rate: 0.00281 
2025-08-08 13:16:40.593297: train_loss -0.6889 
2025-08-08 13:16:40.595590: val_loss -0.7033 
2025-08-08 13:16:40.596436: Pseudo dice [np.float32(0.7899)] 
2025-08-08 13:16:40.597265: Epoch time: 18.22 s 
2025-08-08 13:16:40.598082: Yayy! New best EMA pseudo Dice: 0.7858999967575073 
2025-08-08 13:16:50.170309:  
2025-08-08 13:16:50.171478: Epoch 190 
2025-08-08 13:16:50.172356: Current learning rate: 0.00277 
2025-08-08 13:17:08.313638: train_loss -0.6897 
2025-08-08 13:17:08.317214: val_loss -0.7028 
2025-08-08 13:17:08.318226: Pseudo dice [np.float32(0.7966)] 
2025-08-08 13:17:08.319044: Epoch time: 18.15 s 
2025-08-08 13:17:08.319788: Yayy! New best EMA pseudo Dice: 0.7870000004768372 
2025-08-08 13:17:17.823757:  
2025-08-08 13:17:17.824838: Epoch 191 
2025-08-08 13:17:17.825687: Current learning rate: 0.00273 
2025-08-08 13:17:35.938699: train_loss -0.6979 
2025-08-08 13:17:35.941090: val_loss -0.6923 
2025-08-08 13:17:35.941947: Pseudo dice [np.float32(0.7831)] 
2025-08-08 13:17:35.943016: Epoch time: 18.12 s 
2025-08-08 13:17:37.159992:  
2025-08-08 13:17:37.161987: Epoch 192 
2025-08-08 13:17:37.162966: Current learning rate: 0.00268 
2025-08-08 13:17:55.324737: train_loss -0.7228 
2025-08-08 13:17:55.326971: val_loss -0.6909 
2025-08-08 13:17:55.327849: Pseudo dice [np.float32(0.7859)] 
2025-08-08 13:17:55.328777: Epoch time: 18.17 s 
2025-08-08 13:17:56.513643:  
2025-08-08 13:17:56.516685: Epoch 193 
2025-08-08 13:17:56.517702: Current learning rate: 0.00264 
2025-08-08 13:18:14.689179: train_loss -0.7034 
2025-08-08 13:18:14.691339: val_loss -0.713 
2025-08-08 13:18:14.692303: Pseudo dice [np.float32(0.7996)] 
2025-08-08 13:18:14.693649: Epoch time: 18.18 s 
2025-08-08 13:18:14.694515: Yayy! New best EMA pseudo Dice: 0.7878000140190125 
2025-08-08 13:18:24.364574:  
2025-08-08 13:18:24.365537: Epoch 194 
2025-08-08 13:18:24.366324: Current learning rate: 0.0026 
2025-08-08 13:18:42.489272: train_loss -0.7123 
2025-08-08 13:18:42.491296: val_loss -0.6804 
2025-08-08 13:18:42.492151: Pseudo dice [np.float32(0.7767)] 
2025-08-08 13:18:42.492942: Epoch time: 18.13 s 
2025-08-08 13:18:43.693903:  
2025-08-08 13:18:43.695887: Epoch 195 
2025-08-08 13:18:43.696871: Current learning rate: 0.00256 
2025-08-08 13:19:01.818628: train_loss -0.737 
2025-08-08 13:19:01.820785: val_loss -0.7296 
2025-08-08 13:19:01.821698: Pseudo dice [np.float32(0.8079)] 
2025-08-08 13:19:01.822517: Epoch time: 18.13 s 
2025-08-08 13:19:01.823315: Yayy! New best EMA pseudo Dice: 0.7888000011444092 
2025-08-08 13:19:12.088881:  
2025-08-08 13:19:12.090233: Epoch 196 
2025-08-08 13:19:12.091204: Current learning rate: 0.00252 
2025-08-08 13:19:30.319487: train_loss -0.7146 
2025-08-08 13:19:30.322248: val_loss -0.7246 
2025-08-08 13:19:30.323890: Pseudo dice [np.float32(0.8047)] 
2025-08-08 13:19:30.325017: Epoch time: 18.23 s 
2025-08-08 13:19:30.326102: Yayy! New best EMA pseudo Dice: 0.7904000282287598 
2025-08-08 13:19:39.972369:  
2025-08-08 13:19:39.973717: Epoch 197 
2025-08-08 13:19:39.974777: Current learning rate: 0.00248 
2025-08-08 13:19:58.104192: train_loss -0.745 
2025-08-08 13:19:58.106820: val_loss -0.6926 
2025-08-08 13:19:58.107775: Pseudo dice [np.float32(0.7777)] 
2025-08-08 13:19:58.108850: Epoch time: 18.14 s 
2025-08-08 13:19:59.333604:  
2025-08-08 13:19:59.336732: Epoch 198 
2025-08-08 13:19:59.337662: Current learning rate: 0.00243 
2025-08-08 13:20:17.452188: train_loss -0.6953 
2025-08-08 13:20:17.454590: val_loss -0.6794 
2025-08-08 13:20:17.455657: Pseudo dice [np.float32(0.7765)] 
2025-08-08 13:20:17.456555: Epoch time: 18.12 s 
2025-08-08 13:20:18.652715:  
2025-08-08 13:20:18.655132: Epoch 199 
2025-08-08 13:20:18.656397: Current learning rate: 0.00239 
2025-08-08 13:20:36.912742: train_loss -0.7028 
2025-08-08 13:20:36.914866: val_loss -0.7168 
2025-08-08 13:20:36.915737: Pseudo dice [np.float32(0.7991)] 
2025-08-08 13:20:36.916586: Epoch time: 18.26 s 
2025-08-08 13:20:46.503601:  
2025-08-08 13:20:46.504907: Epoch 200 
2025-08-08 13:20:46.506136: Current learning rate: 0.00235 
2025-08-08 13:21:04.592380: train_loss -0.7174 
2025-08-08 13:21:04.594638: val_loss -0.6561 
2025-08-08 13:21:04.595570: Pseudo dice [np.float32(0.749)] 
2025-08-08 13:21:04.596514: Epoch time: 18.09 s 
2025-08-08 13:21:05.800215:  
2025-08-08 13:21:05.803656: Epoch 201 
2025-08-08 13:21:05.804867: Current learning rate: 0.00231 
2025-08-08 13:21:24.070954: train_loss -0.7131 
2025-08-08 13:21:24.073261: val_loss -0.7116 
2025-08-08 13:21:24.074173: Pseudo dice [np.float32(0.7882)] 
2025-08-08 13:21:24.075013: Epoch time: 18.28 s 
2025-08-08 13:21:25.326766:  
2025-08-08 13:21:25.328574: Epoch 202 
2025-08-08 13:21:25.329504: Current learning rate: 0.00226 
2025-08-08 13:21:43.554409: train_loss -0.7006 
2025-08-08 13:21:43.557356: val_loss -0.7437 
2025-08-08 13:21:43.558284: Pseudo dice [np.float32(0.8148)] 
2025-08-08 13:21:43.559224: Epoch time: 18.23 s 
2025-08-08 13:21:44.765932:  
2025-08-08 13:21:44.767882: Epoch 203 
2025-08-08 13:21:44.768919: Current learning rate: 0.00222 
2025-08-08 13:22:02.983319: train_loss -0.7313 
2025-08-08 13:22:02.985370: val_loss -0.6895 
2025-08-08 13:22:02.986158: Pseudo dice [np.float32(0.7842)] 
2025-08-08 13:22:02.987052: Epoch time: 18.22 s 
2025-08-08 13:22:04.194145:  
2025-08-08 13:22:04.195959: Epoch 204 
2025-08-08 13:22:04.197015: Current learning rate: 0.00218 
2025-08-08 13:22:22.294086: train_loss -0.7282 
2025-08-08 13:22:22.296628: val_loss -0.6923 
2025-08-08 13:22:22.297562: Pseudo dice [np.float32(0.7785)] 
2025-08-08 13:22:22.298483: Epoch time: 18.1 s 
2025-08-08 13:22:23.535288:  
2025-08-08 13:22:23.537077: Epoch 205 
2025-08-08 13:22:23.538160: Current learning rate: 0.00214 
2025-08-08 13:22:41.650612: train_loss -0.7204 
2025-08-08 13:22:41.652905: val_loss -0.6316 
2025-08-08 13:22:41.653779: Pseudo dice [np.float32(0.7319)] 
2025-08-08 13:22:41.654648: Epoch time: 18.12 s 
2025-08-08 13:22:42.850302:  
2025-08-08 13:22:42.853375: Epoch 206 
2025-08-08 13:22:42.854359: Current learning rate: 0.00209 
2025-08-08 13:23:00.995035: train_loss -0.7411 
2025-08-08 13:23:00.997323: val_loss -0.6916 
2025-08-08 13:23:00.998218: Pseudo dice [np.float32(0.7749)] 
2025-08-08 13:23:00.999052: Epoch time: 18.15 s 
2025-08-08 13:23:02.180290:  
2025-08-08 13:23:02.182325: Epoch 207 
2025-08-08 13:23:02.183379: Current learning rate: 0.00205 
2025-08-08 13:23:20.325024: train_loss -0.7265 
2025-08-08 13:23:20.328635: val_loss -0.7031 
2025-08-08 13:23:20.329529: Pseudo dice [np.float32(0.7903)] 
2025-08-08 13:23:20.330654: Epoch time: 18.15 s 
2025-08-08 13:23:21.506593:  
2025-08-08 13:23:21.509470: Epoch 208 
2025-08-08 13:23:21.510300: Current learning rate: 0.00201 
2025-08-08 13:23:39.710659: train_loss -0.7411 
2025-08-08 13:23:39.712699: val_loss -0.6931 
2025-08-08 13:23:39.713597: Pseudo dice [np.float32(0.7791)] 
2025-08-08 13:23:39.714391: Epoch time: 18.21 s 
2025-08-08 13:23:40.894904:  
2025-08-08 13:23:40.896590: Epoch 209 
2025-08-08 13:23:40.897458: Current learning rate: 0.00196 
2025-08-08 13:23:59.029668: train_loss -0.7226 
2025-08-08 13:23:59.032085: val_loss -0.6985 
2025-08-08 13:23:59.033006: Pseudo dice [np.float32(0.7908)] 
2025-08-08 13:23:59.034022: Epoch time: 18.14 s 
2025-08-08 13:24:00.212912:  
2025-08-08 13:24:00.216185: Epoch 210 
2025-08-08 13:24:00.217323: Current learning rate: 0.00192 
2025-08-08 13:24:18.349282: train_loss -0.7331 
2025-08-08 13:24:18.351508: val_loss -0.6868 
2025-08-08 13:24:18.352345: Pseudo dice [np.float32(0.7784)] 
2025-08-08 13:24:18.353142: Epoch time: 18.14 s 
2025-08-08 13:24:19.580362:  
2025-08-08 13:24:19.582540: Epoch 211 
2025-08-08 13:24:19.583612: Current learning rate: 0.00188 
2025-08-08 13:24:37.716677: train_loss -0.711 
2025-08-08 13:24:37.719407: val_loss -0.7083 
2025-08-08 13:24:37.720272: Pseudo dice [np.float32(0.7915)] 
2025-08-08 13:24:37.721141: Epoch time: 18.14 s 
2025-08-08 13:24:38.897268:  
2025-08-08 13:24:38.900525: Epoch 212 
2025-08-08 13:24:38.901506: Current learning rate: 0.00184 
2025-08-08 13:24:57.007612: train_loss -0.7157 
2025-08-08 13:24:57.009835: val_loss -0.7195 
2025-08-08 13:24:57.011068: Pseudo dice [np.float32(0.8014)] 
2025-08-08 13:24:57.013557: Epoch time: 18.11 s 
2025-08-08 13:24:58.388739:  
2025-08-08 13:24:58.390766: Epoch 213 
2025-08-08 13:24:58.391863: Current learning rate: 0.00179 
2025-08-08 13:25:16.466855: train_loss -0.7381 
2025-08-08 13:25:16.469455: val_loss -0.6958 
2025-08-08 13:25:16.470305: Pseudo dice [np.float32(0.7823)] 
2025-08-08 13:25:16.471097: Epoch time: 18.08 s 
2025-08-08 13:25:17.637029:  
2025-08-08 13:25:17.640296: Epoch 214 
2025-08-08 13:25:17.641040: Current learning rate: 0.00175 
2025-08-08 13:25:35.775271: train_loss -0.7464 
2025-08-08 13:25:35.777752: val_loss -0.7067 
2025-08-08 13:25:35.778674: Pseudo dice [np.float32(0.7921)] 
2025-08-08 13:25:35.779562: Epoch time: 18.14 s 
2025-08-08 13:25:37.480126:  
2025-08-08 13:25:37.481981: Epoch 215 
2025-08-08 13:25:37.483059: Current learning rate: 0.0017 
2025-08-08 13:25:55.487534: train_loss -0.7287 
2025-08-08 13:25:55.489702: val_loss -0.7098 
2025-08-08 13:25:55.490550: Pseudo dice [np.float32(0.7911)] 
2025-08-08 13:25:55.491358: Epoch time: 18.01 s 
2025-08-08 13:25:56.702806:  
2025-08-08 13:25:56.706352: Epoch 216 
2025-08-08 13:25:56.707479: Current learning rate: 0.00166 
2025-08-08 13:26:14.897756: train_loss -0.6939 
2025-08-08 13:26:14.899936: val_loss -0.6462 
2025-08-08 13:26:14.900717: Pseudo dice [np.float32(0.7424)] 
2025-08-08 13:26:14.901482: Epoch time: 18.2 s 
2025-08-08 13:26:16.082967:  
2025-08-08 13:26:16.085331: Epoch 217 
2025-08-08 13:26:16.086565: Current learning rate: 0.00162 
2025-08-08 13:26:34.147965: train_loss -0.7164 
2025-08-08 13:26:34.150256: val_loss -0.6903 
2025-08-08 13:26:34.151263: Pseudo dice [np.float32(0.7799)] 
2025-08-08 13:26:34.152275: Epoch time: 18.07 s 
2025-08-08 13:26:35.345847:  
2025-08-08 13:26:35.348885: Epoch 218 
2025-08-08 13:26:35.349944: Current learning rate: 0.00157 
2025-08-08 13:26:53.454608: train_loss -0.7542 
2025-08-08 13:26:53.456640: val_loss -0.7032 
2025-08-08 13:26:53.457488: Pseudo dice [np.float32(0.785)] 
2025-08-08 13:26:53.458320: Epoch time: 18.11 s 
2025-08-08 13:26:54.594796:  
2025-08-08 13:26:54.596606: Epoch 219 
2025-08-08 13:26:54.597669: Current learning rate: 0.00153 
2025-08-08 13:27:12.755193: train_loss -0.7361 
2025-08-08 13:27:12.757352: val_loss -0.7124 
2025-08-08 13:27:12.758267: Pseudo dice [np.float32(0.8031)] 
2025-08-08 13:27:12.759100: Epoch time: 18.16 s 
2025-08-08 13:27:13.943717:  
2025-08-08 13:27:13.947060: Epoch 220 
2025-08-08 13:27:13.948110: Current learning rate: 0.00148 
2025-08-08 13:27:32.005730: train_loss -0.7392 
2025-08-08 13:27:32.008149: val_loss -0.7489 
2025-08-08 13:27:32.009205: Pseudo dice [np.float32(0.8225)] 
2025-08-08 13:27:32.010133: Epoch time: 18.07 s 
2025-08-08 13:27:33.202153:  
2025-08-08 13:27:33.204315: Epoch 221 
2025-08-08 13:27:33.205354: Current learning rate: 0.00144 
2025-08-08 13:27:51.378935: train_loss -0.71 
2025-08-08 13:27:51.381617: val_loss -0.6862 
2025-08-08 13:27:51.382625: Pseudo dice [np.float32(0.7814)] 
2025-08-08 13:27:51.383462: Epoch time: 18.18 s 
2025-08-08 13:27:52.532752:  
2025-08-08 13:27:52.535977: Epoch 222 
2025-08-08 13:27:52.537007: Current learning rate: 0.00139 
2025-08-08 13:28:10.721249: train_loss -0.729 
2025-08-08 13:28:10.723404: val_loss -0.6915 
2025-08-08 13:28:10.724329: Pseudo dice [np.float32(0.7835)] 
2025-08-08 13:28:10.725168: Epoch time: 18.19 s 
2025-08-08 13:28:11.903326:  
2025-08-08 13:28:11.905661: Epoch 223 
2025-08-08 13:28:11.906545: Current learning rate: 0.00135 
2025-08-08 13:28:30.041421: train_loss -0.7268 
2025-08-08 13:28:30.043844: val_loss -0.7259 
2025-08-08 13:28:30.044727: Pseudo dice [np.float32(0.8073)] 
2025-08-08 13:28:30.045733: Epoch time: 18.14 s 
2025-08-08 13:28:31.215943:  
2025-08-08 13:28:31.219276: Epoch 224 
2025-08-08 13:28:31.220253: Current learning rate: 0.0013 
2025-08-08 13:28:49.449645: train_loss -0.7597 
2025-08-08 13:28:49.451950: val_loss -0.6858 
2025-08-08 13:28:49.452926: Pseudo dice [np.float32(0.7769)] 
2025-08-08 13:28:49.453832: Epoch time: 18.24 s 
2025-08-08 13:28:50.613212:  
2025-08-08 13:28:50.615570: Epoch 225 
2025-08-08 13:28:50.616853: Current learning rate: 0.00126 
2025-08-08 13:29:08.727561: train_loss -0.7208 
2025-08-08 13:29:08.729898: val_loss -0.7317 
2025-08-08 13:29:08.730789: Pseudo dice [np.float32(0.8077)] 
2025-08-08 13:29:08.731602: Epoch time: 18.12 s 
2025-08-08 13:29:09.902871:  
2025-08-08 13:29:09.906282: Epoch 226 
2025-08-08 13:29:09.907369: Current learning rate: 0.00121 
2025-08-08 13:29:28.074048: train_loss -0.7414 
2025-08-08 13:29:28.076683: val_loss -0.7254 
2025-08-08 13:29:28.077610: Pseudo dice [np.float32(0.7976)] 
2025-08-08 13:29:28.078500: Epoch time: 18.17 s 
2025-08-08 13:29:29.245082:  
2025-08-08 13:29:29.247004: Epoch 227 
2025-08-08 13:29:29.248140: Current learning rate: 0.00117 
2025-08-08 13:29:47.399477: train_loss -0.7542 
2025-08-08 13:29:47.401516: val_loss -0.7062 
2025-08-08 13:29:47.402251: Pseudo dice [np.float32(0.7893)] 
2025-08-08 13:29:47.403072: Epoch time: 18.16 s 
2025-08-08 13:29:48.542424:  
2025-08-08 13:29:48.546010: Epoch 228 
2025-08-08 13:29:48.546844: Current learning rate: 0.00112 
2025-08-08 13:30:06.628630: train_loss -0.7234 
2025-08-08 13:30:06.630789: val_loss -0.7212 
2025-08-08 13:30:06.631541: Pseudo dice [np.float32(0.8127)] 
2025-08-08 13:30:06.632421: Epoch time: 18.09 s 
2025-08-08 13:30:06.633174: Yayy! New best EMA pseudo Dice: 0.7925000190734863 
2025-08-08 13:30:16.455557:  
2025-08-08 13:30:16.456939: Epoch 229 
2025-08-08 13:30:16.458106: Current learning rate: 0.00108 
2025-08-08 13:30:34.582050: train_loss -0.7488 
2025-08-08 13:30:34.584261: val_loss -0.7232 
2025-08-08 13:30:34.585116: Pseudo dice [np.float32(0.8041)] 
2025-08-08 13:30:34.585978: Epoch time: 18.13 s 
2025-08-08 13:30:34.586981: Yayy! New best EMA pseudo Dice: 0.7936999797821045 
2025-08-08 13:30:44.321691:  
2025-08-08 13:30:44.322728: Epoch 230 
2025-08-08 13:30:44.323689: Current learning rate: 0.00103 
2025-08-08 13:31:02.556431: train_loss -0.7657 
2025-08-08 13:31:02.559000: val_loss -0.7327 
2025-08-08 13:31:02.560063: Pseudo dice [np.float32(0.8036)] 
2025-08-08 13:31:02.561123: Epoch time: 18.24 s 
2025-08-08 13:31:02.562153: Yayy! New best EMA pseudo Dice: 0.794700026512146 
2025-08-08 13:31:12.174020:  
2025-08-08 13:31:12.175540: Epoch 231 
2025-08-08 13:31:12.176730: Current learning rate: 0.00098 
2025-08-08 13:31:30.270601: train_loss -0.7646 
2025-08-08 13:31:30.272845: val_loss -0.7196 
2025-08-08 13:31:30.273797: Pseudo dice [np.float32(0.8017)] 
2025-08-08 13:31:30.274729: Epoch time: 18.1 s 
2025-08-08 13:31:30.275720: Yayy! New best EMA pseudo Dice: 0.7954000234603882 
2025-08-08 13:31:39.910958:  
2025-08-08 13:31:39.912262: Epoch 232 
2025-08-08 13:31:39.913258: Current learning rate: 0.00094 
2025-08-08 13:31:58.024293: train_loss -0.7528 
2025-08-08 13:31:58.026259: val_loss -0.6926 
2025-08-08 13:31:58.027067: Pseudo dice [np.float32(0.7858)] 
2025-08-08 13:31:58.027843: Epoch time: 18.12 s 
2025-08-08 13:31:59.210464:  
2025-08-08 13:31:59.213970: Epoch 233 
2025-08-08 13:31:59.214934: Current learning rate: 0.00089 
2025-08-08 13:32:17.388334: train_loss -0.766 
2025-08-08 13:32:17.390930: val_loss -0.7067 
2025-08-08 13:32:17.391879: Pseudo dice [np.float32(0.7932)] 
2025-08-08 13:32:17.392736: Epoch time: 18.18 s 
2025-08-08 13:32:18.559781:  
2025-08-08 13:32:18.561682: Epoch 234 
2025-08-08 13:32:18.562734: Current learning rate: 0.00084 
2025-08-08 13:32:36.706778: train_loss -0.7246 
2025-08-08 13:32:36.710037: val_loss -0.6972 
2025-08-08 13:32:36.711046: Pseudo dice [np.float32(0.7828)] 
2025-08-08 13:32:36.712008: Epoch time: 18.15 s 
2025-08-08 13:32:37.895152:  
2025-08-08 13:32:37.898536: Epoch 235 
2025-08-08 13:32:37.899787: Current learning rate: 0.00079 
2025-08-08 13:32:56.026192: train_loss -0.7412 
2025-08-08 13:32:56.029020: val_loss -0.7099 
2025-08-08 13:32:56.030054: Pseudo dice [np.float32(0.7987)] 
2025-08-08 13:32:56.030949: Epoch time: 18.13 s 
2025-08-08 13:32:57.202411:  
2025-08-08 13:32:57.204506: Epoch 236 
2025-08-08 13:32:57.205617: Current learning rate: 0.00075 
2025-08-08 13:33:15.413357: train_loss -0.751 
2025-08-08 13:33:15.415917: val_loss -0.738 
2025-08-08 13:33:15.416892: Pseudo dice [np.float32(0.8141)] 
2025-08-08 13:33:15.417868: Epoch time: 18.22 s 
2025-08-08 13:33:15.418666: Yayy! New best EMA pseudo Dice: 0.795799970626831 
2025-08-08 13:33:24.429320:  
2025-08-08 13:33:24.430830: Epoch 237 
2025-08-08 13:33:24.431613: Current learning rate: 0.0007 
2025-08-08 13:33:42.514356: train_loss -0.7709 
2025-08-08 13:33:42.516760: val_loss -0.6991 
2025-08-08 13:33:42.517684: Pseudo dice [np.float32(0.7739)] 
2025-08-08 13:33:42.518575: Epoch time: 18.09 s 
2025-08-08 13:33:43.694207:  
2025-08-08 13:33:43.697355: Epoch 238 
2025-08-08 13:33:43.698186: Current learning rate: 0.00065 
2025-08-08 13:34:01.830281: train_loss -0.7382 
2025-08-08 13:34:01.832622: val_loss -0.6882 
2025-08-08 13:34:01.833409: Pseudo dice [np.float32(0.7754)] 
2025-08-08 13:34:01.834200: Epoch time: 18.14 s 
2025-08-08 13:34:03.520368:  
2025-08-08 13:34:03.522159: Epoch 239 
2025-08-08 13:34:03.522990: Current learning rate: 0.0006 
2025-08-08 13:34:21.624954: train_loss -0.7369 
2025-08-08 13:34:21.627358: val_loss -0.7087 
2025-08-08 13:34:21.628197: Pseudo dice [np.float32(0.7952)] 
2025-08-08 13:34:21.629013: Epoch time: 18.11 s 
2025-08-08 13:34:22.819969:  
2025-08-08 13:34:22.823480: Epoch 240 
2025-08-08 13:34:22.824765: Current learning rate: 0.00055 
2025-08-08 13:34:40.966215: train_loss -0.7451 
2025-08-08 13:34:40.968333: val_loss -0.7286 
2025-08-08 13:34:40.969221: Pseudo dice [np.float32(0.7995)] 
2025-08-08 13:34:40.969996: Epoch time: 18.15 s 
2025-08-08 13:34:42.152401:  
2025-08-08 13:34:42.154429: Epoch 241 
2025-08-08 13:34:42.155289: Current learning rate: 0.0005 
2025-08-08 13:35:00.315860: train_loss -0.7681 
2025-08-08 13:35:00.318035: val_loss -0.7108 
2025-08-08 13:35:00.318865: Pseudo dice [np.float32(0.7924)] 
2025-08-08 13:35:00.319694: Epoch time: 18.17 s 
2025-08-08 13:35:01.495603:  
2025-08-08 13:35:01.497662: Epoch 242 
2025-08-08 13:35:01.498716: Current learning rate: 0.00045 
2025-08-08 13:35:19.678454: train_loss -0.7524 
2025-08-08 13:35:19.680907: val_loss -0.7137 
2025-08-08 13:35:19.681647: Pseudo dice [np.float32(0.7938)] 
2025-08-08 13:35:19.682416: Epoch time: 18.19 s 
2025-08-08 13:35:20.909067:  
2025-08-08 13:35:20.912598: Epoch 243 
2025-08-08 13:35:20.913423: Current learning rate: 0.0004 
2025-08-08 13:35:39.064784: train_loss -0.7603 
2025-08-08 13:35:39.067223: val_loss -0.7114 
2025-08-08 13:35:39.068151: Pseudo dice [np.float32(0.7932)] 
2025-08-08 13:35:39.069168: Epoch time: 18.16 s 
2025-08-08 13:35:40.237490:  
2025-08-08 13:35:40.239608: Epoch 244 
2025-08-08 13:35:40.240669: Current learning rate: 0.00035 
2025-08-08 13:35:58.355756: train_loss -0.7592 
2025-08-08 13:35:58.357729: val_loss -0.7206 
2025-08-08 13:35:58.358467: Pseudo dice [np.float32(0.8034)] 
2025-08-08 13:35:58.359254: Epoch time: 18.12 s 
2025-08-08 13:35:59.525532:  
2025-08-08 13:35:59.528839: Epoch 245 
2025-08-08 13:35:59.529745: Current learning rate: 0.0003 
2025-08-08 13:36:17.571547: train_loss -0.7571 
2025-08-08 13:36:17.573802: val_loss -0.7145 
2025-08-08 13:36:17.574700: Pseudo dice [np.float32(0.799)] 
2025-08-08 13:36:17.575554: Epoch time: 18.05 s 
2025-08-08 13:36:18.801310:  
2025-08-08 13:36:18.803072: Epoch 246 
2025-08-08 13:36:18.803950: Current learning rate: 0.00024 
2025-08-08 13:36:36.922941: train_loss -0.7743 
2025-08-08 13:36:36.925506: val_loss -0.7039 
2025-08-08 13:36:36.926575: Pseudo dice [np.float32(0.7883)] 
2025-08-08 13:36:36.927505: Epoch time: 18.13 s 
2025-08-08 13:36:38.132179:  
2025-08-08 13:36:38.135617: Epoch 247 
2025-08-08 13:36:38.136735: Current learning rate: 0.00019 
2025-08-08 13:36:56.339062: train_loss -0.7825 
2025-08-08 13:36:56.341453: val_loss -0.7223 
2025-08-08 13:36:56.342504: Pseudo dice [np.float32(0.8022)] 
2025-08-08 13:36:56.343354: Epoch time: 18.21 s 
2025-08-08 13:36:57.512361:  
2025-08-08 13:36:57.514210: Epoch 248 
2025-08-08 13:36:57.515326: Current learning rate: 0.00013 
2025-08-08 13:37:15.587584: train_loss -0.7546 
2025-08-08 13:37:15.590089: val_loss -0.7032 
2025-08-08 13:37:15.591065: Pseudo dice [np.float32(0.7868)] 
2025-08-08 13:37:15.591979: Epoch time: 18.08 s 
2025-08-08 13:37:16.779420:  
2025-08-08 13:37:16.782736: Epoch 249 
2025-08-08 13:37:16.783825: Current learning rate: 7e-05 
2025-08-08 13:37:34.889827: train_loss -0.7529 
2025-08-08 13:37:34.892070: val_loss -0.7169 
2025-08-08 13:37:34.892970: Pseudo dice [np.float32(0.7953)] 
2025-08-08 13:37:34.893813: Epoch time: 18.11 s 
2025-08-08 13:37:44.393895: Training done. 
2025-08-08 13:37:44.558761: Using splits from existing split file: /zhome/4b/5/187216/dm-i-ai-2025/tumor_segmentation/data_nnUNet/preprocessed/Dataset001_TumorSegmentation/splits_final.json 
2025-08-08 13:37:44.560891: The split file contains 1 splits. 
2025-08-08 13:37:44.563428: Desired fold for training: 0 
2025-08-08 13:37:44.564259: This split has 581 training and 27 validation cases. 
2025-08-08 13:37:44.565310: predicting patient_002 
2025-08-08 13:37:44.569696: patient_002, shape torch.Size([1, 1, 426, 400]), rank 0 
2025-08-08 13:38:35.768769: predicting patient_013 
2025-08-08 13:38:35.776528: patient_013, shape torch.Size([1, 1, 889, 400]), rank 0 
2025-08-08 13:38:36.321139: predicting patient_014 
2025-08-08 13:38:36.325281: patient_014, shape torch.Size([1, 1, 489, 400]), rank 0 
2025-08-08 13:38:36.597129: predicting patient_015 
2025-08-08 13:38:36.602378: patient_015, shape torch.Size([1, 1, 489, 400]), rank 0 
2025-08-08 13:38:36.880197: predicting patient_019 
2025-08-08 13:38:36.885562: patient_019, shape torch.Size([1, 1, 489, 400]), rank 0 
2025-08-08 13:38:37.150649: predicting patient_025 
2025-08-08 13:38:37.155383: patient_025, shape torch.Size([1, 1, 489, 400]), rank 0 
2025-08-08 13:38:37.455359: predicting patient_030 
2025-08-08 13:38:37.460537: patient_030, shape torch.Size([1, 1, 489, 400]), rank 0 
2025-08-08 13:38:37.786926: predicting patient_036 
2025-08-08 13:38:37.793014: patient_036, shape torch.Size([1, 1, 427, 400]), rank 0 
2025-08-08 13:38:38.128983: predicting patient_042 
2025-08-08 13:38:38.133888: patient_042, shape torch.Size([1, 1, 489, 400]), rank 0 
2025-08-08 13:38:38.433335: predicting patient_060 
2025-08-08 13:38:38.438005: patient_060, shape torch.Size([1, 1, 489, 400]), rank 0 
2025-08-08 13:38:38.710461: predicting patient_065 
2025-08-08 13:38:38.715134: patient_065, shape torch.Size([1, 1, 486, 400]), rank 0 
2025-08-08 13:38:38.950233: predicting patient_066 
2025-08-08 13:38:38.957379: patient_066, shape torch.Size([1, 1, 739, 400]), rank 0 
2025-08-08 13:38:39.409713: predicting patient_074 
2025-08-08 13:38:39.414245: patient_074, shape torch.Size([1, 1, 489, 400]), rank 0 
2025-08-08 13:38:39.638901: predicting patient_099 
2025-08-08 13:38:39.643149: patient_099, shape torch.Size([1, 1, 477, 400]), rank 0 
2025-08-08 13:38:39.872484: predicting patient_111 
2025-08-08 13:38:39.876638: patient_111, shape torch.Size([1, 1, 426, 400]), rank 0 
2025-08-08 13:38:40.149993: predicting patient_120 
2025-08-08 13:38:40.154011: patient_120, shape torch.Size([1, 1, 426, 400]), rank 0 
2025-08-08 13:38:40.382696: predicting patient_121 
2025-08-08 13:38:40.387862: patient_121, shape torch.Size([1, 1, 426, 400]), rank 0 
2025-08-08 13:38:40.655086: predicting patient_125 
2025-08-08 13:38:40.660084: patient_125, shape torch.Size([1, 1, 489, 400]), rank 0 
2025-08-08 13:38:40.943418: predicting patient_128 
2025-08-08 13:38:40.947575: patient_128, shape torch.Size([1, 1, 489, 400]), rank 0 
2025-08-08 13:38:41.233964: predicting patient_131 
2025-08-08 13:38:41.238552: patient_131, shape torch.Size([1, 1, 489, 400]), rank 0 
2025-08-08 13:38:41.462749: predicting patient_134 
2025-08-08 13:38:41.467193: patient_134, shape torch.Size([1, 1, 444, 400]), rank 0 
2025-08-08 13:38:41.747373: predicting patient_142 
2025-08-08 13:38:41.752810: patient_142, shape torch.Size([1, 1, 489, 400]), rank 0 
2025-08-08 13:38:41.973905: predicting patient_152 
2025-08-08 13:38:41.980948: patient_152, shape torch.Size([1, 1, 865, 400]), rank 0 
2025-08-08 13:38:42.516903: predicting patient_161 
2025-08-08 13:38:42.521154: patient_161, shape torch.Size([1, 1, 426, 400]), rank 0 
2025-08-08 13:38:42.745435: predicting patient_171 
2025-08-08 13:38:42.749682: patient_171, shape torch.Size([1, 1, 426, 400]), rank 0 
2025-08-08 13:38:43.015741: predicting patient_176 
2025-08-08 13:38:43.024944: patient_176, shape torch.Size([1, 1, 489, 400]), rank 0 
2025-08-08 13:38:43.251041: predicting patient_177 
2025-08-08 13:38:43.255187: patient_177, shape torch.Size([1, 1, 426, 400]), rank 0 
2025-08-08 13:38:55.099167: Validation complete 
2025-08-08 13:38:55.100389: Mean Validation Dice:  0.738598195287856 
