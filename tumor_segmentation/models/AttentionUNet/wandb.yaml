trainer:
  logger:
    class_path: lightning.pytorch.loggers.WandbLogger
    init_args:
      project: "tumor-segmentation"
      name: "attention-unet"  # Specific name for Basic GNN
      save_dir: "wandb_logs"
      log_model: "all"
  callbacks+:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        dirpath: "checkpoints"
        filename: "attention-unet-{epoch:02d}-{val_dice:.4f}"
        monitor: "val_dice"
        mode: "max"
        save_top_k: 1
        verbose: true 