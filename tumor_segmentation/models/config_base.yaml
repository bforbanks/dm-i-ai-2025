# Base configuration with common trainer, data, and callback settings
# This file should be inherited by model-specific configs

# Data configuration - Common for all models
data:
  val_split: 0.20
  batch_size: 16
  num_workers: 0
  patient_control_ratio: 0.80
  use_oversampling: False  # Toggle between oversampling (true) and previous dataloading (false)
  padding: false  # Toggle between padding (true) and resizing (false) for image processing
  target_width: 400  # Target width when padding is enabled
  target_height: 992  # Target height when padding is enabled

# Trainer configuration - Common for all models
trainer:
  max_epochs: 10000
  max_time: "00:12:00:00"  # Maximum training time of 30 minutes
  accelerator: auto
  devices: auto
  precision: 32
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelSummary
      init_args:
        max_depth: -1 
    # - class_path: lightning.pytorch.callbacks.EarlyStopping
    #   init_args:
    #     monitor: "val_displacement_distance_epoch"
    #     mode: "min"
    #     patience: 10
    #     verbose: true
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: "epoch"
    - class_path: callbacks.visualization_callback.TumorVisualizationCallback
      init_args:
        log_every_n_epochs: 3
        tumor_image_name: "patient_019"
        control_image_name: "control_275"
        additional_tumor_names: ["patient_042", "patient_067"]
        additional_control_names: ["control_123", "control_090"]
    - class_path: callbacks.dice_analysis_callback.DiceAnalysisCallback
      init_args:
        analysis_every_n_epochs: 3
        save_top_k: 7
        verbose: false  # Set to false to disable verbose dice analysis output
    - class_path: callbacks.epoch_checkpoint_callback.EpochCheckpointCallback
      init_args:
        target_epoch: 75
        dirpath: "checkpoints"
        filename: "epoch_065_specific"